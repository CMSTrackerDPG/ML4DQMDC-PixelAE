{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run autoencoder training iteratively on growing datasets (for 1 type of histogram)**  \n",
    "First part of the notebook: train an autoencoder on the first 5, 10, 15 etc. runs of 2017 data taking.  \n",
    "Second part of the notebook: choose a random run to test on, use 5 previous runs for training.  \n",
    "(this is a first step towards using reference runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('utils')\n",
    "import csv_utils as csvu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import plot_utils as pu\n",
    "import autoencoder_utils as aeu\n",
    "import generate_data_utils as gdu\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(gdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the data (all runs)\n",
    "\n",
    "year = '2017'\n",
    "histname = 'chargeInner_PXLayer_2'\n",
    "\n",
    "df = csvu.read_csv('data/DF'+year+'_'+histname+'.csv')\n",
    "df = dfu.select_highstat(df)\n",
    "runs_all = dfu.get_runs(df)\n",
    "(hists_all,runnbs_all,lsnbs_all) = hu.preparedatafromdf(df,returnrunls=True,onlygolden=False,rebinningfactor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get a test set\n",
    "\n",
    "goodrunsls = {'2017':\n",
    "              {\n",
    "                \"297056\":[[-1]],\n",
    "                #\"297177\":[[-1]],\n",
    "                #\"301449\":[[-1]]\n",
    "              }}\n",
    "\n",
    "badrunsls = {'2017':\n",
    "            {\n",
    "                \"297287\":[[-1]],\n",
    "                \"297288\":[[-1]],\n",
    "                \"297289\":[[-1]],\n",
    "                \"299316\":[[-1]],\n",
    "                \"299324\":[[-1]],\n",
    "            }}\n",
    "\n",
    "# load good and bad sets from df\n",
    "(hists_good,runnbs_good,lsnbs_good) = hu.preparedatafromdf( dfu.select_runsls(df,goodrunsls[year]),returnrunls=True,onlygolden=True)\n",
    "(hists_bad,runnbs_bad,lsnbs_bad) = hu.preparedatafromdf( dfu.select_runsls(df,badrunsls[year]),returnrunls=True,onlygolden=False)\n",
    "print('shape of good test set '+str(hists_good.shape))\n",
    "print('shape of bad test set '+str(hists_bad.shape))\n",
    "# make plot\n",
    "pu.plot_sets([hists_good,hists_bad],ax=None,title='',colorlist=['b','r'],labellist=['good','bad'],transparencylist=[],xlims=(0,-1))\n",
    "# use resampling tool to upsample and add more variation\n",
    "hists_good = gdu.upsample_hist_set(hists_good,figname='',ntarget=2e3,fourierstdfactor=15.)\n",
    "hists_bad = gdu.upsample_hist_set(hists_bad,figname='',ntarget=2e3,fourierstdfactor=5.)\n",
    "print('shape of good test set '+str(hists_good.shape))\n",
    "print('shape of bad test set '+str(hists_bad.shape))\n",
    "# make plot\n",
    "pu.plot_sets([hists_good,hists_bad],ax=None,title='',colorlist=['b','r'],labellist=['good','bad'],transparencylist=[0.1,0.1],xlims=(0,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to purify training set by removing a given fraction of high mse histograms\n",
    "\n",
    "def purify_training_set(hists,model,rmfraction):\n",
    "    mse = aeu.mseTop10Raw(hists,model.predict(hists))\n",
    "    threshold = np.quantile(mse,1-rmfraction)\n",
    "    keepindices = np.where(mse<threshold)\n",
    "    return hists[keepindices]\n",
    "\n",
    "### functions to test performance on test set\n",
    "\n",
    "def test_autoencoder(hists_good,hists_bad,model):\n",
    "    mse_good = aeu.mseTop10Raw(hists_good,model.predict(hists_good))\n",
    "    mse_bad = aeu.mseTop10Raw(hists_bad,model.predict(hists_bad))\n",
    "    labels_good = np.zeros(len(mse_good))\n",
    "    labels_bad = np.ones(len(mse_bad))\n",
    "\n",
    "    labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "    scores = np.concatenate(tuple([mse_good,mse_bad]))\n",
    "    maxnoninf = np.max(np.where(scores==np.inf,np.min(scores),scores))\n",
    "    scores = np.where(scores==np.inf,maxnoninf,scores)\n",
    "\n",
    "    auc = aeu.get_roc(scores,labels)\n",
    "    plt.show()\n",
    "\n",
    "def plot_examples(hists_good,hists_bad,model):\n",
    "    # set parameters\n",
    "    nexamples = 6\n",
    "    fig,axs = plt.subplots(2,nexamples,figsize=(24,12))\n",
    "    inds_good = np.random.choice(range(len(hists_good)),nexamples)\n",
    "    inds_bad = np.random.choice(range(len(hists_bad)),nexamples)\n",
    "    inds_ref = np.random.choice(range(len(hists_good)),20)\n",
    "    # determine whether to show run/lumi number in label (not possible when using resampled sets)\n",
    "    truelabel = True\n",
    "    if( len(hists_good)!=len(runnbs_good) or len(hists_bad)!=len(runnbs_good) ): truelabel = False\n",
    "    # plot examples\n",
    "    for i in range(nexamples):\n",
    "        hist_good = hists_good[inds_good[i]:inds_good[i]+1]\n",
    "        reco_good = model.predict(hist_good)\n",
    "        hist_bad = hists_bad[inds_bad[i]:inds_bad[i]+1]\n",
    "        reco_bad = model.predict(hist_bad)\n",
    "        hist_good_label = hist_bad_label = 'hist'\n",
    "        if truelabel: \n",
    "            hist_good_label += ' (run: '+str(int(runnbs_good[inds_good[i]]))+', ls: '+str(int(lsnbs_good[inds_good[i]]))+')'\n",
    "            hist_bad_label += ' (run: '+str(int(runnbs_bad[inds_bad[i]]))+', ls: '+str(int(lsnbs_bad[inds_bad[i]]))+')'\n",
    "        pu.plot_sets([hist_good,reco_good,hists_good[inds_ref]],\n",
    "                  fig=fig,ax=axs[0,i],\n",
    "                  title='',\n",
    "                  colorlist=['black','red','blue'],\n",
    "                  labellist=[hist_good_label,'reco','good hists'],\n",
    "                  transparencylist=[1.,1.,0.1])\n",
    "        pu.plot_sets([hist_bad,reco_bad,hists_good[inds_ref]],\n",
    "                  fig=fig,ax=axs[1,i],\n",
    "                  title='',\n",
    "                  colorlist=['black','red','blue'],\n",
    "                  labellist=[hist_bad_label,'reco','good hists'],\n",
    "                  transparencylist=[1.,1.,0.1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### iterate over growing amount of data\n",
    "\n",
    "nruns = [5,10]\n",
    "\n",
    "# first iteration manually\n",
    "X_train = hists_all[np.where(runnbs_all<runs_all[nruns[0]])]\n",
    "print('size of training set (intial): '+str(len(X_train)))\n",
    "X_train_ext = gdu.upsample_hist_set(X_train,1e5)\n",
    "#X_train_ext = X_train\n",
    "model = aeu.train_simple_autoencoder(X_train_ext,nepochs=10)\n",
    "print('evaluating model on test set')\n",
    "test_autoencoder(hists_good,hists_bad,model)\n",
    "plot_examples(hists_good,hists_bad,model)\n",
    "\n",
    "# next iterations in a loop\n",
    "for i in range(1,len(nruns)):\n",
    "    \n",
    "    this_upperbound = runs_all[nruns[i]]\n",
    "    this_lowerbound = runs_all[nruns[i-1]]\n",
    "    print('adding runs {} to {}'.format(this_lowerbound,this_upperbound))\n",
    "    print('(training on {} runs in total)'.format(nruns[i]))\n",
    "    newhists = hists_all[np.where( (runnbs_all<this_upperbound) & (runnbs_all>=this_lowerbound) )]\n",
    "    print('number of new histograms added to training set: '+str(len(newhists)))\n",
    "    X_train = np.concatenate( (X_train,newhists), axis=0 )\n",
    "    X_train = purify_training_set(X_train,model,0.1)\n",
    "    print('size of training set (intial): '+str(len(X_train)))\n",
    "    X_train_ext = gdu.upsample_hist_set(X_train,1e5)\n",
    "    #X_train_ext = X_train\n",
    "    model = aeu.train_simple_autoencoder(X_train_ext)\n",
    "    print('size of training set (after training and purifying): '+str(len(X_train)))\n",
    "    print('evaluating model on test set')\n",
    "    test_autoencoder(hists_good,hists_bad,model)\n",
    "    plot_examples(hists_good,hists_bad,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose random run for testing, train on previous runs\n",
    "# (testing: see next cell)\n",
    "\n",
    "# choose runs\n",
    "print('number of available runs: '+str(len(runs_all)))\n",
    "runindex = np.random.choice(range(5,len(runs_all)))\n",
    "runindex = runs_all.index(305364)\n",
    "test_run = runs_all[runindex]\n",
    "print('chosen run index: '+str(runindex)+', corresponding to run: '+str(test_run))\n",
    "training_runs = runs_all[runindex-5:runindex]\n",
    "print('runs used for training: '+str(training_runs))\n",
    "\n",
    "# get the data\n",
    "df = dfu.select_dcson(df)\n",
    "(hists_train,runnbs_train,lsnbs_train) = hu.preparedatafromdf( dfu.select_runs(df,training_runs),returnrunls=True,onlygolden=False)\n",
    "(hists_test,runnbs_test,lsnbs_test) = hu.preparedatafromdf( dfu.select_runs(df,[test_run]),returnrunls=True,onlygolden=False)\n",
    "print('shape of training set '+str(hists_train.shape))\n",
    "print('shape of test set '+str(hists_test.shape))\n",
    "# make plot\n",
    "pu.plot_sets([hists_train,hists_test],ax=None,title='',colorlist=['b','g'],labellist=['train','test'],transparencylist=[0.5,0.5],xlims=(0,-1))\n",
    "\n",
    "# train the autoencoder\n",
    "X_train = gdu.upsample_hist_set(hists_train,1e5)\n",
    "#X_train = hists_train\n",
    "model = aeu.train_simple_autoencoder(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test the autoencoder trained in the previous cell\n",
    "\n",
    "# note: do not simply use hists_good for a good test set, \n",
    "# as the model might not be trained on all shape variations that are supposed to be 'good',\n",
    "# resulting in artificially bad performance.\n",
    "# we can use hists_test instead, but it is not at all guaranteed that all of them are good.\n",
    "# hence the label 'good hists' in the plot below is not necessarily correct.\n",
    "\n",
    "test_autoencoder(hists_test,hists_bad,model)\n",
    "plot_examples(hists_test,hists_bad,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
