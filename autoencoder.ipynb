{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test an autoencoder for a particular type of histogram**  \n",
    "At this stage all of the available data (per year) is used to train the autoencoder.  \n",
    "For the case where only a small subset of the data is used for training, see autoencoder_iterative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('utils')\n",
    "import csv_utils as csvu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import clustering_utils as cu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(cu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read and select data\n",
    "\n",
    "histtype = 'DF2017_chargeInner_PXLayer_2'\n",
    "df = csvu.read_csv('data/'+histtype+'.csv')\n",
    "print('raw input data shape: {}'.format( dfu.get_hist_values(df)[0].shape ))\n",
    "df = dfu.select_dcson(df)\n",
    "print('input data shape: {}'.format( dfu.get_hist_values(df)[0].shape ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter step 1: filter out low statistics\n",
    "\n",
    "df = dfu.select_highstat(df,entries_to_bins_ratio=1000)\n",
    "print('number of passing lumisections: {}'.format( len(df) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter step 2: filter out clearly anomalous data based on distance in moment space\n",
    "# at this point this is a little deprecated, however, maybe re-introduce later on!\n",
    "\n",
    "# current implementation is still experimental and probably not optimal, if only the speed of it... \n",
    "# and does not work properly.......\n",
    "\n",
    "skipthiscell = True\n",
    "\n",
    "if not skipthiscell:\n",
    "    \n",
    "    nprevious = 5 # number of previous runs to compare with\n",
    "    runlist = get_runs(df)\n",
    "    threshold = -100\n",
    "    selector = []\n",
    "\n",
    "    # settings for moments\n",
    "    orders = [1,2]\n",
    "    xmin = 0.\n",
    "    xmax = 1.\n",
    "    nbins = df.at[0,'Xbins']\n",
    "    binwidth = (xmax-xmin)/nbins\n",
    "    bins = np.linspace(xmin+binwidth/2,xmax-binwidth/2,num=nbins,endpoint=True)\n",
    "\n",
    "    for i,run in enumerate(runlist):\n",
    "        #print('now investigating run '+str(run))\n",
    "        if i < nprevious: continue\n",
    "        # get this run\n",
    "        thisdf = select_runs(df,[run])\n",
    "        (thishists,_,thisls) = get_hist_values(thisdf)\n",
    "        thishists = thishists[:,1:-1]\n",
    "        thismoments = histmoments(bins,thishists,orders)\n",
    "        # get nprevious runs\n",
    "        pruns = select_runs(df,runlist[i-nprevious:i])\n",
    "        (phists,_,_) = get_hist_values(pruns)\n",
    "        phists = phists[:,1:-1]\n",
    "        pmoments = histmoments(bins,phists,orders)\n",
    "        # fit kde\n",
    "        fitfunc = gaussiankde(pmoments,bw='scott')\n",
    "        # evaluate on this run\n",
    "        thislogprob = np.log(fitfunc.pdf(thismoments))\n",
    "        passingls = thisls[np.where(thislogprob>threshold)]\n",
    "        if len(passingls)>0: selector.append((run,passingls))\n",
    "        # print some info\n",
    "        nrejected = len(np.asarray(thislogprob<threshold).nonzero()[0])\n",
    "        #print('{} out of {} ls were rejected'.format(nrejected,len(thislogprob)))\n",
    "\n",
    "    dfpass = select_runsls(df,selector)\n",
    "    print('number of passing lumisections: '+str(len(dfpass)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### alternative if not using moment method\n",
    "dfpass = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preprocessing of the data: rebinning and normalizing\n",
    "\n",
    "rebinningfactor = 1\n",
    "\n",
    "X_train = hu.preparedatafromdf(dfpass,rebinningfactor=rebinningfactor,doplot=True)\n",
    "(ntrain,nbins) = X_train.shape\n",
    "print('Size of training set: '+str(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build the model and train it, or load an already saved model\n",
    "\n",
    "# choose whether to train new model or load one \n",
    "trainnew = True\n",
    "savemodel = False\n",
    "modelname = histtype+'_dcson_40epochs.h5'\n",
    "\n",
    "# imports\n",
    "#import math\n",
    "#from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#from keras.layers import Input, Dense\n",
    "#from keras.layers.advanced_activations import PReLU\n",
    "#from keras.models import Model, load_model\n",
    "from keras.models import load_model\n",
    "\n",
    "# case 1: train new model\n",
    "if trainnew:\n",
    "    \n",
    "    input_size = X_train.shape[1]\n",
    "    arch = [int(X_train.shape[1]/2.)]\n",
    "    act = ['tanh']*len(arch)\n",
    "    opt = 'adam'\n",
    "    loss = aeu.mseTop10\n",
    "    autoencoder = aeu.getautoencoder(input_size,arch,act,opt,loss)\n",
    "    \n",
    "    history = autoencoder.fit(X_train, X_train, epochs=2, batch_size=500, shuffle=False, verbose=1, validation_split=0.1)\n",
    "    pu.plot_loss(history, title = 'model loss')\n",
    "    if savemodel: autoencoder.save(modelname)\n",
    "    \n",
    "# case 2: load existing model\n",
    "else:\n",
    "    autoencoder = load_model('models/'+modelname,custom_objects={'mseTop10': mseTop10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the model on the training set\n",
    "\n",
    "predictionTrain = autoencoder.predict(X_train)\n",
    "mseTrain = aeu.mseTop10Raw(X_train, predictionTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the global MSE trend\n",
    "\n",
    "pu.plot_mse(mseTrain)\n",
    "(mean,std) = pu.plot_mse(mseTrain,doplot=False)\n",
    "print('mean mse: {}'.format(mean))\n",
    "print('std mse: {}'.format(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### impose a mse upper boundary and plot random examples of passing and failing histograms\n",
    "# note: at this point, only the training set (usually golden json) is considered!\n",
    "# for a test set: see cell below.\n",
    "\n",
    "cutvalue = mean + 3*std\n",
    "#cutvalue = 4.73e-6\n",
    "print('The mse threshold is: '+str(cutvalue))\n",
    "goodindices = np.arange(0,len(mseTrain))[mseTrain<cutvalue]\n",
    "badindices = np.arange(0,len(mseTrain))[mseTrain>cutvalue]\n",
    "\n",
    "print('Number of passing histograms: '+str(len(goodindices)))\n",
    "print('Number of failing histograms: '+str(len(badindices)))\n",
    "\n",
    "nplot = 20\n",
    "print('examples of good histograms and reconstruction:')\n",
    "randint = np.random.choice(goodindices,size=nplot,replace=False)\n",
    "for i in randint: \n",
    "    histlist = [X_train[int(i),:],predictionTrain[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "\n",
    "print('examples of bad histograms and reconstruction:')\n",
    "randint = np.random.choice(badindices,size=nplot,replace=False)\n",
    "for i in randint:\n",
    "    histlist = [X_train[int(i),:],predictionTrain[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get a test set and evaluate the model\n",
    "\n",
    "goodrunsls = { \"297056\":[[-1]],\n",
    "                \"297177\":[[-1]],\n",
    "                \"301449\":[[-1]] \n",
    "             }\n",
    "badrunsls = {\n",
    "                #\"297048\":[[-1]],\n",
    "                #\"297282\":[[-1]],\n",
    "                #\"297283\":[[-1]],\n",
    "                #\"297284\":[[-1]],\n",
    "                \"297287\":[[-1]],\n",
    "                #\"297288\":[[-1]],\n",
    "                #\"297289\":[[-1]],\n",
    "                #\"299316\":[[-1]],\n",
    "                #\"299317\":[[-1]],\n",
    "                #\"299318\":[[-1]],\n",
    "                #\"299324\":[[-1]],\n",
    "                #\"299326\":[[-1]],\n",
    "                #\"301086\":[[88,126]],\n",
    "                #\"301086\":[[89,89]],\n",
    "                #\"303948\":[[1710,1710]],\n",
    "            }\n",
    "df = csvu.read_csv('data/'+histtype+'.csv')\n",
    "df = dfu.select_dcson(df)\n",
    "X_test_good = hu.preparedatafromdf( dfu.select_runsls(df,goodrunsls) )\n",
    "X_test_bad = hu.preparedatafromdf( dfu.select_runsls(df,badrunsls) )\n",
    "\n",
    "pu.plot_sets([X_test_good,X_test_bad],colorlist=['b','r'],\n",
    "             labellist=['Histograms in test set labeled \"good\"','Histograms in test set labeled \"bad\"'])\n",
    "\n",
    "prediction_test_good = autoencoder.predict(X_test_good)\n",
    "mse_test_good = aeu.mseTopNRaw(X_test_good, prediction_test_good, n=10 )\n",
    "prediction_test_bad = autoencoder.predict(X_test_bad)\n",
    "mse_test_bad = aeu.mseTopNRaw(X_test_bad, prediction_test_bad, n=10 )\n",
    "\n",
    "print('average mse on good set: '+str(np.mean(mse_test_good)))\n",
    "print('average mse on bad set: '+str(np.mean(mse_test_bad)))\n",
    "\n",
    "nplot = 10\n",
    "print('examples of good histograms and reconstruction:')\n",
    "randint = np.random.choice(np.arange(len(X_test_good)),size=nplot,replace=False)\n",
    "for i in randint: \n",
    "    histlist = [X_test_good[int(i),:],prediction_test_good[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "\n",
    "print('examples of bad histograms and reconstruction:')\n",
    "randint = np.random.choice(np.arange(len(X_test_bad)),size=nplot,replace=False)\n",
    "for i in randint:\n",
    "    histlist = [X_test_bad[int(i),:],prediction_test_bad[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use artificial data to assess the model performance\n",
    "\n",
    "goodhists = gdu.fourier_noise(X_test_good,nresamples=60,nonnegative=True,stdfactor=15.,figname='f')\n",
    "badhists = gdu.fourier_noise(X_test_bad,nresamples=2400,nonnegative=True,stdfactor=15.,figname='f')\n",
    "print('number of good histograms: '+str(len(goodhists)))\n",
    "print('number of bad histograms: '+str(len(badhists)))\n",
    "\n",
    "validation_data = np.vstack((goodhists,badhists))\n",
    "labels = np.hstack((np.zeros(len(goodhists)),np.ones(len(badhists))))\n",
    "prediction = autoencoder.predict(validation_data)\n",
    "mse = aeu.mseTopNRaw(validation_data, prediction, n=10 )\n",
    "print('examples of artificial histograms and reconstruction:')\n",
    "shuffled_indices = np.arange(len(validation_data))\n",
    "_ = np.random.shuffle(shuffled_indices)\n",
    "validation_data = validation_data[shuffled_indices]\n",
    "labels = labels[shuffled_indices]\n",
    "prediction = prediction[shuffled_indices]\n",
    "mse = mse[shuffled_indices]\n",
    "\n",
    "# distribution of output scores\n",
    "pu.plot_score_dist(mse,labels,nbins=200,normalize=True)\n",
    "print(np.amin(mse[np.where(labels==1)]))\n",
    "print(np.amax(mse[np.where(labels==0)]))\n",
    "# classical ROC curve: signal efficiency (good data marked as good) vs background efficiency (bad data marked as good)\n",
    "auc = aeu.get_roc(mse, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### continution of previous cell: choose wp and plot confusion matrix\n",
    "\n",
    "msewp = 0.9e-3\n",
    "aeu.get_confusion_matrix_from_hists(validation_data,labels,prediction,msewp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cells below are deprecated and not used anymore**  \n",
    "No guarantee that they will still run or that any useful conclusions can be drawn from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use the function above to train a network for different types \n",
    "### of histograms and compare the output\n",
    "# part 1: process all histograms\n",
    "# function definition has been moved to autoencoder_utils.py!\n",
    "\n",
    "dfratio = fit_autoencoder('DF2018_MainDiagonal_Position.csv')\n",
    "dfpixel = fit_autoencoder('DF2018_NumberOfClustersInPixel.csv',rebinningfactor=8)\n",
    "dfstrip = fit_autoencoder('DF2018_NumberOfClustersInStrip.csv',rebinningfactor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use the function above to train a network for different types \n",
    "### of histograms and compare the output\n",
    "# part 2: check consistency\n",
    "\n",
    "print(np.sum(np.array(dfratio['passencoder'])))\n",
    "print(np.sum(np.array(dfpixel['passencoder'])))\n",
    "print(np.sum(np.array(dfstrip['passencoder'])))\n",
    "print('----')\n",
    "npass = np.zeros(len(dfratio))\n",
    "for i in range(len(dfratio)):\n",
    "    n = 0\n",
    "    if(dfratio.at[i,'passencoder']): n+=1\n",
    "    if(dfpixel.at[i,'passencoder']): n+=1\n",
    "    if(dfstrip.at[i,'passencoder']): n+=1\n",
    "    npass[i] = n\n",
    "print(np.sum(np.where(npass==3,1,0)))\n",
    "print(np.sum(np.where(npass==2,1,0)))\n",
    "print(np.sum(np.where(npass==1,1,0)))\n",
    "print(np.sum(np.where(npass==0,1,0)))\n",
    "print('----')\n",
    "print(np.sum(np.where(np.array(dfratio['passencoder'])+np.array(dfpixel['passencoder'])==2,1,0)))\n",
    "print(np.sum(np.where(np.array(dfratio['passencoder'])+np.array(dfstrip['passencoder'])==2,1,0)))\n",
    "print(np.sum(np.where(np.array(dfpixel['passencoder'])+np.array(dfstrip['passencoder'])==2,1,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### another idea: train a self-consistent autoencoder\n",
    "\n",
    "datafilename = 'DF2017_MainDiagonal_Position.csv'\n",
    "df = read_csv(datafilename)\n",
    "print('raw input data shape: '+str(get_hist_values(df)[0].shape))\n",
    "df = select_golden(df)\n",
    "print('golden input data shape: '+str(get_hist_values(df)[0].shape))\n",
    "domoment = True\n",
    "if domoment:\n",
    "    (df,dfpass,_,_,_) = filteranomalous(df,rmlargest=0.005,doplot=True)\n",
    "    momentmask = np.array(df['passmomentmethod'])\n",
    "    momentinds = np.nonzero(momentmask)\n",
    "else:\n",
    "    dfpass = df\n",
    "    momentinds = np.arange(0,len(df))\n",
    "\n",
    "print('number of passing lumisections: '+str(len(dfpass)))\n",
    "\n",
    "rebinningfactor = 1\n",
    "\n",
    "(histpass,_,_) = get_hist_values(dfpass)\n",
    "histpass = histpass[:,1:-1]\n",
    "print('histograms shape: '+str(histpass.shape))\n",
    "rhistpass = rebin2d(histpass,rebinningfactor)\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "rhistpass = normalize(rhistpass, norm='l1', axis=1) #normalise the sample, i.e the rows\n",
    "\n",
    "nremoved = 1e10\n",
    "encodermask = np.zeros(len(df))\n",
    "encodermask[momentinds] = 1\n",
    "while(nremoved>100):\n",
    "    ninit = len(rhistpass)\n",
    "    print('Starting network training for '+str(ninit)+' instances.')\n",
    "    (_,mse) = train_autoencoder(rhistpass,datafilename)\n",
    "    (gmean,gstd) = globalMSETrend(mse)\n",
    "    cutvalue = gmean+5*gstd\n",
    "    encodermask[encodermask==1] = np.where(mse<cutvalue,1,0)\n",
    "    rhistpass = rhistpass[mse<cutvalue]\n",
    "    print('Network training finished, '+str(len(rhistpass))+' out of '+str(ninit)+' instances passed.')\n",
    "    nremoved = ninit - len(rhistpass)\n",
    "df['passencoder'] = encodermask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check histograms resulting from cell above\n",
    "\n",
    "nplot = 100\n",
    "temp = df[df['passencoder']==1]\n",
    "temp.reset_index(drop=True,inplace=True)\n",
    "(ghists,_,_) = get_hist_values(temp)\n",
    "print(ghists.shape)\n",
    "randint = np.random.choice(np.arange(0,len(ghists)),size=nplot,replace=False)\n",
    "for i in randint:\n",
    "    plt.figure()\n",
    "    plt.plot(ghists[i,:],color='b')\n",
    "\n",
    "temp = df[df['passencoder']==0]\n",
    "temp.reset_index(drop=True,inplace=True)\n",
    "(bhists,_,_) = get_hist_values(temp)\n",
    "print(bhists.shape)\n",
    "randint = np.random.choice(np.arange(0,len(bhists)),size=nplot,replace=False)\n",
    "for i in randint:\n",
    "    plt.figure()\n",
    "    plt.plot(bhists[i,:],color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
