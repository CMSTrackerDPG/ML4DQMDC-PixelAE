{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic reading and writing of csv files as a first data processing**  \n",
    "\n",
    "This script starts from the raw csv files provided by central DQM as an ultimate input.  \n",
    "These files are difficult to work with since they contain a fixed number of lines, not grouped by e.g. run number, and they contain a large number of histogram types together.  \n",
    "This script (of which basically all the functionality is in the 'utils' folder) puts them into a more useful form, i.e. one file per histogram type and per year, containing all runs and lumisections for that type for that year.  \n",
    "\n",
    "It might be a good idea to run this code, where you change the histogram types to the ones that you intend to use in your study.  \n",
    "Options are also available (although not shown in this small tutorial) to make files per era instead of per year, if you prefer that.\n",
    "\n",
    "For more information, check the documentation of utils/csv_utils and utils.dataframe_utils! See also the comments in the code below for some more explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import dataframe_utils as dfu\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(dfu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read an example csv file\n",
    "\n",
    "dim = 2 # dimension of histograms (1 or 2)\n",
    "datadirs = list(csvu.get_data_dirs(year='2017',dim=dim)) \n",
    "# get_data_dirs returns the directories where to find the input csv files.\n",
    "# this is hard-coded for now and might change in the future.\n",
    "# if your data is located elsewhere, you can easily write an equivalent function with the same output.\n",
    "print('data directories:')\n",
    "print(datadirs)\n",
    "datadir = datadirs[0]\n",
    "csvfiles = csvu.sort_filenames(list(csvu.get_csv_files(datadir)))\n",
    "# sort_filenames and get_csv_files are more or less self-explanatory.\n",
    "print('number of csv files in {}: {}'.format(datadir,len(csvfiles)))\n",
    "df = csvu.read_csv(csvfiles[0])\n",
    "# read_csv turns an input csv file into a pandas dataframe. \n",
    "# uncomment the following two lines to get a printout of the dataframe before any further processing.\n",
    "# comment them back again to have a better view of the rest of the printouts in this cell.\n",
    "#print('example data frame:')\n",
    "#print(df)\n",
    "print('--- available runs present in this file: ---')\n",
    "for r in dfu.get_runs(df): print(r)\n",
    "print('--- available histogram types in this file ---')\n",
    "for h in dfu.get_histnames(df): print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main reformatting of input csv files\n",
    "# note that this function can take quite a while to run!\n",
    "\n",
    "csvu.write_skimmed_csv(['clusterposition_zphi_ontrack_PXLayer_1'],'2017',eras=['B'],dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra: for 2D histograms, even the files per histogram type and per era might be too big to easily work with.\n",
    "# this cell writes even smaller files for quicker testing\n",
    "\n",
    "year = '2017'\n",
    "era = 'B'\n",
    "dim = 2 # dimension of histograms (1 or 2)\n",
    "histname = 'clusterposition_zphi_ontrack_PXLayer_1'\n",
    "datadirs = list(csvu.get_data_dirs(year=year,eras=[era],dim=dim)) \n",
    "datadir = datadirs[0]\n",
    "csvfiles = csvu.sort_filenames(list(csvu.get_csv_files(datadir)))\n",
    "print('number of csv files in {}: {}'.format(datadir,len(csvfiles)))\n",
    "df = csvu.read_csv(csvfiles[0])\n",
    "df = dfu.select_histnames(df,[histname])\n",
    "df.to_csv('DF'+year+era+'_'+histname+'_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
