{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test an autoencoder for a particular type of histogram**  \n",
    "At this stage all of the available data (per year) is used to train the autoencoder.  \n",
    "For the case where only a small subset of the data is used for training, see autoencoder_iterative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read and select data\n",
    "\n",
    "histtype = 'DF2017_chargeInner_PXLayer_2'\n",
    "df = csvu.read_csv('../data/'+histtype+'.csv')\n",
    "print('raw input data shape: {}'.format( dfu.get_hist_values(df)[0].shape ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filtering: select only DCS-bin on data and filter out low statistics\n",
    "\n",
    "df = dfu.select_dcson(df)\n",
    "print('number of passing lumisections after DCS selection: {}'.format( len(df) ))\n",
    "\n",
    "df = dfu.select_highstat(df,entries_to_bins_ratio=100)\n",
    "print('number of passing lumisections after high statistics selection: {}'.format( len(df) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preprocessing of the data: rebinning and normalizing\n",
    "\n",
    "rebinningfactor = 1\n",
    "\n",
    "X_train = hu.preparedatafromdf(df,rebinningfactor=rebinningfactor,donormalize=True,doplot=True)\n",
    "(ntrain,nbins) = X_train.shape\n",
    "print('size of training set: '+str(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build the model and train it, or load an already saved model\n",
    "\n",
    "# choose whether to train new model or load one \n",
    "trainnew = True\n",
    "savemodel = False\n",
    "modelname = histtype+'_dcson_40epochs.h5'\n",
    "\n",
    "# imports\n",
    "from keras.models import load_model\n",
    "\n",
    "# case 1: train new model\n",
    "if trainnew:\n",
    "    \n",
    "    input_size = X_train.shape[1]\n",
    "    arch = [int(X_train.shape[1]/2.)]\n",
    "    act = ['tanh']*len(arch)\n",
    "    opt = 'adam'\n",
    "    loss = aeu.mseTop10\n",
    "    autoencoder = aeu.getautoencoder(input_size,arch,act,opt,loss)\n",
    "    \n",
    "    history = autoencoder.fit(X_train, X_train, epochs=20, batch_size=500, shuffle=False, verbose=1, validation_split=0.1)\n",
    "    pu.plot_loss(history, title = 'model loss')\n",
    "    if savemodel: autoencoder.save(modelname)\n",
    "    \n",
    "# case 2: load existing model\n",
    "else:\n",
    "    autoencoder = load_model('../models/'+modelname,custom_objects={'mseTop10': aeu.mseTop10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the model on the training set\n",
    "\n",
    "predictionTrain = autoencoder.predict(X_train)\n",
    "mseTrain = aeu.mseTop10Raw(X_train, predictionTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the global MSE trend\n",
    "\n",
    "pu.plot_mse(mseTrain,rmlargest=0.005)\n",
    "(mean,std) = pu.plot_mse(mseTrain,doplot=False,rmlargest=0.005)\n",
    "print('mean mse: {}'.format(mean))\n",
    "print('std mse: {}'.format(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### impose a mse upper boundary and plot random examples of passing and failing histograms\n",
    "# note: at this point, only the training set is considered!\n",
    "# for a test set: see cell below.\n",
    "\n",
    "cutvalue = mean + 3*std\n",
    "#cutvalue = 4.73e-6\n",
    "print('The mse threshold is: '+str(cutvalue))\n",
    "goodindices = np.arange(0,len(mseTrain))[mseTrain<cutvalue]\n",
    "badindices = np.arange(0,len(mseTrain))[mseTrain>cutvalue]\n",
    "\n",
    "print('Number of passing histograms: '+str(len(goodindices)))\n",
    "print('Number of failing histograms: '+str(len(badindices)))\n",
    "\n",
    "nplot = 5\n",
    "print('examples of good histograms and reconstruction:')\n",
    "randint = np.random.choice(goodindices,size=nplot,replace=False)\n",
    "for i in randint: \n",
    "    histlist = [X_train[int(i),:],predictionTrain[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "    plt.show()\n",
    "\n",
    "print('examples of bad histograms and reconstruction:')\n",
    "randint = np.random.choice(badindices,size=nplot,replace=False)\n",
    "for i in randint:\n",
    "    histlist = [X_train[int(i),:],predictionTrain[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get a test set and evaluate the model\n",
    "\n",
    "goodrunsls = { \"297056\":[[-1]],\n",
    "                \"297177\":[[-1]],\n",
    "                \"301449\":[[-1]] \n",
    "             }\n",
    "badrunsls = {\n",
    "                #\"297048\":[[-1]],\n",
    "                #\"297282\":[[-1]],\n",
    "                #\"297283\":[[-1]],\n",
    "                #\"297284\":[[-1]],\n",
    "                \"297287\":[[-1]],\n",
    "                #\"297288\":[[-1]],\n",
    "                #\"297289\":[[-1]],\n",
    "                #\"299316\":[[-1]],\n",
    "                #\"299317\":[[-1]],\n",
    "                #\"299318\":[[-1]],\n",
    "                #\"299324\":[[-1]],\n",
    "                #\"299326\":[[-1]],\n",
    "                #\"301086\":[[88,126]],\n",
    "                #\"301086\":[[89,89]],\n",
    "                #\"303948\":[[1710,1710]],\n",
    "            }\n",
    "df = csvu.read_csv('../data/'+histtype+'.csv')\n",
    "df = dfu.select_dcson(df)\n",
    "X_test_good = hu.preparedatafromdf( dfu.select_runsls(df,goodrunsls),donormalize=True )\n",
    "X_test_bad = hu.preparedatafromdf( dfu.select_runsls(df,badrunsls),donormalize=True )\n",
    "\n",
    "pu.plot_sets([X_test_good,X_test_bad],colorlist=['b','r'],\n",
    "             labellist=['Histograms in test set labeled \"good\"','Histograms in test set labeled \"bad\"'])\n",
    "\n",
    "prediction_test_good = autoencoder.predict(X_test_good)\n",
    "mse_test_good = aeu.mseTopNRaw(X_test_good, prediction_test_good, n=10 )\n",
    "prediction_test_bad = autoencoder.predict(X_test_bad)\n",
    "mse_test_bad = aeu.mseTopNRaw(X_test_bad, prediction_test_bad, n=10 )\n",
    "\n",
    "print('average mse on good set: '+str(np.mean(mse_test_good)))\n",
    "print('average mse on bad set: '+str(np.mean(mse_test_bad)))\n",
    "\n",
    "nplot = 10\n",
    "print('examples of good histograms and reconstruction:')\n",
    "randint = np.random.choice(np.arange(len(X_test_good)),size=nplot,replace=False)\n",
    "for i in randint: \n",
    "    histlist = [X_test_good[int(i),:],prediction_test_good[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "    plt.show()\n",
    "\n",
    "print('examples of bad histograms and reconstruction:')\n",
    "randint = np.random.choice(np.arange(len(X_test_bad)),size=nplot,replace=False)\n",
    "for i in randint:\n",
    "    histlist = [X_test_bad[int(i),:],prediction_test_bad[int(i),:]]\n",
    "    labellist = ['data','reconstruction']\n",
    "    colorlist = ['black','blue']\n",
    "    pu.plot_hists(histlist,colorlist=colorlist,labellist=labellist)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use artificial data to assess the model performance\n",
    "\n",
    "goodhists = gdu.fourier_noise(X_test_good,nresamples=60,nonnegative=True,stdfactor=15.,figname='f')\n",
    "badhists = gdu.fourier_noise(X_test_bad,nresamples=2400,nonnegative=True,stdfactor=15.,figname='f')\n",
    "print('number of good histograms: '+str(len(goodhists)))\n",
    "print('number of bad histograms: '+str(len(badhists)))\n",
    "\n",
    "validation_data = np.vstack((goodhists,badhists))\n",
    "labels = np.hstack((np.zeros(len(goodhists)),np.ones(len(badhists))))\n",
    "prediction = autoencoder.predict(validation_data)\n",
    "mse = aeu.mseTopNRaw(validation_data, prediction, n=10 )\n",
    "print('examples of artificial histograms and reconstruction:')\n",
    "shuffled_indices = np.arange(len(validation_data))\n",
    "_ = np.random.shuffle(shuffled_indices)\n",
    "validation_data = validation_data[shuffled_indices]\n",
    "labels = labels[shuffled_indices]\n",
    "prediction = prediction[shuffled_indices]\n",
    "mse = mse[shuffled_indices]\n",
    "\n",
    "# distribution of output scores\n",
    "pu.plot_score_dist(mse,labels,nbins=200,normalize=True)\n",
    "print(np.amin(mse[np.where(labels==1)]))\n",
    "print(np.amax(mse[np.where(labels==0)]))\n",
    "# classical ROC curve: signal efficiency (good data marked as good) vs background efficiency (bad data marked as good)\n",
    "auc = aeu.get_roc(mse, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### continution of previous cell: choose wp and plot confusion matrix\n",
    "\n",
    "msewp = 1.5e-5\n",
    "aeu.get_confusion_matrix_from_hists(validation_data,labels,prediction,msewp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
