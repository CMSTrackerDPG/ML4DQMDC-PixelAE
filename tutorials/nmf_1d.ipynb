{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test an NMF model for a particular type of histogram**\n",
    "\n",
    "Notes:  \n",
    "- This script is intended to be used with 1D histograms. (For the extension to 2D histograms, see nmf_2d.ipynb!)  \n",
    "- We only consider one type of histogram at a time. (For the extension to multiple histograms, see nmf_combine.ipynb!)  \n",
    "- In this case the use of the custom class HistStruct is not necessary and one can work with the dataframe and numpy arrays directly. However, we use it here as a proof-of-principle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import dataframe_utils as dfu\n",
    "import json_utils as jsonu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)\n",
    "import NMFClassifier\n",
    "importlib.reload(NMFClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define run properties\n",
    "# in this cell all major run properties are going to be set,\n",
    "# e.g. what runs to train on and what runs to test on\n",
    "\n",
    "# define a list of good 'reference' runs (found by eye)\n",
    "# should be replaced at some point by the reference runs defined by the DQM/DC team.\n",
    "goodrunsls = {'2017':\n",
    "                {\n",
    "                \"297056\":[[-1]],\n",
    "                \"297177\":[[-1]],\n",
    "                \"301449\":[[-1]],\n",
    "                }\n",
    "             }\n",
    "\n",
    "# define core test set of clearly bad runs (found by eye)\n",
    "badrunsls = {'2017':\n",
    "                {\n",
    "                \"297287\":[[-1]],\n",
    "                \"297288\":[[-1]],\n",
    "                #\"297289\":[[-1]],\n",
    "                \"299316\":[[-1]],\n",
    "                \"299324\":[[-1]],\n",
    "                #\"299326\":[[-1]],\n",
    "                #\"301086\":[[88,126]] # only bad for size_PXDisk_+1 -> maybe do not use for now (unclear what are real anomalies)\n",
    "                }\n",
    "            }\n",
    "\n",
    "# set year to use\n",
    "year = '2017'\n",
    "\n",
    "# set histogram names to use \n",
    "histname = 'chargeInner_PXLayer_2'\n",
    "            \n",
    "# set whether to train globally or locally\n",
    "training_mode = 'local'\n",
    "\n",
    "if training_mode == 'global':\n",
    "    runsls_training = None # use none to not add a mask for training (can e.g. use DCS-bit on mask)\n",
    "    runsls_good = None # use none to not add a mask for good runs (can e.g. use templates)\n",
    "    runsls_bad = badrunsls[year] # predefined bad runs\n",
    "    print('selected runs/lumisections for training: all')\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on a small set of runs\n",
    "    # for now on n runs preceding a chosen application run,\n",
    "    # to be extended with choosing reference runs.\n",
    "    \n",
    "    # select application run\n",
    "    available_runs = dfu.get_runs( dfu.select_dcson( csvu.read_csv('../data/DF'+year+'_'+histname+'.csv') ) )\n",
    "    run_application = 305351\n",
    "    run_application_index = available_runs.index(run_application)\n",
    "    # select training set\n",
    "    ntraining = 5\n",
    "    runsls_training = jsonu.tuplelist_to_jsondict([(el,[-1]) for el in available_runs[run_application_index-ntraining:run_application_index]])\n",
    "    runsls_bad = badrunsls[year]\n",
    "    runsls_good = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the data based on the configuration defined above\n",
    "\n",
    "readnew = True\n",
    "save = False\n",
    "hsfilename = 'test.pkl'\n",
    "\n",
    "if readnew:\n",
    "    \n",
    "    # add the histograms\n",
    "    histstruct = HistStruct.HistStruct()\n",
    "    # loop over the histogram types to take into account\n",
    "    print('adding {}...'.format(histname))\n",
    "    # read the histograms from the csv file\n",
    "    filename = '../data/DF'+year+'_'+histname+'.csv'\n",
    "    df = csvu.read_csv( filename )\n",
    "    # in case of local training, we can remove most of the histograms\n",
    "    if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "        runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "        df = dfu.select_runsls( df, runsls_total )\n",
    "    histstruct.add_dataframe( df )\n",
    "    print('found {} histograms'.format(len(histstruct.runnbs)))\n",
    "    \n",
    "    # add masks\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_hightstat_mask( 'highstat' )\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        # special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "    \n",
    "    if save:\n",
    "        histstruct.save( hsfilename )\n",
    "        \n",
    "if not readnew:\n",
    "    \n",
    "    histstruct = HistStruct.HistStruct.load( hsfilename )\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if 'bad' in name])\n",
    "    \n",
    "print('created a histstruct with the following properties:')\n",
    "print('- number of histogram types: {}'.format(len(histstruct.histnames)))\n",
    "print('- number of lumisections: {}'.format(len(histstruct.lsnbs)))\n",
    "print('- masks: {}'.format(list(histstruct.masks.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipthiscell = False\n",
    "\n",
    "if( training_mode=='local' and not skipthiscell ):\n",
    "    \n",
    "    # training and application runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','training'],['highstat','good']],\n",
    "                                labellist = ['training','testing'],\n",
    "                                colorlist = ['blue','green']\n",
    "                              )\n",
    "    \n",
    "    # application run and bad test runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['bad']],\n",
    "                                labellist = ['good','bad'],\n",
    "                                colorlist = ['green','red']\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the training set using artificial data\n",
    "\n",
    "extendtraining = False\n",
    "\n",
    "if extendtraining:\n",
    "    histstruct.exthistograms['training'] = {}\n",
    "    print('generating artificial training data for '+histname)\n",
    "    hists = histstruct.get_histograms( histname=histname, masknames=['dcson','highstat','training'] )\n",
    "    print('  original number of histograms: {}'.format(len(hists)))\n",
    "    histstruct.exthistograms['training'][histname] = gdu.upsample_hist_set( hists , 5e4)\n",
    "    print('  -> generated {} histograms'.format(len(histstruct.exthistograms['training'][histname])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and train an NMF model\n",
    "\n",
    "if training_mode=='local': hists_train = histstruct.get_histograms( histname=histname, masknames=['dcson','highstat','training'] )\n",
    "elif training_mode=='global':\n",
    "    # use all available data for training (with DCS-on and statistics selection)\n",
    "    #hists_train = histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] )\n",
    "    # this can however take a long time... alternatively, use averaged histograms for training\n",
    "    hists_train = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), 1000 )\n",
    "if extendtraining: hists_train = histstruct.exthistograms['training'][histname]\n",
    "classifier = NMFClassifier.NMFClassifier( hists_train, ncomponents=3, nmax=10 )\n",
    "_ = histstruct.add_classifier( histname, classifier, evaluate=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the NMF components\n",
    "\n",
    "components = classifier.get_components()\n",
    "_ = pu.plot_hists_multi( components, colorlist=list(range(len(components))), xaxtitle='bin number', yaxtitle='arbitrary units', title='NMF components' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the models on all histograms in the (non-extended) histstruct\n",
    "\n",
    "print('evaluating model for '+histname)\n",
    "_ = histstruct.evaluate_classifier(histname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to arrays with correct shape\n",
    "\n",
    "if training_mode=='local':\n",
    "    mse_train = histstruct.get_scores( histname=histname, masknames=['dcson','highstat','training'])\n",
    "    print('found mse array for training set of following shape: {}'.format(mse_train.shape))\n",
    "    mse_good = histstruct.get_scores( histname=histname, masknames=['dcson','highstat','good'])\n",
    "    print('found mse array for good set of following shape: {}'.format(mse_good.shape))\n",
    "    mse_bad = []\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad.append( histstruct.get_scores( histname=histname, masknames=['dcson','bad{}'.format(i)]) )\n",
    "        print('found mse array for bad set of following shape: {}'.format(mse_bad[i].shape))\n",
    "\n",
    "elif training_mode=='global':\n",
    "    mse_train = histstruct.get_scores( histname=histname, masknames=['dcson','highstat'])\n",
    "    print('found mse array for training set of following shape: {}'.format(mse_train.shape))\n",
    "    hists_good = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat']), 100 )\n",
    "    mse_good = histstruct.classifiers[histname].evaluate( hists_good )\n",
    "    print('found mse array for good set of following shape: {}'.format(mse_good.shape))\n",
    "    mse_bad = []\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad.append( histstruct.get_scores( histname=histname, masknames=['dcson','bad{}'.format(i)]) )\n",
    "        print('found mse array for bad set of following shape: {}'.format(mse_bad[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the test set using artificial data generation and evaluate the model on the extended test set\n",
    "\n",
    "skipthiscell = False # to prevent running this cell by accident\n",
    "\n",
    "if not skipthiscell:\n",
    "    \n",
    "    histstruct.exthistograms['good'] = {}\n",
    "    for i in range(nbadruns): histstruct.exthistograms['bad{}'.format(i)] = {}\n",
    "    print('generating data for '+histname)\n",
    "    if 'good' in histstruct.masks.keys():\n",
    "        goodhists = histstruct.get_histograms( histname=histname,masknames=['dcson','highstat','good'] )\n",
    "    else:\n",
    "        goodhists = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), 15 )\n",
    "    histstruct.exthistograms['good'][histname] = gdu.upsample_hist_set( goodhists,\n",
    "                                                    figname='',ntarget=nbadruns*5e3,fourierstdfactor=20.)\n",
    "    for i in range(nbadruns):\n",
    "        badhists = histstruct.get_histograms( histname=histname,masknames=['dcson','bad{}'.format(i)] )\n",
    "        histstruct.exthistograms['bad{}'.format(i)][histname] = gdu.upsample_hist_set(\n",
    "            badhists,figname='',ntarget=5e3,fourierstdfactor=20.)\n",
    "\n",
    "    print('evaluating: '+histname)\n",
    "    # calculate mse for good test set\n",
    "    mse_good_ext = histstruct.classifiers[histname].evaluate( histstruct.exthistograms['good'][histname] )\n",
    "    print('found mse array for good set of following shape: {}'.format(mse_good_ext.shape))\n",
    "    mse_bad_ext = []\n",
    "    for i in range(nbadruns):\n",
    "        # calculate mse\n",
    "        mse_bad_ext.append( histstruct.classifiers[histname].evaluate( histstruct.exthistograms['bad{}'.format(i)][histname] ) )\n",
    "        print('found mse array for bad set of following shape: {}'.format(mse_bad_ext[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a roc curve based on the test results above\n",
    "\n",
    "importlib.reload(aeu)\n",
    "\n",
    "use_ext = True\n",
    "mse_good_eval = mse_good\n",
    "mse_bad_eval = mse_bad\n",
    "if use_ext:\n",
    "    mse_good_eval = mse_good_ext\n",
    "    mse_bad_eval = mse_bad_ext\n",
    "\n",
    "mse_bad_eval_flat = np.concatenate(tuple(mse_bad_eval))\n",
    "labels_good = np.zeros(len(mse_good_eval)) # background: label = 0\n",
    "labels_bad = np.ones(len(mse_bad_eval_flat)) # signal: label = 1\n",
    "\n",
    "labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "scores = np.concatenate(tuple([mse_good_eval,mse_bad_eval_flat]))\n",
    "\n",
    "pu.plot_score_dist(scores, labels, nbins=50, normalize=True)\n",
    "\n",
    "auc = aeu.get_roc(scores, labels, mode='geom', doprint=False)\n",
    "\n",
    "threshold = 0.1e-3\n",
    "aeu.get_confusion_matrix(scores,labels,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot some random examples\n",
    "\n",
    "# define reference histograms\n",
    "refhists = {}\n",
    "if( 'good' in histstruct.masks.keys() ): \n",
    "    refhists[histname] = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['highstat','dcson','good']), 15 )\n",
    "else: \n",
    "    refhists[histname] = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), 15 )\n",
    "\n",
    "# define number of plots to make\n",
    "nplot = 10\n",
    "\n",
    "# make plots for good histograms\n",
    "runnbs_good = histstruct.get_runnbs( masknames=['highstat','dcson'] )\n",
    "lsnbs_good = histstruct.get_lsnbs( masknames=['highstat','dcson'] )\n",
    "indices = np.random.choice( np.arange(len(runnbs_good)), size=nplot, replace=False )\n",
    "for i in indices:\n",
    "    _ = histstruct.plot_ls( runnbs_good[i], lsnbs_good[i], recohist='auto', refhists=refhists )\n",
    "    \n",
    "# make plots for bad histograms\n",
    "runnbs_bad = histstruct.get_runnbs( masknames=['dcson','bad'] )\n",
    "lsnbs_bad = histstruct.get_lsnbs( masknames=['dcson','bad'] )\n",
    "indices = np.random.choice( np.arange(len(runnbs_bad)), size=nplot, replace=False )\n",
    "for i in indices:\n",
    "    _ = histstruct.plot_ls( runnbs_bad[i], lsnbs_bad[i], recohist='auto', refhists=refhists )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
