{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train an autoencoder (very similar to autoencoder.ipynb) on several types of histograms and study the combined prediction**\n",
    "\n",
    "Note: this is quite long and complicated script that is quite flexible in the method of training and testing. It is not so much a fixed and fully worked out tutorial, but rather a development script. In fact, many of the results I showed in \"recent\" DQM/DC general meetings were obtained with this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import json_utils as jsonu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "import refruns_utils as rru\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "importlib.reload(rru)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)\n",
    "import AutoEncoder\n",
    "importlib.reload(AutoEncoder)\n",
    "import SeminormalFitter\n",
    "import GaussianKdeFitter\n",
    "import HyperRectangleFitter\n",
    "importlib.reload(SeminormalFitter)\n",
    "importlib.reload(GaussianKdeFitter)\n",
    "importlib.reload(HyperRectangleFitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define run properties\n",
    "# in this cell all major run properties are going to be set,\n",
    "# e.g. what runs to train on and what runs to test on\n",
    "\n",
    "# define a list of good 'reference' runs (found by eye)\n",
    "# should be replaced at some point by the reference runs defined by the DQM/DC team.\n",
    "goodrunsls = {'2017':\n",
    "              {\n",
    "                \"297056\":[[-1]],\n",
    "                \"297177\":[[-1]],\n",
    "                \"301449\":[[-1]],\n",
    "              },\n",
    "              '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "             {  \"315267\":[[-1]] \n",
    "             }}\n",
    "\n",
    "# define core test set of clearly bad runs (found by eye)\n",
    "badrunsls = {'2017':\n",
    "                {\n",
    "                \"297287\":[[-1]],\n",
    "                \"297288\":[[-1]],\n",
    "                \"297289\":[[-1]],\n",
    "                \"299316\":[[-1]],\n",
    "                \"299324\":[[-1]],\n",
    "                \"299326\":[[-1]],\n",
    "                \"301086\":[[88,126]] # only bad for size_PXDisk_+1 -> maybe do not use for now (unclear what are real anomalies)\n",
    "                },\n",
    "            '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "                {\n",
    "                #\"317479\":[[-1]],\n",
    "                \"317480\":[[-1]],\n",
    "                \"317481\":[[-1]],\n",
    "                \"317482\":[[-1]],\n",
    "                #\"319847\":[[1,35]]\n",
    "            }}\n",
    "\n",
    "# set year to use\n",
    "year = '2017'\n",
    "\n",
    "# set histogram names to use \n",
    "histnames = [\n",
    "            'chargeInner_PXLayer_2',\n",
    "             'chargeInner_PXLayer_3',\n",
    "             'charge_PXDisk_+1','charge_PXDisk_+2','charge_PXDisk_+3',\n",
    "             'size_PXLayer_1','size_PXLayer_2',\n",
    "             'size_PXLayer_3'\n",
    "            ]\n",
    "\n",
    "# set whether to train globally or locally\n",
    "training_mode = 'global'\n",
    "\n",
    "if training_mode == 'global':\n",
    "    runsls_training = None # use none to not add a mask for training (can e.g. use DCS-bit on mask)\n",
    "    runsls_good = None # use none to not add a mask for good runs (can e.g. use templates)\n",
    "    runsls_bad = badrunsls[year] # predefined bad runs\n",
    "    print('selected runs/lumisections for training: all')\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on a small set of runs\n",
    "    # - either on n runs preceding a chosen application run,\n",
    "    # - or on the run associated as reference to the chosen application run.\n",
    "    \n",
    "    # select application run\n",
    "    available_runs = dfu.get_runs( dfu.select_dcson( csvu.read_csv('../data/DF'+year+'_'+histnames[0]+'.csv') ) )\n",
    "    run_application = 299316\n",
    "    run_application_index = available_runs.index(run_application)\n",
    "    # select training set\n",
    "    usereference = False\n",
    "    if usereference:\n",
    "        run_reference = rru.get_reference_run( run_application, jsonfile='../utils/json_allRunsRefRuns.json' )\n",
    "        if run_reference<0:\n",
    "            raise Exception('no valid reference run has been defined for run {}'.format(run_application))\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(run_reference,[-1])])\n",
    "    else:\n",
    "        ntraining = 5\n",
    "        offset = 0 # normal case: offset = 0 (just use 5 previous runs)\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(el,[-1]) for el in available_runs[run_application_index-ntraining-offset:run_application_index-offset]])\n",
    "    #runsls_bad = badrunsls[year]\n",
    "    #runsls_good = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_bad = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    runsls_good = runsls_training\n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the data based on the configuration defined above\n",
    "\n",
    "readnew = True\n",
    "save = False\n",
    "\n",
    "if readnew:\n",
    "    \n",
    "    # add the histograms\n",
    "    histstruct = HistStruct.HistStruct()\n",
    "    # loop over the histogram types to take into account\n",
    "    for histname in histnames:\n",
    "        print('adding {}...'.format(histname))\n",
    "        # read the histograms from the csv file\n",
    "        filename = '../data/DF'+year+'_'+histname+'.csv'\n",
    "        df = csvu.read_csv( filename )\n",
    "        # in case of local training, we can remove most of the histograms\n",
    "        if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "            runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "            df = dfu.select_runsls( df, runsls_total )\n",
    "        histstruct.add_dataframe( df )\n",
    "    print('found {} histograms'.format(len(histstruct.runnbs)))\n",
    "    \n",
    "    # add masks\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_highstat_mask( 'highstat' )\n",
    "    histstruct.add_stat_mask( 'lowstat', max_entries_to_bins_ratio=100 )\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        # special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "    \n",
    "    if save:\n",
    "        histstruct.save( 'test.pkl' )\n",
    "        \n",
    "if not readnew:\n",
    "    \n",
    "    histstruct = HistStruct.HistStruct.load( 'test.pkl' )\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if 'bad' in name])\n",
    "    \n",
    "print('created a histstruct with the following properties:')\n",
    "print('- number of histogram types: {}'.format(len(histstruct.histnames)))\n",
    "print('- number of lumisections: {}'.format(len(histstruct.lsnbs)))\n",
    "print('- masks: {}'.format(list(histstruct.masks.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the training and/or test sets\n",
    "# especially useful if running in local mode to check if training set is relevant for targeted application run,\n",
    "# and if the application run contains anomalies\n",
    "\n",
    "skipthiscell = True\n",
    "\n",
    "if( training_mode=='local' and not skipthiscell ):\n",
    "    \n",
    "    # training and application runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','training'],['dcson','highstat','good']],\n",
    "                                labellist = ['training','testing'],\n",
    "                                colorlist = ['blue','green']\n",
    "                              )\n",
    "    \n",
    "    # application run and bad test runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad']],\n",
    "                                labellist = ['good','bad'],\n",
    "                                colorlist = ['green','red']\n",
    "                              )\n",
    "    \n",
    "if( training_mode=='global' and not skipthiscell ):\n",
    "    \n",
    "    # bad test runs\n",
    "    for i in [0,1,2,3,4,5,6]:\n",
    "        histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['dcson','highstat','bad{}'.format(i)]],\n",
    "                                labellist = ['typical good histograms','bad'],\n",
    "                                colorlist = ['blue','red'],\n",
    "                                transparencylist = [0.01,1.]\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the training set using artificial data\n",
    "\n",
    "extendtraining = False\n",
    "\n",
    "if extendtraining:\n",
    "    histstruct.exthistograms['training'] = {}\n",
    "    for histname in histstruct.histnames:\n",
    "        # option 1: start from 'training' mask\n",
    "        hists = histstruct.get_histograms( histname=histname, masknames=['dcson','highstat','training'] )\n",
    "        # option 2: start from averages of DCS-on data\n",
    "        #hists = hu.averagehists( \n",
    "        #            histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), \n",
    "        #            1000 )\n",
    "        print('generating artificial training data for '+histname)\n",
    "        histstruct.exthistograms['training'][histname] = gdu.upsample_hist_set(hists, 5e4, figname='f' )\n",
    "        print(' -> generated {} histograms'.format(len(histstruct.exthistograms['training'][histname])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and train an autoencoder for each element\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "trainnew = False\n",
    "save = False\n",
    "modelloc = '../models/autoencoders_global_training_dcson_highstat_v20210622'\n",
    "modelbasename = ''\n",
    "\n",
    "if trainnew:\n",
    "    for histname in histstruct.histnames:\n",
    "        # choose training set\n",
    "        hists = histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] )\n",
    "        if extendtraining: hists = histstruct.exthistograms['training'][histname]\n",
    "        print('size of training set: {}'.format(hists.shape))\n",
    "        # choose whether to save the model\n",
    "        modelname = modelbasename+'_'+histname+'.h5'\n",
    "        modelname = os.path.join(modelloc,modelname)\n",
    "        if not save: modelname = '' # empty string means do not save models\n",
    "        nepochs = 40 # manual number of epochs\n",
    "        model = aeu.train_simple_autoencoder(hists,nepochs=nepochs,modelname=modelname,\n",
    "                                            batch_size=2000\n",
    "                                            )\n",
    "        classifier = AutoEncoder.AutoEncoder( model=model )\n",
    "        histstruct.add_classifier(histname,classifier)\n",
    "    \n",
    "else:\n",
    "    from autoencoder_utils import mseTop10\n",
    "    for histname in histstruct.histnames:\n",
    "        print('loading model for {}'.format(histname))\n",
    "        modelname = modelbasename+'_'+histname+'.h5'\n",
    "        modelname = os.path.join(modelloc,modelname)\n",
    "        model = load_model(modelname,custom_objects={'mseTop10':mseTop10})\n",
    "        classifier = AutoEncoder.AutoEncoder( model=model )\n",
    "        histstruct.add_classifier(histname,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the models on all histograms in the (non-extended) histstruct\n",
    "\n",
    "mse_train = []\n",
    "mse_good = []\n",
    "mse_bad = []\n",
    "for i in range(nbadruns): mse_bad.append([])\n",
    "for histname in histstruct.histnames:\n",
    "    print('evaluating model for '+histname)\n",
    "    histstruct.evaluate_classifier(histname)\n",
    "    # get mse for training set\n",
    "    if 'training' in histstruct.masks.keys():\n",
    "        thismse = histstruct.get_scores( histname=histname, masknames=['dcson','highstat', 'training'] )\n",
    "    else:\n",
    "        thismse = histstruct.get_scores( histname=histname, masknames=['dcson','highstat'] )\n",
    "    mse_train.append( thismse )\n",
    "    # get mse for good set\n",
    "    if 'good' in histstruct.masks.keys(): \n",
    "        thismse = histstruct.get_scores( histname=histname, masknames=['dcson','highstat','good'] )\n",
    "    else:\n",
    "        hists_good = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat']), 1000 )\n",
    "        thismse = histstruct.classifiers[histname].evaluate( hists_good )\n",
    "    mse_good.append( thismse )\n",
    "    # get mse for bad sets\n",
    "    for i in range(nbadruns):\n",
    "        thismse = histstruct.get_scores( histname=histname, masknames=['dcson','highstat','bad{}'.format(i)] )\n",
    "        mse_bad[i].append( thismse )\n",
    "        \n",
    "# transform to arrays with correct shape\n",
    "mse_train = np.array(mse_train)\n",
    "mse_train = np.transpose(mse_train)\n",
    "print('found mse array for training set of following shape: {}'.format(mse_train.shape))\n",
    "mse_good = np.array(mse_good)\n",
    "mse_good = np.transpose(mse_good)\n",
    "print('found mse array for good set of following shape: {}'.format(mse_good.shape))\n",
    "for i in range(nbadruns):\n",
    "    mse_bad[i] = np.array(mse_bad[i])\n",
    "    mse_bad[i] = np.transpose(mse_bad[i])\n",
    "    print('found mse array for bad set of following shape: {}'.format(mse_bad[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the multidemensional mse and fit a distribution\n",
    "\n",
    "dimslist = []\n",
    "fitfunclist = []\n",
    "nhisttypes = len(histstruct.histnames)\n",
    "for i in range(0,nhisttypes-1):\n",
    "    for j in range(i+1,nhisttypes):\n",
    "        dimslist.append((i,j))\n",
    "\n",
    "plt.close('all')\n",
    "(npoints,ndims) = mse_train.shape\n",
    "\n",
    "# settings for GaussianKdeFitter\n",
    "scott_bw = npoints**(-1./(ndims+4))\n",
    "bw_method = 20*scott_bw\n",
    "# settings for HyperRectangleFitter\n",
    "quantiles = ([0.00062,0.0006,0.00015,0.00015,\n",
    "             0.0003,0.0003,0.00053,0.00065])\n",
    "\n",
    "for dims in dimslist:\n",
    "    thismse = mse_train[:,dims]\n",
    "    if training_mode=='global': \n",
    "        fitfunc = SeminormalFitter.SeminormalFitter(thismse)\n",
    "        #fitfunc = HyperRectangleFitter.HyperRectangleFitter(thismse, \n",
    "        #                                                    [quantiles[dims[0]],quantiles[dims[1]]],\n",
    "        #                                                    'up')\n",
    "    else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(thismse,bw_method=bw_method)\n",
    "    pu.plot_fit_2d(thismse, fitfunc=fitfunc, logprob=True, clipprob=True,\n",
    "                    onlycontour=False, xlims=30, ylims=30, \n",
    "                    onlypositive=True, transparency=0.5,\n",
    "                    xaxtitle=histstruct.histnames[dims[0]], \n",
    "                    yaxtitle=histstruct.histnames[dims[1]],\n",
    "                    title='density fit of lumisection MSE')\n",
    "    #plt.close('all') # release plot memory\n",
    "    fitfunclist.append(fitfunc)\n",
    "    \n",
    "if training_mode=='global': \n",
    "    fitfunc = SeminormalFitter.SeminormalFitter(mse_train)\n",
    "    #fitfunc = HyperRectangleFitter.HyperRectangleFitter(mse_train, quantiles, 'up')\n",
    "else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(mse_train,bw_method=bw_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the test set using artificial data generation and evaluate the model on the extended test set\n",
    "\n",
    "skipthiscell = False # to prevent running this cell by accident\n",
    "\n",
    "if not skipthiscell:\n",
    "    \n",
    "    histstruct.exthistograms['good'] = {}\n",
    "    for i in range(nbadruns): histstruct.exthistograms['bad{}'.format(i)] = {}\n",
    "    for histname in histstruct.histnames:\n",
    "        print('generating data for '+histname)\n",
    "        if 'good' in histstruct.masks.keys():\n",
    "            goodhists = histstruct.get_histograms( histname=histname,masknames=['dcson','highstat','good'] )\n",
    "        else:\n",
    "            goodhists = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), 15 )\n",
    "        histstruct.exthistograms['good'][histname] = gdu.upsample_hist_set( goodhists,\n",
    "                                                    figname='',ntarget=nbadruns*5e3,fourierstdfactor=20.)\n",
    "        # alternative: copy original good set (e.g. for using resampled bad but original good)\n",
    "        #histstruct.exthistograms['good'][name] = goodhists\n",
    "        for i in range(nbadruns):\n",
    "            badhists = histstruct.get_histograms( histname=histname,masknames=['dcson','highstat','bad{}'.format(i)] )\n",
    "            histstruct.exthistograms['bad{}'.format(i)][histname] = gdu.upsample_hist_set(\n",
    "                badhists,figname='',ntarget=5e3,fourierstdfactor=20.)\n",
    "            \n",
    "    mse_good_ext = []\n",
    "    mse_bad_ext = []\n",
    "    for i in range(nbadruns): mse_bad_ext.append( [] )\n",
    "\n",
    "    for histname in histstruct.histnames:\n",
    "        print('evaluating: '+histname)\n",
    "        # calculate mse for good test set\n",
    "        mse = histstruct.classifiers[histname].evaluate( histstruct.exthistograms['good'][histname] )\n",
    "        mse_good_ext.append(mse)\n",
    "        for i in range(nbadruns):\n",
    "            # calculate mse\n",
    "            mse = histstruct.classifiers[histname].evaluate( histstruct.exthistograms['bad{}'.format(i)][histname] )\n",
    "            mse_bad_ext[i].append(mse)\n",
    "    \n",
    "    # transform to arrays with correct shape\n",
    "    mse_good_ext = np.array(mse_good_ext)\n",
    "    mse_good_ext = np.transpose(mse_good_ext)\n",
    "    print('found mse array for good set of following shape: {}'.format(mse_good_ext.shape))\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad_ext[i] = np.array(mse_bad_ext[i])\n",
    "        mse_bad_ext[i] = np.transpose(mse_bad_ext[i])\n",
    "        print('found mse array for bad set of following shape: {}'.format(mse_bad_ext[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (re-)define the test set\n",
    "\n",
    "use_ext = False\n",
    "\n",
    "mse_good_eval = mse_good\n",
    "mse_bad_eval = mse_bad\n",
    "if use_ext:\n",
    "    mse_good_eval = mse_good_ext\n",
    "    mse_bad_eval = mse_bad_ext\n",
    "    \n",
    "# subselect only specific bad sets for quick checking\n",
    "# note: not very clean, e.g. watch out with using nbadsets after this cell...\n",
    "mse_bad_eval = [mse_bad_eval[i] for i in [4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a new plot of probability contours and overlay data points\n",
    "### (only 2D projections!)  \n",
    "\n",
    "doplot = True\n",
    "\n",
    "if doplot:\n",
    "    plt.close('all')\n",
    "    colorlist = ['red','lightcoral','firebrick','chocolate','fuchsia','orange','purple']\n",
    "    #colorlist = ['red']*nbadsets\n",
    "    if len(colorlist)<len(mse_bad_eval):\n",
    "        raise Exception('ERROR: need more colors...')\n",
    "\n",
    "    for dims,partialfitfunc in zip(dimslist,fitfunclist):\n",
    "        fig,ax = pu.plot_fit_2d(mse_train[:,dims], fitfunc=partialfitfunc, logprob=True, clipprob=True, \n",
    "                    onlycontour=True, xlims=30, ylims=30, \n",
    "                    onlypositive=True, transparency=0.5,\n",
    "                    xaxtitle=histstruct.histnames[dims[0]], \n",
    "                    yaxtitle=histstruct.histnames[dims[1]],\n",
    "                    title='density fit of lumisection MSE')\n",
    "        for j in range(len(mse_bad_eval)): ax.plot(mse_bad_eval[j][:,dims[0]],mse_bad_eval[j][:,dims[1]],\n",
    "                                               '.',color=colorlist[j],markersize=4)\n",
    "        ax.plot(mse_good_eval[:,dims[0]],mse_good_eval[:,dims[1]],'.',color='blue',markersize=4)\n",
    "    \n",
    "\n",
    "# get the minimum log probability of histograms in good set\n",
    "print('--- good lumesections ---')\n",
    "logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
    "print('length of log prob array: '+str(len(logprob_good)))\n",
    "print('minimum of log prob: '+str(np.min(logprob_good)))\n",
    "#print(sorted(logprob_good))\n",
    "print('--- bad lumisections ---')\n",
    "logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n",
    "#for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "print('length of log prob array: '+str(len(logprob_bad)))\n",
    "print('maximum of log prob: '+str(np.max(logprob_bad)))\n",
    "#print(sorted(logprob_good))\n",
    "#print(sorted(logprob_bad))\n",
    "#print(logprob_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a roc curve based on the test results above\n",
    "# note: smaller logprob = less probable = more outlier = more anomalous\n",
    "# so if anomalies are signal and good histograms are background, -logprob is a suitable score definition,\n",
    "# since everything above a certain threshold will be considered signal and below it background.\n",
    "\n",
    "labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "\n",
    "labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "scores = aeu.clip_scores( scores )\n",
    "\n",
    "pu.plot_score_dist(scores, labels, siglabel='anomalous', sigcolor='r', \n",
    "                   bcklabel='good', bckcolor='g', \n",
    "                   nbins=200, normalize=True,\n",
    "                   xaxtitle='negative logarithmic probability',\n",
    "                   yaxtitle='number of lumisections (normalized)')\n",
    "\n",
    "auc = aeu.get_roc(scores, labels, mode='geom', doprint=False)\n",
    "\n",
    "logprob_threshold = 60 # everything below this logprob will be considered signal (i.e. anomalous)\n",
    "aeu.get_confusion_matrix(scores,labels,-logprob_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate particular lumisections\n",
    "\n",
    "mode = 'ls'\n",
    "run = 297100\n",
    "ls = 233 # ignored if mode is 'run'\n",
    "masknames = ['dcson','highstat'] # if mode is 'ls', used for mse plotting\n",
    "plot_mse = False # ignored if mode is 'run'\n",
    "\n",
    "#print(histstruct.runnbs[:10])\n",
    "#print(histstruct.lsnbs[:10])\n",
    "\n",
    "# define reference histograms\n",
    "refhists = {}\n",
    "for histname in histstruct.histnames:\n",
    "    if( 'good' in histstruct.masks.keys() ): \n",
    "        #refhists[histname] = histstruct.get_histograms(masknames=['highstat','dcson','good'])\n",
    "        refhists[histname] = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['highstat','dcson','good']), 15 )\n",
    "    else: \n",
    "        refhists[histname] = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), 15 )\n",
    "\n",
    "if mode=='ls':\n",
    "    # plot this particular run/ls\n",
    "    _ = histstruct.plot_ls( run, ls, recohist='auto', refhists=refhists )\n",
    "    msepoint = histstruct.get_scores_ls( run, ls )\n",
    "    msepointarray = np.array([msepoint[histname] for histname in histstruct.histnames])\n",
    "    logprob = np.log(fitfunc.pdf(np.array([msepointarray])))\n",
    "    print('-------------')\n",
    "    print('MSE values:')\n",
    "    for histname in histstruct.histnames: print('{} : {}'.format(histname,msepoint[histname]))\n",
    "    print('-------------')\n",
    "    print('logprob: '+str(logprob))\n",
    "    # plot mse distribution\n",
    "    if plot_mse:\n",
    "        for dim,histname in enumerate(histnames):\n",
    "            mses = histstruct.get_scores( histname=histname, masknames=masknames )\n",
    "            #mses = mse_good_eval[:,dim]\n",
    "            nmses = len(mses)\n",
    "            labels = np.zeros(nmses)\n",
    "            mses = np.concatenate((mses,np.ones(int(nmses/15))*msepoint[histname]))\n",
    "            labels = np.concatenate((labels,np.ones(int(nmses/15))))\n",
    "            pu.plot_score_dist( mses, labels, nbins=200, normalize=False,\n",
    "                        siglabel='this lumisection', bcklabel='all lumisections',\n",
    "                        title=histname )\n",
    "\n",
    "if mode=='run':\n",
    "    # plot given run\n",
    "    runnbs = histstruct.get_runnbs( masknames=masknames )\n",
    "    lsnbs = histstruct.get_lsnbs( masknames=masknames )\n",
    "    runsel = np.where(runnbs==run)\n",
    "    lsnbs = lsnbs[runsel]\n",
    "    print('plotting {} lumisections...'.format(len(lsnbs)))\n",
    "    for lsnb in lsnbs:\n",
    "        fig,ax = histstruct.plot_ls(run, lsnb, recohist='auto', refhists=refhists )\n",
    "        plt.show()\n",
    "        msepoint = histstruct.get_scores_ls( run, lsnb )\n",
    "        msepointarray = np.array([msepoint[histname] for histname in histstruct.histnames])\n",
    "        logprob = np.log(fitfunc.pdf(np.array([msepointarray])))\n",
    "        print('-------------')\n",
    "        print('MSE values:')\n",
    "        for histname in histstruct.histnames: print('{} : {}'.format(histname,msepoint[histname]))\n",
    "        print('-------------')\n",
    "        print('logprob: '+str(logprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate how the method performs on the golden/custom test set\n",
    "\n",
    "#evaljson = jsonu.loadjson('utils/json_pixel_good_201201.json')\n",
    "#histstruct.add_json_mask( 'pixelgood', evaljson )\n",
    "masks_eval = ['golden', 'lowstat']\n",
    "lsnbs_eval = histstruct.get_lsnbs( masknames=masks_eval )\n",
    "runnbs_eval = histstruct.get_runnbs( masknames=masks_eval )\n",
    "mse_eval_dict = histstruct.get_scores( masknames=masks_eval )\n",
    "mse_eval = []\n",
    "for histname in histstruct.histnames:\n",
    "    mse_eval.append( mse_eval_dict[histname] )\n",
    "mse_eval = np.array(mse_eval)\n",
    "mse_eval = np.transpose(mse_eval)\n",
    "print('found mse array for evaluation set of following shape: {}'.format(mse_eval.shape))\n",
    "logprob_eval = np.log(fitfunc.pdf(mse_eval))\n",
    "#print(logprob_eval)\n",
    "\n",
    "# define reference histograms\n",
    "refhists = {}\n",
    "for histname in histstruct.histnames:\n",
    "    if( 'good' in histstruct.masks.keys() ): \n",
    "        #refhists[histname] = histstruct.get_histograms(masknames=['highstat','dcson','good'])\n",
    "        refhists[histname] = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['highstat','dcson','good']), 15 )\n",
    "    else: \n",
    "        refhists[histname] = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), 15 )\n",
    "\n",
    "def get_runsls_inrange(logprob, runnbs, lsnbs, logprob_up=None, logprob_down=None):\n",
    "    # get a list of tuples of (run number, ls number) corresponding to ls with log probability within a given range\n",
    "    # - logprob, runnbs and lsnbs are equally long 1D arrays\n",
    "    # - logprob_up and logprob_down are upper and lower thresholds\n",
    "    #     if both are not None, the lumisections with logprob between the boundaries are returned\n",
    "    #     if logprob_up is None, the lumisections with logprob > logprob_down are returned\n",
    "    #     if logprob_down is None, the lumisections with logprob < logprob_up are returned\n",
    "    indices = np.array([])\n",
    "    if logprob_down is None:\n",
    "        indices = np.nonzero(logprob<logprob_up)[0]\n",
    "    elif logprob_up is None:\n",
    "        indices = np.nonzero(logprob>logprob_down)[0]\n",
    "    else:\n",
    "        indices = np.nonzero((logprob>logprob_down) & (logprob<logprob_up))[0]\n",
    "    runsinrange = runnbs[indices]\n",
    "    lsinrange = lsnbs[indices]\n",
    "    runslsinrange = []\n",
    "    for rr,lsr in zip(runsinrange,lsinrange):\n",
    "        runslsinrange.append((int(rr),int(lsr)))\n",
    "    return {'indices':indices,'runslsinrange':runslsinrange}\n",
    "\n",
    "logup = 1000\n",
    "logdown = None\n",
    "temp = get_runsls_inrange(logprob_eval, runnbs_eval, lsnbs_eval,\n",
    "                          logprob_up = logup, logprob_down = logdown)\n",
    "\n",
    "runslsinrange = temp['runslsinrange']\n",
    "print('{} out of {} LS are within these boundaries'.format(len(runslsinrange),len(logprob_eval)))\n",
    "\n",
    "# make plots\n",
    "nplotsmax = 20\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pdf = PdfPages('autoencoder_combine_output.pdf')\n",
    "for i,(runnb,lsnb) in enumerate(runslsinrange):\n",
    "    if i>=nplotsmax:\n",
    "        print('maximum number of plots reached')\n",
    "        break\n",
    "    print('------------------------')\n",
    "    fig,axs = histstruct.plot_ls( runnb, lsnb, recohist='auto', refhists=refhists)\n",
    "    plt.show()\n",
    "    pdf.savefig(fig)\n",
    "    msepoint = histstruct.get_scores_ls( runnb, lsnb )\n",
    "    msepointarray = np.array([msepoint[histname] for histname in histstruct.histnames])\n",
    "    logprob = np.log(fitfunc.pdf(np.array([msepointarray])))\n",
    "    print('-------------')\n",
    "    print('MSE values:')\n",
    "    for histname in histstruct.histnames: print('{} : {}'.format(histname,msepoint[histname]))\n",
    "    print('-------------')\n",
    "    print('logprob: '+str(logprob))\n",
    "    # only for 2 dimensions: extra contour plot\n",
    "    #if nhisttypes != 2: continue\n",
    "    #fig,ax = plt.subplots()\n",
    "    #contourplot = ax.contourf(x, y, np.log(fitfunc.pdfgrid(pos)))\n",
    "    #plt.colorbar(contourplot)\n",
    "    #ax.plot(msepoint[0],msepoint[1],'.k',markersize=10)\n",
    "    #ax.set_xlim((0.,xlim))\n",
    "    #ax.set_ylim((0.,ylim))\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate OMS data: get data\n",
    "\n",
    "import sys\n",
    "sys.path.append('../omsapi')\n",
    "from get_oms_data import get_oms_api,get_oms_data,get_oms_response_attribute\n",
    "# get the api instance\n",
    "omsapi = get_oms_api()\n",
    "# pileup and luminosity in good test set\n",
    "oms_target_run = 297100\n",
    "oms_info = get_oms_data( omsapi, 'lumisections', oms_target_run, attributes=['lumisection_number','pileup','delivered_lumi','recorded_lumi'] )\n",
    "# L1 and HLT rates in good test set\n",
    "oms_info_l1 = get_oms_data( omsapi, 'l1triggerrates', oms_target_run, extraargs={'group[granularity]':'lumisection'} )\n",
    "path_filter = {'attribute_name':'path_name','value':'HLT_ZeroBias_v5','operator':'EQ'}\n",
    "oms_info_hlt = get_oms_data( omsapi, 'hltpathrates', oms_target_run, extraargs={'group[granularity]':'lumisection'}, extrafilters=[path_filter] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate OMS data: make plots\n",
    "\n",
    "importlib.reload(pu)\n",
    "\n",
    "oms_lsnbs = get_oms_response_attribute(oms_info,'lumisection_number')\n",
    "oms_dcson = jsonu.isdcson( [oms_target_run]*len(oms_lsnbs), oms_lsnbs )\n",
    "pileup = get_oms_response_attribute(oms_info,'pileup')\n",
    "lumi_del = get_oms_response_attribute(oms_info,'delivered_lumi')\n",
    "lumi_rec = get_oms_response_attribute(oms_info,'recorded_lumi')\n",
    "l1_rate = get_oms_response_attribute(oms_info_l1,'l1a_physics')\n",
    "l1_rate = [el['rate'] for el in l1_rate]\n",
    "l1_lsnbs = get_oms_response_attribute(oms_info_l1,'first_lumisection_number') # can differ from oms_lsnbs since some lumisection numbers can be missing apparently\n",
    "l1_rate = [(l1_rate[l1_lsnbs.index(i)] if i in l1_lsnbs else None) for i in oms_lsnbs]\n",
    "hlt_rate = get_oms_response_attribute(oms_info_hlt,'rate')\n",
    "hlt_lsnbs = get_oms_response_attribute(oms_info_hlt,'first_lumisection_number') # can differ from oms_lsnbs since some lumisection numbers can be missing apparently\n",
    "hlt_rate = [(hlt_rate[hlt_lsnbs.index(i)] if i in hlt_lsnbs else None) for i in oms_lsnbs]\n",
    "\n",
    "\n",
    "doslice = False\n",
    "if doslice:\n",
    "    cropslice=slice(40,70,None)\n",
    "    oms_lsnbs = oms_lsnbs[cropslice]\n",
    "    oms_dcson = oms_dcson[cropslice]\n",
    "    pileup = pileup[cropslice]\n",
    "    lumi_rec = lumi_rec[cropslice]\n",
    "    lumi_del = lumi_del[cropslice]\n",
    "    l1_rate = l1_rate[cropslice]\n",
    "    hlt_rate = hlt_rate[cropslice]\n",
    "    \n",
    "_ = pu.plot_hists([pileup], colorlist=['b'], labellist=['pileup'], \n",
    "              xlims=(oms_lsnbs[0],oms_lsnbs[-1]),\n",
    "              title='pileup for run {}'.format(oms_target_run), xaxtitle='lumisection number', yaxtitle='pileup',\n",
    "              bkgcolor=oms_dcson, bkgcmap='cool', bkgrange=(0,1), bkgtitle='DCS bit')\n",
    "_ = pu.plot_hists([lumi_rec,lumi_del], colorlist=['g','b'], labellist=['recorded luminosity','delivered luminosity'],\n",
    "              xlims=(oms_lsnbs[0],oms_lsnbs[-1]),\n",
    "              title='luminosity for run {}'.format(oms_target_run), xaxtitle='lumisection number', yaxtitle='luminosity',\n",
    "              bkgcolor=oms_dcson,bkgcmap='cool', bkgrange=(0,1), bkgtitle='DCS bit')\n",
    "_ = pu.plot_hists([l1_rate], colorlist=['b'], labellist=['L1 trigger rate'], \n",
    "              xlims=(oms_lsnbs[0],oms_lsnbs[-1]),\n",
    "              title='L1 trigger rate for run {}'.format(oms_target_run), xaxtitle='lumisection number', yaxtitle='rate',\n",
    "              bkgcolor=oms_dcson,bkgcmap='cool', bkgrange=(0,1), bkgtitle='DCS bit')\n",
    "_ = pu.plot_hists([hlt_rate], colorlist=['b'], labellist=['HLT trigger rate'], \n",
    "              xlims=(oms_lsnbs[0],oms_lsnbs[-1]),\n",
    "              title='HLT trigger rate for run {}'.format(oms_target_run), xaxtitle='lumisection number', yaxtitle='rate',\n",
    "              bkgcolor=oms_dcson,bkgcmap='cool', bkgrange=(0,1), bkgtitle='DCS bit')\n",
    "\n",
    "#lsnb = 20\n",
    "#idx_oms = np.where(np.array(oms_lsnbs)==lsnb)[0][0]\n",
    "#print('average pileup for this lumisection: {}'.format(pileup[idx_oms]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
