{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train an NMF model on several types of 1D pixel histograms and study the combined prediction**\n",
    "\n",
    "Note: very similar to autoencoder_combine.ipynb (in fact this script started as a copy of that one), but here the used model is not an autoencoder but an NMF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "sys.path.append('../utils')\n",
    "import csv_utils as csvu\n",
    "import json_utils as jsonu\n",
    "import dataframe_utils as dfu\n",
    "import hist_utils as hu\n",
    "import autoencoder_utils as aeu\n",
    "import plot_utils as pu\n",
    "import generate_data_utils as gdu\n",
    "import refruns_utils as rru\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(dfu)\n",
    "importlib.reload(hu)\n",
    "importlib.reload(aeu)\n",
    "importlib.reload(pu)\n",
    "importlib.reload(gdu)\n",
    "importlib.reload(rru)\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "import HistStruct\n",
    "importlib.reload(HistStruct)\n",
    "import NMFClassifier\n",
    "importlib.reload(NMFClassifier)\n",
    "import SeminormalFitter\n",
    "import GaussianKdeFitter\n",
    "import HyperRectangleFitter\n",
    "importlib.reload(SeminormalFitter)\n",
    "importlib.reload(GaussianKdeFitter)\n",
    "importlib.reload(HyperRectangleFitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define run properties\n",
    "# in this cell all major run properties are going to be set,\n",
    "# e.g. what runs to train on and what runs to test on\n",
    "\n",
    "# define a list of good 'reference' runs (found by eye)\n",
    "# should be replaced at some point by the reference runs defined by the DQM/DC team.\n",
    "goodrunsls = {'2017':\n",
    "                {\n",
    "                \"297056\":[[-1]],\n",
    "                \"297177\":[[-1]],\n",
    "                \"301449\":[[-1]],\n",
    "                }\n",
    "              }\n",
    "\n",
    "# define core test set of clearly bad runs (found by eye)\n",
    "badrunsls = {'2017':\n",
    "                {\n",
    "                \"297287\":[[-1]],\n",
    "                \"297288\":[[-1]],\n",
    "                \"297289\":[[-1]],\n",
    "                \"299316\":[[-1]],\n",
    "                \"299324\":[[-1]],\n",
    "                \"299326\":[[-1]],\n",
    "                \"301086\":[[88,126]] # only bad for size_PXDisk_+1 -> maybe do not use for now (unclear what are real anomalies)\n",
    "                }\n",
    "            }\n",
    "\n",
    "# set year to use\n",
    "year = '2017'\n",
    "\n",
    "# set histogram names to use \n",
    "histnames = [\n",
    "            'chargeInner_PXLayer_2',\n",
    "             'chargeInner_PXLayer_3',\n",
    "             'charge_PXDisk_+1','charge_PXDisk_+2','charge_PXDisk_+3',\n",
    "             'size_PXLayer_1','size_PXLayer_2',\n",
    "             'size_PXLayer_3'\n",
    "            ]\n",
    "\n",
    "# set whether to train globally or locally\n",
    "training_mode = 'global'\n",
    "\n",
    "if training_mode == 'global':\n",
    "    runsls_training = None # use none to not add a mask for training (can e.g. use DCS-bit on mask)\n",
    "    runsls_good = None # use none to not add a mask for good runs (can e.g. use templates)\n",
    "    runsls_bad = badrunsls[year] # predefined bad runs\n",
    "    print('selected runs/lumisections for training: all')\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on a small set of runs\n",
    "    # for now on n runs preceding a chosen application run,\n",
    "    # to be extended with choosing reference runs.\n",
    "    \n",
    "    # select application run\n",
    "    available_runs = dfu.get_runs( dfu.select_dcson( csvu.read_csv('../data/DF'+year+'_'+histnames[0]+'.csv') ) )\n",
    "    run_application = 305351\n",
    "    run_application_index = available_runs.index(run_application)\n",
    "    # select training set\n",
    "    ntraining = 5\n",
    "    runsls_training = jsonu.tuplelist_to_jsondict([(el,[-1]) for el in available_runs[run_application_index-ntraining:run_application_index]])\n",
    "    runsls_bad = badrunsls[year]\n",
    "    runsls_good = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    print('selected runs/lumisections for training: ')\n",
    "    print(runsls_training)\n",
    "    print('selected runs/lumisections as good test set:')\n",
    "    print(runsls_good)\n",
    "    print('selected runs/lumisections as bad test set:')\n",
    "    print(runsls_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the data based on the configuration defined above\n",
    "\n",
    "readnew = True\n",
    "save = False\n",
    "\n",
    "if readnew:\n",
    "    \n",
    "    # add the histograms\n",
    "    histstruct = HistStruct.HistStruct()\n",
    "    # loop over the histogram types to take into account\n",
    "    for histname in histnames:\n",
    "        print('adding {}...'.format(histname))\n",
    "        # read the histograms from the csv file\n",
    "        filename = '../data/DF2017_'+histname+'.csv'\n",
    "        df = csvu.read_csv( filename )\n",
    "        # in case of local training, we can remove most of the histograms\n",
    "        if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "            runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "            df = dfu.select_runsls( df, runsls_total )\n",
    "        histstruct.add_dataframe( df )\n",
    "    print('found {} histograms'.format(len(histstruct.runnbs)))\n",
    "    \n",
    "    # add masks\n",
    "    histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "    histstruct.add_goldenjson_mask('golden' )\n",
    "    histstruct.add_hightstat_mask( 'highstat' )\n",
    "    if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "    if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "    nbadruns = 0\n",
    "    if runsls_bad is not None:\n",
    "        histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "        # special case for bad runs: add a mask per run (different bad runs have different characteristics)\n",
    "        nbadruns = len(runsls_bad.keys())\n",
    "        for i,badrun in enumerate(runsls_bad.keys()):\n",
    "            histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "    \n",
    "    if save:\n",
    "        histstruct.save( 'test.pkl' )\n",
    "        \n",
    "if not readnew:\n",
    "    \n",
    "    histstruct = HistStruct.HistStruct.load( 'test.pkl' )\n",
    "    nbadruns = len([name for name in list(histstruct.masks.keys()) if 'bad' in name])\n",
    "    \n",
    "print('created a histstruct with the following properties:')\n",
    "print('- number of histogram types: {}'.format(len(histstruct.histnames)))\n",
    "print('- number of lumisections: {}'.format(len(histstruct.lsnbs)))\n",
    "print('- masks: {}'.format(list(histstruct.masks.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the training and/or test sets\n",
    "# especially useful if running in local mode to check if training set is relevant for targeted application run,\n",
    "# and if the application run contains anomalies\n",
    "\n",
    "skipthiscell = True\n",
    "\n",
    "if( training_mode=='local' and not skipthiscell ):\n",
    "    \n",
    "    # training and application runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','training'],['highstat','good']],\n",
    "                                labellist = ['training','testing'],\n",
    "                                colorlist = ['blue','green']\n",
    "                              )\n",
    "    \n",
    "    # application run and bad test runs\n",
    "    histstruct.plot_histograms( masknames=[['dcson','highstat','good'],['bad']],\n",
    "                                labellist = ['good','bad'],\n",
    "                                colorlist = ['green','red']\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the training set using artificial data\n",
    "\n",
    "extendtraining = False\n",
    "\n",
    "if extendtraining:\n",
    "    histstruct.exthistograms['training'] = {}\n",
    "    for histname,hists in histstruct.get_histograms( masknames=['dcson','highstat','training'] ).items():\n",
    "        print('generating artificial training data for '+histname)\n",
    "        histstruct.exthistograms['training'][histname] = gdu.upsample_hist_set(hists,5e4)\n",
    "        print(' -> generated {} histograms'.format(len(histstruct.exthistograms['training'][histname])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and train an NMF model for each element\n",
    "\n",
    "trainnew = True\n",
    "save = False # ignored if trainnew is False\n",
    "name_ext = '2017_global_training_dcson_highstat_ncomponents3'\n",
    "\n",
    "if trainnew:\n",
    "    for histname in histstruct.histnames:\n",
    "        print('building NMF model for histogram type {}'.format(histname))\n",
    "        if training_mode=='local': hists_train = histstruct.get_histograms( histname=histname, masknames=['dcson','highstat','training'] )\n",
    "        elif training_mode=='global':\n",
    "            # use all available data for training (with DCS-on and statistics selection)\n",
    "            #hists_train = histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] )\n",
    "            # this can however take a long time... alternatively, use averaged histograms for training\n",
    "            # warning: this could lead to bias since averaged histograms will be 'artificially good'\n",
    "            #hists_train = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), int(1e3) )\n",
    "            # alternatively, train on randomly chosen histograms from training set\n",
    "            hists_train = histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] )\n",
    "            random_indices = np.random.choice(len(hists_train), size=int(5e4), replace=False)\n",
    "            hists_train = hists_train[random_indices]\n",
    "        if extendtraining: hists_train = histstruct.exthistograms['training'][histname]\n",
    "        print('size of training set: {}'.format(hists_train.shape))\n",
    "        classifier = NMFClassifier.NMFClassifier( hists_train, ncomponents=3, nmax=10 )\n",
    "        histstruct.add_classifier( histname, classifier, evaluate=False )\n",
    "        if save: \n",
    "            path = '../models/nmfclassifier_{}_{}.pkl'.format(histname,name_ext)\n",
    "            with open(path,'wb') as f:\n",
    "                pickle.dump(classifier,f)\n",
    "                \n",
    "else:\n",
    "    for histname in histstruct.histnames:\n",
    "        path = '../models/nmfclassifier_{}_{}.pkl'.format(histname,name_ext)\n",
    "        with open(path,'rb') as f:\n",
    "            classifier = pickle.load(f)\n",
    "        histstruct.add_classifier( histname, classifier, evaluate=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot NMF model components\n",
    "\n",
    "# initializations\n",
    "ncols = min(4,len(histnames))\n",
    "nrows = int(math.ceil(len(histnames)/ncols))\n",
    "fig,axs = plt.subplots(nrows,ncols,figsize=(6*ncols,6*nrows),squeeze=False)\n",
    "# loop over all histogram types\n",
    "for j,histname in enumerate(histstruct.histnames):\n",
    "    # get the histograms to plot\n",
    "    hists = histstruct.classifiers[histname].get_components()\n",
    "    pu.plot_hists_multi(hists, fig=fig, ax=axs[int(j/ncols),j%ncols],\n",
    "                        title=histname, colorlist=list(range(len(hists))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reset NMF model loss parameters without re-training\n",
    "\n",
    "for histname in histstruct.histnames:\n",
    "    histstruct.classifiers[histname].set_nmax( 10 )\n",
    "    #histstruct.classifiers[histname].set_loss_type( 'chi2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the models on all histograms in the (non-extended) histstruct\n",
    "\n",
    "mse_train = []\n",
    "mse_good = []\n",
    "mse_bad = []\n",
    "for i in range(nbadruns): mse_bad.append([])\n",
    "for histname in histstruct.histnames:\n",
    "    print('evaluating model for '+histname)\n",
    "    histstruct.evaluate_classifier(histname)\n",
    "    # get mse for training set\n",
    "    if 'training' in histstruct.masks.keys():\n",
    "        thismse = histstruct.get_scores( histname=histname, masknames=['dcson','highstat', 'training'] )\n",
    "    else:\n",
    "        thismse = histstruct.get_scores( histname=histname, masknames=['dcson','highstat'] )\n",
    "    mse_train.append( thismse )\n",
    "    # get mse for good set\n",
    "    if 'good' in histstruct.masks.keys(): \n",
    "        thismse = histstruct.get_scores( histname=histname, masknames=['dcson','highstat','good'] )\n",
    "    else:\n",
    "        hists_good = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat']), 1000 )\n",
    "        thismse = histstruct.classifiers[histname].evaluate( hists_good )\n",
    "    mse_good.append( thismse )\n",
    "    # get mse for bad sets\n",
    "    for i in range(nbadruns):\n",
    "        thismse = histstruct.get_scores( histname=histname, masknames=['dcson','highstat','bad{}'.format(i)] )\n",
    "        mse_bad[i].append( thismse )\n",
    "        \n",
    "# transform to arrays with correct shape\n",
    "mse_train = np.array(mse_train)\n",
    "mse_train = np.transpose(mse_train)\n",
    "print('found mse array for training set of following shape: {}'.format(mse_train.shape))\n",
    "mse_good = np.array(mse_good)\n",
    "mse_good = np.transpose(mse_good)\n",
    "print('found mse array for good set of following shape: {}'.format(mse_good.shape))\n",
    "for i in range(nbadruns):\n",
    "    mse_bad[i] = np.array(mse_bad[i])\n",
    "    mse_bad[i] = np.transpose(mse_bad[i])\n",
    "    print('found mse array for bad set of following shape: {}'.format(mse_bad[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the multidemensional mse and fit a distribution\n",
    "\n",
    "importlib.reload(HyperRectangleFitter)\n",
    "importlib.reload(pu)\n",
    "\n",
    "dimslist = []\n",
    "fitfunclist = []\n",
    "nhisttypes = len(histstruct.histnames)\n",
    "for i in range(0,nhisttypes-1):\n",
    "    for j in range(i+1,nhisttypes):\n",
    "        dimslist.append((i,j))\n",
    "\n",
    "plt.close('all')\n",
    "(npoints,ndims) = mse_train.shape\n",
    "scott_bw = npoints**(-1./(ndims+4))\n",
    "bw_method = 20*scott_bw\n",
    "for dims in dimslist:\n",
    "   \n",
    "    thismse = mse_train[:,dims]\n",
    "    if training_mode=='global': \n",
    "        fitfunc = SeminormalFitter.SeminormalFitter(thismse)\n",
    "        #fitfunc = HyperRectangleFitter.HyperRectangleFitter( thismse, 0.001, 'up', verbose=True )\n",
    "    else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(thismse,bw_method=bw_method)\n",
    "    fig,ax = pu.plot_fit_2d(thismse, fitfunc=fitfunc, logprob=True, clipprob=True,\n",
    "                    onlycontour=False, xlims=30, ylims=30, \n",
    "                    onlypositive=True, xaxtitle=histstruct.histnames[dims[0]], \n",
    "                    yaxtitle=histstruct.histnames[dims[1]], transparency=0.5)\n",
    "    plt.show()\n",
    "    #plt.close('all') # release plot memory\n",
    "    fitfunclist.append(fitfunc)\n",
    "    \n",
    "if training_mode=='global': \n",
    "    fitfunc = SeminormalFitter.SeminormalFitter(mse_train)\n",
    "    #fitfunc = HyperRectangleFitter.HyperRectangleFitter( mse_train, 0.001, 'up', verbose=True )\n",
    "else: fitfunc = GaussianKdeFitter.GaussianKdeFitter(mse_train,bw_method=bw_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the test set using artificial data generation and evaluate the model on the extended test set\n",
    "\n",
    "skipthiscell = False # to prevent running this cell by accident\n",
    "\n",
    "if not skipthiscell:\n",
    "    \n",
    "    histstruct.exthistograms['good'] = {}\n",
    "    for i in range(nbadruns): histstruct.exthistograms['bad{}'.format(i)] = {}\n",
    "    for histname in histstruct.histnames:\n",
    "        print('generating data for '+histname)\n",
    "        if 'good' in histstruct.masks.keys():\n",
    "            goodhists = histstruct.get_histograms( histname=histname,masknames=['dcson','highstat','good'] )\n",
    "        else:\n",
    "            goodhists = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), 15 )\n",
    "        histstruct.exthistograms['good'][histname] = gdu.upsample_hist_set( goodhists,\n",
    "                                                    figname='',ntarget=nbadruns*5e3,fourierstdfactor=20.)\n",
    "        # alternative: copy original good set (e.g. for using resampled bad but original good)\n",
    "        #histstruct.exthistograms['good'][name] = goodhists\n",
    "        for i in range(nbadruns):\n",
    "            badhists = histstruct.get_histograms( histname=histname,masknames=['dcson','highstat','bad{}'.format(i)] )\n",
    "            histstruct.exthistograms['bad{}'.format(i)][histname] = gdu.upsample_hist_set(\n",
    "                badhists,figname='',ntarget=5e3,fourierstdfactor=20.)\n",
    "            \n",
    "    mse_good_ext = []\n",
    "    mse_bad_ext = []\n",
    "    for i in range(nbadruns): mse_bad_ext.append( [] )\n",
    "\n",
    "    for histname in histstruct.histnames:\n",
    "        print('evaluating: '+histname)\n",
    "        # calculate mse for good test set\n",
    "        mse = histstruct.classifiers[histname].evaluate( histstruct.exthistograms['good'][histname] )\n",
    "        mse_good_ext.append(mse)\n",
    "        for i in range(nbadruns):\n",
    "            # calculate mse\n",
    "            mse = histstruct.classifiers[histname].evaluate( histstruct.exthistograms['bad{}'.format(i)][histname] )\n",
    "            mse_bad_ext[i].append(mse)\n",
    "    \n",
    "    # transform to arrays with correct shape\n",
    "    mse_good_ext = np.array(mse_good_ext)\n",
    "    mse_good_ext = np.transpose(mse_good_ext)\n",
    "    print('found mse array for good set of following shape: {}'.format(mse_good_ext.shape))\n",
    "    for i in range(nbadruns):\n",
    "        mse_bad_ext[i] = np.array(mse_bad_ext[i])\n",
    "        mse_bad_ext[i] = np.transpose(mse_bad_ext[i])\n",
    "        print('found mse array for bad set of following shape: {}'.format(mse_bad_ext[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (re-)define the test set\n",
    "\n",
    "use_ext = True\n",
    "\n",
    "mse_good_eval = mse_good\n",
    "mse_bad_eval = mse_bad\n",
    "if use_ext:\n",
    "    mse_good_eval = mse_good_ext\n",
    "    mse_bad_eval = mse_bad_ext\n",
    "    \n",
    "# subselect only specific bad sets for quick checking\n",
    "# note: not very clean, e.g. watch out with using nbadsets after this cell...\n",
    "#mse_bad_eval = [mse_bad_eval[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a new plot of probability contours and overlay data points\n",
    "### (only 2D projections!)\n",
    "  \n",
    "doplot = False\n",
    "\n",
    "if doplot:\n",
    "    plt.close('all')\n",
    "    colorlist = ['red','lightcoral','firebrick','chocolate','fuchsia','orange','purple']\n",
    "    if len(colorlist)<len(mse_bad_eval):\n",
    "        raise Exception('ERROR: need more colors...')\n",
    "\n",
    "    for dims,partialfitfunc in zip(dimslist,fitfunclist):\n",
    "        fig,ax = pu.plot_fit_2d(mse_train[:,dims], fitfunc=partialfitfunc, logprob=True, clipprob=True, \n",
    "                    onlycontour=True, xlims=30, ylims=30, \n",
    "                    onlypositive=True, xaxtitle=histstruct.histnames[dims[0]], \n",
    "                    yaxtitle=histstruct.histnames[dims[1]],\n",
    "                    transparency=0.5)\n",
    "        for j in range(len(mse_bad_eval)):\n",
    "            ax.plot(mse_bad_eval[j][:,dims[0]],mse_bad_eval[j][:,dims[1]],\n",
    "                '.',color=colorlist[j],markersize=4)\n",
    "        ax.plot(mse_good_eval[:,dims[0]],mse_good_eval[:,dims[1]],'.',color='blue',markersize=4)\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "# get the minimum log probability of histograms in good set\n",
    "print('--- good lumesections ---')\n",
    "logprob_good = np.log(fitfunc.pdf(mse_good_eval))\n",
    "print('length of log prob array: '+str(len(logprob_good)))\n",
    "print('minimum of log prob: '+str(np.min(logprob_good)))\n",
    "#print(sorted(logprob_good))\n",
    "print('--- bad lumisections ---')\n",
    "logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad_eval[j])) for j in range(len(mse_bad_eval))]\n",
    "#for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "print('length of log prob array: '+str(len(logprob_bad)))\n",
    "print('maximum of log prob: '+str(np.max(logprob_bad)))\n",
    "#print(sorted(logprob_good))\n",
    "#print(sorted(logprob_bad))\n",
    "#print(logprob_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a roc curve based on the test results above\n",
    "# note: smaller logprob = less probable = more outlier = more anomalous\n",
    "# so if anomalies are signal and good histograms are background, -logprob is a suitable score definition,\n",
    "# since everything above a certain threshold will be considered signal and below it background.\n",
    "\n",
    "labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "\n",
    "labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "scores = aeu.clip_scores(scores)\n",
    "\n",
    "pu.plot_score_dist(scores, labels, siglabel='anomalous', sigcolor='r', \n",
    "                   bcklabel='good', bckcolor='g', \n",
    "                   nbins=200, normalize=True,\n",
    "                   xaxtitle='negative logarithmic probability',\n",
    "                   yaxtitle='number of lumisections (normalized)')\n",
    "\n",
    "auc = aeu.get_roc(scores, labels, mode='geom', doprint=True)\n",
    "\n",
    "logprob_threshold = 65 # everything below this logprob will be considered signal (i.e. anomalous)\n",
    "aeu.get_confusion_matrix(scores,labels,-logprob_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate particular lumisections\n",
    "\n",
    "mode = 'ls'\n",
    "run = 306139\n",
    "ls = 1112 # ignored if mode is 'run'\n",
    "masknames = ['dcson','highstat'] # only used for mse distribution is mode is 'ls'\n",
    "plot_mse = True # ignored if mode is 'run'\n",
    "\n",
    "#print(histstruct.runnbs[:10])\n",
    "#print(histstruct.lsnbs[:10])\n",
    "\n",
    "# define reference histograms\n",
    "refhists = {}\n",
    "for histname in histstruct.histnames:\n",
    "    if( 'good' in histstruct.masks.keys() ): \n",
    "        #refhists[histname] = histstruct.get_histograms(masknames=['highstat','dcson','good'])\n",
    "        refhists[histname] = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['highstat','dcson','good']), 15 )\n",
    "    else: \n",
    "        refhists[histname] = hu.averagehists( histstruct.get_histograms( histname=histname, masknames=['dcson','highstat'] ), 15 )\n",
    "\n",
    "if mode=='ls':\n",
    "    # plot this particular run/ls\n",
    "    _ = histstruct.plot_ls( run, ls, recohist='auto', refhists=refhists )\n",
    "    # get mse and logprob for this run/ls\n",
    "    msepoint = histstruct.get_scores_ls( run, ls )\n",
    "    msepointarray = np.array([msepoint[histname] for histname in histstruct.histnames])\n",
    "    logprob = np.log(fitfunc.pdf(np.array([msepointarray])))\n",
    "    print('-------------')\n",
    "    print('MSE values:')\n",
    "    for histname in histstruct.histnames: print('{} : {}'.format(histname,msepoint[histname]))\n",
    "    print('-------------')\n",
    "    print('logprob: '+str(logprob))\n",
    "    msepoint = histstruct.get_scores_ls( run, ls )\n",
    "    # plot mse distribution\n",
    "    if plot_mse:\n",
    "        for histname in histnames:\n",
    "            mses = histstruct.get_scores( histname=histname, masknames=masknames )\n",
    "            nmses = len(mses)\n",
    "            labels = np.zeros(nmses)\n",
    "            mses = np.concatenate((mses,np.ones(1)*msepoint[histname]))\n",
    "            labels = np.concatenate((labels,np.ones(1)))\n",
    "            pu.plot_score_dist( mses, labels, nbins=1000, normalize=True,\n",
    "                        siglabel='this lumisection', bcklabel='all lumisections',\n",
    "                        title=histname )\n",
    "\n",
    "if mode=='run':\n",
    "    # plot given run\n",
    "    runnbs = histstruct.get_runnbs( masknames=masknames )\n",
    "    lsnbs = histstruct.get_lsnbs( masknames=masknames )\n",
    "    runsel = np.where(runnbs==run)\n",
    "    lsnbs = lsnbs[runsel]\n",
    "    print('plotting {} lumisections...'.format(len(lsnbs)))\n",
    "    for lsnb in lsnbs:\n",
    "        fig,ax = histstruct.plot_ls(run, lsnb, recohist='auto', refhists=refhists )\n",
    "        plt.show()\n",
    "        msepoint = histstruct.get_scores_ls( run, lsnb )\n",
    "        msepointarray = np.array([msepoint[histname] for histname in histstruct.histnames])\n",
    "        logprob = np.log(fitfunc.pdf(np.array([msepointarray])))\n",
    "        print('-------------')\n",
    "        print('MSE values:')\n",
    "        for histname in histstruct.histnames: print('{} : {}'.format(histname,msepoint[histname]))\n",
    "        print('-------------')\n",
    "        print('logprob: '+str(logprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate how the method performs on the golden/custom test set\n",
    "\n",
    "#evaljson = jsonu.loadjson('utils/json_pixel_good_201201.json')\n",
    "#histstruct.add_json_mask( 'pixelgood', evaljson )\n",
    "masks_eval = ['golden', 'highstat']\n",
    "lsnbs_eval = histstruct.get_lsnbs( masknames=masks_eval )\n",
    "runnbs_eval = histstruct.get_runnbs( masknames=masks_eval )\n",
    "mse_eval_dict = histstruct.get_scores( masknames=masks_eval )\n",
    "mse_eval = []\n",
    "for histname in histstruct.histnames:\n",
    "    mse_eval.append( mse_eval_dict[histname] )\n",
    "mse_eval = np.array(mse_eval)\n",
    "mse_eval = np.transpose(mse_eval)\n",
    "print('found mse array for evaluation set of following shape: {}'.format(mse_eval.shape))\n",
    "logprob_eval = np.log(fitfunc.pdf(mse_eval))\n",
    "\n",
    "def get_runsls_inrange(logprob,runnbs,lsnbs,logprob_up=None,logprob_down=None):\n",
    "    # get a list of tuples of (run number, ls number) corresponding to ls with log probability within a given range\n",
    "    # - logprob, runnbs and lsnbs are equally long 1D arrays\n",
    "    # - logprob_up and logprob_down are upper and lower thresholds\n",
    "    #     if both are not None, the lumisections with logprob between the boundaries are returned\n",
    "    #     if logprob_up is None, the lumisections with logprob > logprob_down are returned\n",
    "    #     if logprob_down is None, the lumisections with logprob < logprob_up are returned\n",
    "    indices = np.array([])\n",
    "    if logprob_down is None:\n",
    "        indices = np.nonzero(logprob<logprob_up)[0]\n",
    "    elif logprob_up is None:\n",
    "        indices = np.nonzero(logprob>logprob_down)[0]\n",
    "    else:\n",
    "        indices = np.nonzero((logprob>logprob_down) & (logprob<logprob_up))[0]\n",
    "    runsinrange = runnbs[indices]\n",
    "    lsinrange = lsnbs[indices]\n",
    "    runslsinrange = []\n",
    "    for rr,lsr in zip(runsinrange,lsinrange):\n",
    "        runslsinrange.append((int(rr),int(lsr)))\n",
    "    return {'indices':indices,'runslsinrange':runslsinrange}\n",
    "\n",
    "logup = 65\n",
    "logdown = None\n",
    "temp = get_runsls_inrange(logprob_eval, runnbs_eval, lsnbs_eval,\n",
    "                          logprob_up = logup, logprob_down = logdown)\n",
    "\n",
    "runslsinrange = temp['runslsinrange']\n",
    "print('{} out of {} LS are within these boundaries'.format(len(runslsinrange),len(logprob_eval)))\n",
    "\n",
    "# make plots\n",
    "nplotsmax = 100\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pdf = PdfPages('nmf_combine_output.pdf')\n",
    "for i,(runnb,lsnb) in enumerate(runslsinrange):\n",
    "    if i>=nplotsmax:\n",
    "        print('maximum number of plots reached')\n",
    "        break\n",
    "    print('------------------------')\n",
    "    fig,axs = histstruct.plot_ls( runnb, lsnb, recohist='auto', refhists=refhists)\n",
    "    fig.show()\n",
    "    pdf.savefig(fig)\n",
    "    # only for 2 dimensions: extra contour plot\n",
    "    #if nhisttypes != 2: continue\n",
    "    #fig,ax = plt.subplots()\n",
    "    #contourplot = ax.contourf(x, y, np.log(fitfunc.pdfgrid(pos)))\n",
    "    #plt.colorbar(contourplot)\n",
    "    #ax.plot(msepoint[0],msepoint[1],'.k',markersize=10)\n",
    "    #ax.set_xlim((0.,xlim))\n",
    "    #ax.set_ylim((0.,ylim))\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
