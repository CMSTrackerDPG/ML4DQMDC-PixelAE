{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train an autoencoder (very similar to autoencoder.ipynb) on several types of histograms and study the combined prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/utils.ipynb\n",
    "%run utils/clustering_utils.ipynb\n",
    "%run utils/autoencoder_utils.ipynb\n",
    "%run utils/ae_combine_utils.ipynb\n",
    "%run utils/generate_data_utils.ipynb\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define run properties\n",
    "# in this cell all major run properties are going to be set,\n",
    "# e.g. what runs to train on and what runs to test on\n",
    "\n",
    "# define a list of good 'reference' runs (found by eye)\n",
    "# should be replaced at some point by the reference runs defined by the DQM/DC team.\n",
    "goodrunsls = {'2017':\n",
    "              [\n",
    "                (297056,[-1]),\n",
    "                (297177,[-1]),\n",
    "                (301449,[-1]),\n",
    "              ],\n",
    "              '2018': # needs to be re-checked, not guaranteed to be full correct or representative.\n",
    "              [  (315267,[-1])]}\n",
    "\n",
    "# define core test set of clearly bad runs (found by eye)\n",
    "badrunsls = {'2017':\n",
    "                [\n",
    "                (297287,[-1]),\n",
    "                (297288,[-1]),\n",
    "                (297289,[-1]),\n",
    "                (299316,[-1]),\n",
    "                (299324,[-1]),\n",
    "                (299326,[-1]),\n",
    "                (301086,list(range(88,126))) # only bad for size_PXDisk_+1 -> maybe do not use for now (unclear what are real anomalies)\n",
    "                ],\n",
    "            '2018': # needs to be re-checked, not guaranteed to be full correct or representative.\n",
    "                [\n",
    "                #(317479,[-1]),\n",
    "                (317480,[-1]),\n",
    "                (317481,[-1]),\n",
    "                (317482,[-1]),\n",
    "                #(319847,list(range(1,35)))\n",
    "            ]}\n",
    "\n",
    "# set year to use\n",
    "year = '2017'\n",
    "\n",
    "# set histogram names to use \n",
    "histnames = [\n",
    "            'chargeInner_PXLayer_2','chargeInner_PXLayer_3',\n",
    "             'charge_PXDisk_+1','charge_PXDisk_+2','charge_PXDisk_+3',\n",
    "             'size_PXLayer_1','size_PXLayer_2','size_PXLayer_3'\n",
    "            ]\n",
    "\n",
    "# set whether to train globally or locally\n",
    "training_mode = 'local'\n",
    "\n",
    "if training_mode == 'global':\n",
    "    # train on the entire dataset (per year),\n",
    "    # define good runs for testing using averages of this entire dataset,\n",
    "    # define bad runs for testing using a fixed list of runs.\n",
    "    runsls_training = [] # use empty list for all runs\n",
    "    runsls_good = [-15] # use a negative integer for averaging instead of actual runs/ls.\n",
    "    runsls_bad = badrunsls[year]\n",
    "    print('selected runs/lumisections for training: all')\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on n runs preceding a chosen application run,\n",
    "    # define good runs for testing as the application run (NOT guaranteed, check plots!),\n",
    "    # define bad runs for testing using a fixed list of runs.\n",
    "    ntraining = 5\n",
    "    available_runs = get_runs(select_dcson(read_csv('data/DF'+year+'_'+histnames[0]+'.csv')))\n",
    "    runindex = np.random.choice(range(ntraining,len(available_runs)))\n",
    "    runsls_good = [(available_runs[runindex],[-1])]\n",
    "    runsls_training = [(el,[-1]) for el in available_runs[runindex-ntraining:runindex]]\n",
    "    runsls_bad = badrunsls[year]\n",
    "    print('selected runs/lumisections for training: ')\n",
    "    for r in runsls_training: print(r)\n",
    "    print('selected runs/lumisections for application:')\n",
    "    print(runsls_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the data based on the configuration defined above\n",
    "# todo: adapt reading and writing to new paradigm\n",
    "\n",
    "readnewtraining = True\n",
    "readnewgood = True\n",
    "readnewbad = True\n",
    "save = False\n",
    "structname = 'teststruct.pkl'\n",
    "\n",
    "if readnewtraining:\n",
    "    \n",
    "    histstruct_training = histstructure()\n",
    "    histstruct_good = histstructure()\n",
    "    histstruct_bad = histstructure()\n",
    "    print('--- reading training set ---')\n",
    "    histstruct_training.create(year,histnames,highstatonly=True,dcsononly=True,\n",
    "                               runsls=runsls_training)\n",
    "    print('found {} histograms'.format(len(histstruct_training.runnbs)))\n",
    "    \n",
    "if readnewgood:\n",
    "    \n",
    "    print('--- reading good test set ---')\n",
    "    histstruct_good.create(year,histnames,highstatonly=True,dcsononly=True,\n",
    "                           runsls=runsls_good)\n",
    "    print('found {} histograms'.format(len(histstruct_good.runnbs)))\n",
    "    # make an additional link to the same set (useful for uniformity when testing)\n",
    "    histstruct_good.custom['histograms'] = histstruct_good.histograms\n",
    "    \n",
    "if readnewbad:\n",
    "    \n",
    "    print('--- reading bad test set ---')\n",
    "    histstruct_bad.create(year,histnames,runsls=runsls_bad)\n",
    "    print('found {} histograms'.format(len(histstruct_bad.runnbs)))\n",
    "    # add a list of bad histograms split per run\n",
    "    indpr = histstruct_bad.get_perrun_indices()\n",
    "    nbadsets = len(indpr)\n",
    "    histstruct_bad.custom['histograms'] = {}\n",
    "    for name,histograms in histstruct_bad.histograms.items():\n",
    "        histstruct_bad.custom['histograms'][name] = []\n",
    "        for ind in indpr:\n",
    "            histstruct_bad.custom['histograms'][name].append( histograms[ind] )\n",
    "    print('split bad set into {} runs'.format(nbadsets))\n",
    "    \n",
    "'''if save:\n",
    "    with open(structname,'wb') as f:\n",
    "        pickle.dump(histstruct,f)\n",
    "            \n",
    "else:\n",
    "    with open(structname,'rb') as f:\n",
    "        histstruct = pickle.load(f)\n",
    "    nhists = len(histstruct.lsnbs)\n",
    "    nhisttypes = len(histstruct.names)\n",
    "    print('found {} histogram types with {} histograms each'.format(nhisttypes,nhists))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the training and/or test sets\n",
    "# especially useful if running in local mode to check if training set is relevant for targeted application run,\n",
    "# and if the application run contains anomalies\n",
    "\n",
    "if training_mode=='local':\n",
    "    \n",
    "    # training and application runs\n",
    "    fig,axs = plt.subplots(2,4,figsize=(24,12))\n",
    "    for j,name in enumerate(histstruct_training.names):\n",
    "        # (assume the histogram names are the same for training, good and bad)\n",
    "        print('making plot for '+name)\n",
    "        hists_training = histstruct_training.histograms[name]\n",
    "        hists_testing = histstruct_good.histograms[name]\n",
    "        plot_sets([hists_training,hists_testing],\n",
    "                  ax=axs[int(j/4),j%4],\n",
    "                  title=name,\n",
    "                  colorlist=['blue','green'],labellist=['training','testing'],\n",
    "                  transparencylist=[1.,1.])\n",
    "    \n",
    "    # application run and bad test runs\n",
    "    fig,axs = plt.subplots(2,4,figsize=(24,12))\n",
    "    for j,name in enumerate(histstruct_good.names):\n",
    "        # (assume the histogram names are the same for training, good and bad)\n",
    "        print('making plot for '+name)\n",
    "        hists_good = histstruct_good.histograms[name]\n",
    "        hists_bad = histstruct_bad.histograms[name]\n",
    "        plot_sets([hists_bad,hists_good],\n",
    "                  ax=axs[int(j/4),j%4],\n",
    "                  title=name,\n",
    "                  colorlist=['red','green'],labellist=['bad','testing'],\n",
    "                  transparencylist=[1.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the training set using artificial data\n",
    "\n",
    "extendtraining = True\n",
    "\n",
    "histstruct_training.custom['histograms_ext'] = {}\n",
    "\n",
    "if extendtraining:\n",
    "    for (name,hists) in histstruct_training.histograms.items():\n",
    "        print('generating artificial training data for '+name)\n",
    "        histstruct_training.custom['histograms_ext'][name] = upsample_hist_set(hists,5e4)\n",
    "else:\n",
    "    histstruct_training.custom['histograms_ext'] = histstruct_training.histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and train an autoencoder for each element\n",
    "from keras.models import load_model\n",
    "\n",
    "trainnew = True\n",
    "savemodels = False\n",
    "modelname_extension = 'dcson_five_runs' # ignored if savemodels is False\n",
    "histstruct_training.custom['models'] = {}\n",
    "histstruct_good.custom['models'] = {}\n",
    "histstruct_bad.custom['models'] = {}\n",
    "if trainnew:\n",
    "    for (name,hists) in histstruct_training.custom['histograms_ext'].items():\n",
    "        modelname=name+'_'+modelname_extension\n",
    "        if not savemodels: modelname = '' # empty string means do not save models\n",
    "        #nepochs = -1 # automatic number of epochs\n",
    "        nepochs = 40 # manual number of epochs\n",
    "        # modify training parameters depending on type of histogram\n",
    "        #if 'chargeInner_PXLayer_2' in name:\n",
    "            # increased statistics threshold\n",
    "            #hists = hists[np.where( histstruct.entries_all[name]/len(hists[0]) > 1000 )]\n",
    "        model = train_simple_autoencoder(hists,nepochs=nepochs,modelname=modelname)\n",
    "        histstruct_training.custom['models'][name] = model\n",
    "        histstruct_good.custom['models'][name] = model\n",
    "        histstruct_bad.custom['models'][name] = model\n",
    "else:\n",
    "    for name in histstruct_training.names:\n",
    "        print('loading model for '+name)\n",
    "        # note: for now use 2017 models for 2018 data as well (to check behaviour on unseen data)\n",
    "        model_name = name.replace('data','models')+'_'+modelname_extension+'.h5'\n",
    "        #model_name = model_name.replace('2018','2017')\n",
    "        model = load_model(model_name,custom_objects={'mseTop10': mseTop10})\n",
    "        histstruct_training.custom['models'][name] = model\n",
    "        histstruct_good.custom['models'][name] = model\n",
    "        histstruct_bad.custom['models'][name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the models on the (non-extended) training set\n",
    "\n",
    "histstruct_training.custom['mse_histograms'] = {}\n",
    "for (name,hists) in histstruct_training.histograms.items():\n",
    "    print('evaluating model for '+name)\n",
    "    pred = histstruct_training.custom['models'][name].predict(hists)\n",
    "    #mse = K.eval(mseTop10(hists,pred))\n",
    "    mse = mseTop10Raw(hists,pred)\n",
    "    histstruct_training.custom['mse_histograms'][name] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the multidemensional mse and fit a log-normal distribution\n",
    "import matplotlib as mpl\n",
    "\n",
    "fitnew = True    # fit new distribution or load previously saved one\n",
    "savefit = False  # save the new fit or not\n",
    "valkey = 'mse_histograms' # perform fit on (non-extended) training set\n",
    "\n",
    "dimslist = []\n",
    "fitfunclist = []\n",
    "nhisttypes = len(histstruct_training.names)\n",
    "for i in range(0,nhisttypes-1):\n",
    "    for j in range(i+1,nhisttypes):\n",
    "        dimslist.append((i,j))\n",
    "\n",
    "plt.close('all')\n",
    "for dims in dimslist:\n",
    "   \n",
    "    fitfunc = fitseminormal(histstruct_training,valkey,dims,fitnew=fitnew,savefit=savefit)\n",
    "    #fitfunc = fitgaussiankde(histstruct_training,valkey,dims,maxnpoints=10000)\n",
    "    plotfit2d(histstruct_training,valkey,dims,fitfunc,doinitialplot=True)\n",
    "    #plt.close('all') # release plot memory\n",
    "    fitfunclist.append(fitfunc)\n",
    "    \n",
    "# do a total fit\n",
    "if fitnew:\n",
    "    fitfunc = seminormal( get_mse_array(histstruct_training,valkey) )\n",
    "    #fitfunc = fitgaussiankde(histstruct_training,valkey,maxnpoints=10000)\n",
    "    if savefit: fitfunc.save('seminormal_fit_2017_8dim.npy')\n",
    "else:\n",
    "    fitfunc = seminormal()\n",
    "    fitfunc.load('seminormal_fit_2017_8dim.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the test set using artificial data generation\n",
    "\n",
    "skipthiscell = False # to prevent running this cell by accident\n",
    "\n",
    "if not skipthiscell:\n",
    "    \n",
    "    histstruct_good.custom['histograms_ext'] = {}\n",
    "    histstruct_bad.custom['histograms_ext'] = {}\n",
    "    for name in histstruct_training.names:\n",
    "        print('generating data for '+name)\n",
    "        histstruct_good.custom['histograms_ext'][name] = upsample_hist_set(histstruct_good.histograms[name],\n",
    "                                                            figname='',ntarget=nbadsets*4e3,fourierstdfactor=20.)\n",
    "        histstruct_bad.custom['histograms_ext'][name] = []\n",
    "        for badset in histstruct_bad.custom['histograms'][name]:\n",
    "            histstruct_bad.custom['histograms_ext'][name].append(upsample_hist_set(badset,\n",
    "                                                                              figname='',ntarget=4e3,\n",
    "                                                                              fourierstdfactor=20.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the model on the (potentially extended) test set\n",
    "\n",
    "use_ext = False\n",
    "# (whether to calculate the mse on the extended datasets)\n",
    "# (note that in any case the mse will (also) be calculated on the original sets and stored in the histstructs)\n",
    "\n",
    "key = 'histograms'\n",
    "if use_ext:\n",
    "    key = key + '_ext'\n",
    "mse_good = np.zeros((len(histstruct_good.custom[key][histstruct_good.names[0]]),nhisttypes))\n",
    "mse_bad = [np.zeros((len(histstruct_bad.custom[key][histstruct_bad.names[0]][j]),nhisttypes)) for j in range(nbadsets)]\n",
    "\n",
    "histstruct_good.custom['mse_'+key] = {}\n",
    "histstruct_bad.custom['mse_'+key] = {}\n",
    "if use_ext:\n",
    "    histstruct_good.custom['mse_histograms'] = {}\n",
    "    histstruct_bad.custom['mse_histograms'] = {}\n",
    "for i,name in enumerate(histstruct_training.names):\n",
    "    print('evaluating: '+name)\n",
    "    mse_good[:,i] = mseTopNRaw(histstruct_good.custom[key][name],histstruct_training.custom['models'][name].predict(histstruct_good.custom[key][name]), n=10)\n",
    "    histstruct_good.custom['mse_'+key][name] = mse_good[:,i]\n",
    "    if use_ext:\n",
    "        histstruct_good.custom['mse_histograms'][name] = mseTopNRaw(histstruct_good.custom['histograms'][name],histstruct_training.custom['models'][name].predict(histstruct_good.custom['histograms'][name]), n=10)\n",
    "    histstruct_bad.custom['mse_'+key][name] = []\n",
    "    if use_ext: histstruct_bad.custom['mse_histograms'][name] = []\n",
    "    for j in range(nbadsets):\n",
    "        mse_bad[j][:,i] = mseTopNRaw(histstruct_bad.custom[key][name][j],histstruct_training.custom['models'][name].predict(histstruct_bad.custom[key][name][j]), n=10)\n",
    "        histstruct_bad.custom['mse_'+key][name].append(mse_bad[j][:,i])\n",
    "        if use_ext: \n",
    "            histstruct_bad.custom['mse_histograms'][name].append( mseTopNRaw(histstruct_bad.custom['histograms'][name][j],histstruct_training.custom['models'][name].predict(histstruct_bad.custom['histograms'][name][j]), n=10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a new plot of probability contours and overlay data points\n",
    "### (only 2D projections!)\n",
    "\n",
    "plt.close('all')\n",
    "colorlist = ['red','lightcoral','firebrick','chocolate','fuchsia','orange','purple']\n",
    "#colorlist = ['red']*nbadsets\n",
    "if len(colorlist)<nbadsets:\n",
    "    print('### ERROR ###: need more colors...')\n",
    "\n",
    "for dims,partialfitfunc in zip(dimslist,fitfunclist):\n",
    "    fig,ax = plotfit2d(histstruct_training,'mse_histograms',dims,partialfitfunc,doinitialplot=False,onlycontour=True,rangestd=50)\n",
    "    for j in range(len(mse_bad)): ax.plot(mse_bad[j][:,dims[0]],mse_bad[j][:,dims[1]],'.',color=colorlist[j],markersize=4)\n",
    "    ax.plot(mse_good[:,dims[0]],mse_good[:,dims[1]],'.b',markersize=4)\n",
    "\n",
    "# get the minimum log probability of histograms in good set\n",
    "print('--- good lumesections ---')\n",
    "logprob_good = np.log(fitfunc.pdf(mse_good))\n",
    "print('length of log prob array: '+str(len(logprob_good)))\n",
    "print('minimum of log prob: '+str(np.min(logprob_good)))\n",
    "#print(sorted(logprob_good))\n",
    "print('--- bad lumisections ---')\n",
    "logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad[j])) for j in range(len(mse_bad))]\n",
    "#for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "print('length of log prob array: '+str(len(logprob_bad)))\n",
    "print('maximum of log prob: '+str(np.max(logprob_bad)))\n",
    "#print(sorted(logprob_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a roc curve based on the test results above\n",
    "# note: smaller logprob = less probable = more outlier = more anomalous\n",
    "# so if anomalies are signal and good histograms are background, -logprob is a suitable score definition,\n",
    "# since everything above a certain threshold will be considered signal and below it background.\n",
    "\n",
    "labels_good = np.zeros(len(logprob_good)) # background: label = 0\n",
    "labels_bad = np.ones(len(logprob_bad)) # signal: label = 1\n",
    "\n",
    "labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "maxnoninf = np.max(np.where(scores==np.inf,np.min(scores),scores)) + 1\n",
    "scores = np.where(scores==np.inf,maxnoninf,scores)\n",
    "print('logprobs of -inf were reset to {}'.format(-maxnoninf))\n",
    "\n",
    "auc = get_roc(scores,labels)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "logprob_threshold = 84 # everything below this logprob will be considered signal (i.e. anomalous)\n",
    "get_confusion_matrix(scores,labels,-logprob_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate particular lumisections: functionality\n",
    "\n",
    "def plotlsreco(histstruct, run, ls, histstruct_ref, doprint=False):\n",
    "    # plot the histograms for a given run/ls number with their reconstruction\n",
    "    msepoint = []\n",
    "    fig,axs = plt.subplots(2,4,figsize=(24,12))\n",
    "    # find index that given run and ls number correspond to\n",
    "    index = (set(list(np.where(histstruct.runnbs==run)[0])) & set(list(np.where(histstruct.lsnbs==ls)[0])))\n",
    "    if len(index)!=1: \n",
    "        print('index has unexpected shape: '+str(index))\n",
    "        return\n",
    "    (index,) = index\n",
    "    # loop over all histograms belonging to this lumisection and make the plots\n",
    "    for j,name in enumerate(histstruct.names):\n",
    "        hist = histstruct.histograms[name][index:index+1,:]\n",
    "        reco = histstruct.custom['models'][name].predict(hist)\n",
    "        mse = mseTop10Raw(hist,reco)[0]\n",
    "        msepoint.append(mse)\n",
    "        plot_sets([histstruct_ref.histograms[name],hist,reco],\n",
    "                  ax=axs[int(j/4),j%4],\n",
    "                  title=name,\n",
    "                  colorlist=['blue','black','red'],labellist=['good hists','hist (run: '+str(int(run))+', ls: '+str(int(ls))+')','reco'],\n",
    "                  transparencylist=[0.3,1.,1.])\n",
    "        # additional prints\n",
    "        if doprint:\n",
    "            print('mse (this histogram): '+str(mse))\n",
    "            print('mse (average good): '+str(np.average(histstruct_ref.custom['mse_histograms'][name])))\n",
    "    return {'msepoint':msepoint,'figure':fig}\n",
    "\n",
    "def plotrunreco(histstruct, run, histstruct_ref, doprint=False):\n",
    "    # call plotlsreco for all ls in a given run\n",
    "    lsnbs = histstruct.lsnbs[np.where(histstruct.runnbs==run)]\n",
    "    print('plotting {} lumisections...'.format(len(lsnbs)))\n",
    "    for lsnb in lsnbs:\n",
    "        _ = plotlsreco(histstruct,run,lsnb,histstruct_ref,doprint=doprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate particular lumisections: calling\n",
    "\n",
    "run = 300674\n",
    "ls = 1\n",
    "mode = 'ls'\n",
    "histstruct_eval = histstruct_good\n",
    "# (choose histstruct_good or histstruct_training, depending on what you want to investigate)\n",
    "\n",
    "print(histstruct_good.runnbs[:10])\n",
    "print(histstruct_good.lsnbs[:10])\n",
    "\n",
    "if mode=='ls':\n",
    "    # plot this particular run/ls\n",
    "    temp = plotlsreco(histstruct_eval,run,ls,histstruct_good,doprint=True)\n",
    "    msepoint = temp['msepoint']\n",
    "    logprob = np.log(fitfunc.pdf(np.array([msepoint])))\n",
    "    print('logprob: '+str(logprob))\n",
    "\n",
    "if mode=='run':\n",
    "    # plot given run\n",
    "    plotrunreco(histstruct_eval,run,histstruct_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the method on the golden json\n",
    "\n",
    "histstruct_eval = histstruct_good\n",
    "# (note: use either histstruct_good or histstruct_training\n",
    "# when training on the entire dataset, the latter is informative (the former will not even work if using templates)\n",
    "# when training on a subset, the target run, i.e. histstruct_good is more informative)\n",
    "\n",
    "mse_test_golden = np.zeros((len(histstruct_eval.get_golden_indices()),len(histstruct_eval.names)))\n",
    "for i,name in enumerate(histstruct_eval.names):\n",
    "    print('evaluating: '+name)\n",
    "    mse_test_golden[:,i] = histstruct_eval.custom['mse_histograms'][name][histstruct_eval.get_golden_mask()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate how the method performs on golden json data (useful if not using golden json for training)\n",
    "\n",
    "print('evaluating pdf on mse points')\n",
    "logprob_test_golden = np.log(fitfunc.pdf(mse_test_golden))\n",
    "\n",
    "def get_runsls_inrange(logprob,runnbs,lsnbs,logprob_up=None,logprob_down=None):\n",
    "    # get a list of tuples of (run number, ls number) corresponding to ls with log probability within a given range\n",
    "    # - logprob, runnbs and lsnbs are equally long 1D arrays\n",
    "    # - logprob_up and logprob_down are upper and lower thresholds\n",
    "    #     if both are not None, the lumisections with logprob between the boundaries are returned\n",
    "    #     if logprob_up is None, the lumisections with logprob > logprob_down are returned\n",
    "    #     if logprob_down is None, the lumisections with logprob < logprob_up are returned\n",
    "    indices = np.array([])\n",
    "    if logprob_down is None:\n",
    "        indices = np.nonzero(logprob<logprob_up)[0]\n",
    "    elif logprob_up is None:\n",
    "        indices = np.nonzero(logprob>logprob_down)[0]\n",
    "    else:\n",
    "        indices = np.nonzero((logprob>logprob_down) & (logprob<logprob_up))[0]\n",
    "    runsinrange = runnbs[indices]\n",
    "    lsinrange = lsnbs[indices]\n",
    "    runslsinrange = []\n",
    "    for rr,lsr in zip(runsinrange,lsinrange):\n",
    "        runslsinrange.append((int(rr),int(lsr)))\n",
    "    return {'indices':indices,'runslsinrange':runslsinrange}\n",
    "\n",
    "logup = None\n",
    "logdown = 84\n",
    "temp = get_runsls_inrange(logprob_test_golden, histstruct_eval.runnbs[histstruct_eval.get_golden_mask()], histstruct_eval.lsnbs[histstruct_eval.get_golden_mask()],\n",
    "                          logprob_up = logup, logprob_down = logdown)\n",
    "\n",
    "runslsinrange = temp['runslsinrange']\n",
    "print('{} out of {} LS are within these boundaries'.format(len(runslsinrange),len(logprob_test_golden)))\n",
    "\n",
    "# make plots\n",
    "nplotsmax = 1\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pdf = PdfPages('test.pdf')\n",
    "for i,(runnb,lsnb) in enumerate(runslsinrange):\n",
    "    if i>=nplotsmax:\n",
    "        print('maximum number of plots reached')\n",
    "        break\n",
    "    print('------------------------')\n",
    "    temp = plotlsreco(histstruct_eval,runnb,lsnb,histstruct_good)\n",
    "    msepoint = temp['msepoint']\n",
    "    fig = temp['figure']\n",
    "    fig.show()\n",
    "    pdf.savefig(fig)\n",
    "    # only for 2 dimensions: extra contour plot\n",
    "    #if nhisttypes != 2: continue\n",
    "    #fig,ax = plt.subplots()\n",
    "    #contourplot = ax.contourf(x, y, np.log(fitfunc.pdfgrid(pos)))\n",
    "    #plt.colorbar(contourplot)\n",
    "    #ax.plot(msepoint[0],msepoint[1],'.k',markersize=10)\n",
    "    #ax.set_xlim((0.,xlim))\n",
    "    #ax.set_ylim((0.,ylim))\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate other 'pathological' histograms in the training set\n",
    "# deprecated, not used anymore and not guaranteed to work anymore...\n",
    "\n",
    "logprob_train = np.log(fitfunc.pdf(mse_train))\n",
    "print('Minimum log prob value in training set: '+str(np.min(logprob_train)))\n",
    "logupboundary = 0\n",
    "loglowboundary = 71 # if larger than logupboundary, no lower boundary\n",
    "if loglowboundary > logupboundary:\n",
    "    indices = np.nonzero(logprob_train<logupboundary)[0]\n",
    "else:\n",
    "    indices = np.nonzero((logprob_train>loglowboundary) & (logprob_train<logupboundary))[0]\n",
    "nout = len(indices)\n",
    "print(str(nout)+' out of '+str(mse_train.shape[0])+' histograms are within these boundary.')\n",
    "\n",
    "# make list of run and ls numbers\n",
    "badruns = histstruct[0]['runnbs_train'][indices]\n",
    "badls = histstruct[0]['lsnbs_train'][indices]\n",
    "badrunsls = []\n",
    "for br,bls in zip(badruns,badls):\n",
    "    badrunsls.append((int(br),int(bls)))\n",
    "print(badrunsls)\n",
    "\n",
    "# make plots\n",
    "nplotsmax = 20\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pdf = PdfPages('test.pdf')\n",
    "#np.random.shuffle(indices)\n",
    "for i,index in enumerate(indices):\n",
    "    if i>=nplotsmax:\n",
    "        print('maximum number of plots reached')\n",
    "        break\n",
    "    print('------------------------')\n",
    "    msepoint = []\n",
    "    fig,axs = plt.subplots(2,4,figsize=(24,12))\n",
    "    for name in histstruct['names']:\n",
    "        hist = histstruct['hists_all'][name][index:index+1,:]\n",
    "        reco = histstruct['models'][name].predict(hist)\n",
    "        mse = histstruct['mse_train'][name][index]\n",
    "        runnb = histstruct[j]['runnbs_all'][index]\n",
    "        lsnb = histstruct[j]['lsnbs_all'][index]\n",
    "        msepoint.append(mse)\n",
    "        #fig,ax = plt.subplots()\n",
    "        CheckPredictions(hist[0],reco[0],mse,0,0,histstruct[j]['name']) \n",
    "        #plot_sets([hist,reco,histstruct[j]['X_test_good']],\n",
    "        #          ax=axs[int(j/4),j%4],\n",
    "        #          title=histstruct[j]['name'],\n",
    "        #          colorlist=['black','red','blue'],labellist=['hist (run: '+str(int(runnb))+', ls: '+str(int(lsnb))+')','reco','good hists'],\n",
    "        #          transparencylist=[1.,1.,0.3])\n",
    "        # additional prints\n",
    "        #print('mse (this histogram): '+str(mse))\n",
    "        #print('mse (average good): '+str(np.average(histstruct[j]['mse_test_good'])))\n",
    "    #fig.show()\n",
    "    pdf.savefig(fig)\n",
    "    # only for 2 dimensions: extra contour plot\n",
    "    if nhisttypes != 2: continue\n",
    "    fig,ax = plt.subplots()\n",
    "    contourplot = ax.contourf(x, y, np.log(fitfunc.pdfgrid(pos)))\n",
    "    plt.colorbar(contourplot)\n",
    "    ax.plot(msepoint[0],msepoint[1],'.k',markersize=10)\n",
    "    ax.set_xlim((0.,xlim))\n",
    "    ax.set_ylim((0.,ylim))\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
