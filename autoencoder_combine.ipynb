{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train an autoencoder (very similar to autoencoder.ipynb) on several types of histograms and study the combined prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/utils.ipynb\n",
    "%run utils/clustering_utils.ipynb\n",
    "%run utils/autoencoder_utils.ipynb\n",
    "%run utils/ae_combine_utils.ipynb\n",
    "%run utils/generate_data_utils.ipynb\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the data\n",
    "\n",
    "readnew = True\n",
    "save = False\n",
    "structname = 'teststruct.pkl'\n",
    "\n",
    "if readnew:\n",
    "    \n",
    "    year = '2017'\n",
    "    histnames = [\n",
    "            'chargeInner_PXLayer_2','chargeInner_PXLayer_3',\n",
    "             'charge_PXDisk_+1','charge_PXDisk_+2','charge_PXDisk_+3',\n",
    "             'size_PXLayer_1','size_PXLayer_2','size_PXLayer_3'\n",
    "            ]\n",
    "        \n",
    "    #selected_runs = [] # empty list means keeping all runs\n",
    "    selected_runs = get_runs(read_csv('data/DF'+year+'_'+histnames[0]+'.csv'))[0:5]\n",
    "    if len(selected_runs) < 50: print('selected runs: '+str(selected_runs))\n",
    "    \n",
    "    histstruct = histstructure()\n",
    "    histstruct.create(year,histnames,highstat=True,runs=selected_runs)\n",
    "    \n",
    "    nhists = len(histstruct.lsnbs)\n",
    "    nhisttypes = len(histstruct.names)\n",
    "    print('found {} histogram types with {} histograms each'.format(nhisttypes,nhists))\n",
    "    \n",
    "    if save:\n",
    "        with open(structname,'wb') as f:\n",
    "            pickle.dump(histstruct,f)\n",
    "            \n",
    "else:\n",
    "    with open(structname,'rb') as f:\n",
    "        histstruct = pickle.load(f)\n",
    "    nhists = len(histstruct.lsnbs)\n",
    "    nhisttypes = len(histstruct.names)\n",
    "    print('found {} histogram types with {} histograms each'.format(nhisttypes,nhists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the training set using artificial data\n",
    "\n",
    "extendtraining = True\n",
    "\n",
    "histstruct.custom['hists_train'] = {}\n",
    "\n",
    "if extendtraining:\n",
    "    for (name,hists) in histstruct.histograms.items():\n",
    "        print('generating artificial training data for '+name)\n",
    "        histstruct.custom['hists_train'][name] = upsample_hist_set(hists,1e4)\n",
    "else:\n",
    "    histstruct.custom['hists_train'] = histstruct.hists_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define and train an autoencoder for each element\n",
    "from keras.models import load_model\n",
    "\n",
    "trainnew = True\n",
    "savemodels = False\n",
    "modelname_extension = 'dcson_five_runs' # ignored if savemodels is False\n",
    "histstruct.custom['models'] = {}\n",
    "if trainnew:\n",
    "    for (name,hists) in histstruct.custom['hists_train'].items():\n",
    "        modelname=name+'_'+modelname_extension\n",
    "        if not savemodels: modelname = '' # empty string means do not save models\n",
    "        #nepochs = -1 # automatic number of epochs\n",
    "        nepochs = 40 # manual number of epochs\n",
    "        # modify training parameters depending on type of histogram\n",
    "        #if 'chargeInner_PXLayer_2' in name:\n",
    "            # increased statistics threshold\n",
    "            #hists = hists[np.where( histstruct.entries_all[name]/len(hists[0]) > 1000 )]\n",
    "        model = train_simple_autoencoder(hists,nepochs=nepochs,modelname=modelname)\n",
    "        histstruct.custom['models'][name] = model\n",
    "else:\n",
    "    for name in histstruct.names:\n",
    "        print('loading model for '+name)\n",
    "        # note: for now use 2017 models for 2018 data as well (to check behaviour on unseen data)\n",
    "        model_name = 'models/'+name+'_'+modelname_extension+'.h5'\n",
    "        #model_name = model_name.replace('2018','2017')\n",
    "        histstruct.custom['models'][name] = load_model(model_name,custom_objects={'mseTop10': mseTop10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the models on the original set\n",
    "\n",
    "histstruct.custom['mse_histograms'] = {}\n",
    "for (name,hists) in histstruct.histograms.items():\n",
    "    print('evaluating model for '+name)\n",
    "    pred = histstruct.custom['models'][name].predict(hists)\n",
    "    #mse = K.eval(mseTop10(hists,pred))\n",
    "    mse = mseTop10Raw(hists,pred)\n",
    "    histstruct.custom['mse_histograms'][name] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the multidemensional mse and fit a log-normal distribution\n",
    "import matplotlib as mpl\n",
    "\n",
    "fitnew = True    # fit new distribution or load previously saved one\n",
    "savefit = False  # save the new fit or not\n",
    "valkey = 'mse_histograms' # perform fit on (non-extended) training set\n",
    "\n",
    "dimslist = []\n",
    "fitfunclist = []\n",
    "for i in range(0,nhisttypes-1):\n",
    "    for j in range(i+1,nhisttypes):\n",
    "        dimslist.append((i,j))\n",
    "\n",
    "plt.close('all')\n",
    "for dims in dimslist:\n",
    "   \n",
    "    fitfunc = fitseminormal(histstruct,valkey,dims,fitnew=fitnew,savefit=savefit)\n",
    "    #fitfunc = fitgaussiankde(histstruct,valkey,dims,maxnpoints=10000)\n",
    "    plotfit2d(histstruct,valkey,dims,fitfunc,doinitialplot=True)\n",
    "    #plt.close('all') # release plot memory\n",
    "    fitfunclist.append(fitfunc)\n",
    "    \n",
    "# do a total fit\n",
    "if fitnew:\n",
    "    fitfunc = seminormal( get_mse_array(histstruct,valkey) )\n",
    "    #fitfunc = fitgaussiankde(histstruct,valkey,maxnpoints=10000)\n",
    "    if savefit: fitfunc.save('seminormal_fit_2017_8dim.npy')\n",
    "else:\n",
    "    fitfunc = seminormal()\n",
    "    fitfunc.load('seminormal_fit_2017_8dim.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get a test set\n",
    "\n",
    "goodrunsls = {'2017':\n",
    "              [\n",
    "                (297056,[-1]),\n",
    "                # later added these as well for more representative set\n",
    "                #(297177,[-1]),\n",
    "                #(301449,[-1])\n",
    "              ],\n",
    "              '2018':\n",
    "              [  (315267,[-1])]} \n",
    "# if training on full dataset, better use averaging method (see below)\n",
    "\n",
    "# core test set of clearly bad runs\n",
    "badrunsls = {'2017':\n",
    "                [\n",
    "                (297287,[-1]),\n",
    "                (297288,[-1]),\n",
    "                (297289,[-1]),\n",
    "                (299316,[-1]),\n",
    "                (299324,[-1]),\n",
    "                (299326,[-1]),\n",
    "                (301086,list(range(88,126))) # only bad for size_PXDisk_+1 -> do not use for now (unclear what are real anomalies)\n",
    "                ],\n",
    "            '2018':\n",
    "                [\n",
    "                #(317479,[-1]),\n",
    "                (317480,[-1]),\n",
    "                (317481,[-1]),\n",
    "                (317482,[-1]),\n",
    "                #(319847,list(range(1,35)))\n",
    "            ]}\n",
    "\n",
    "histstruct.custom['hists_test_good'] = {}\n",
    "histstruct.custom['hists_test_bad'] = {}\n",
    "for (name,hists) in histstruct.histograms.items():\n",
    "    print('retrieving good and bad test set for '+name)\n",
    "    df = read_csv(name+'.csv')\n",
    "    year = '2017' if '2017' in name else '2018'\n",
    "    # get good test set from predefined run and ls numbers\n",
    "    (ghists,runnbs,lsnbs) = preparedatafromdf(select_runsls(df,goodrunsls[year]),returnrunls=True,onlygolden=True)\n",
    "    # alternative: get good test set from averaging all histograms\n",
    "    #ntemplates = 15\n",
    "    #ghists = np.zeros((ntemplates,hists.shape[1]))\n",
    "    #nsub = int(len(hists)/ntemplates)\n",
    "    #for i in range(ntemplates):\n",
    "    #    startindex = i*nsub\n",
    "    #    stopindex = (i+1)*nsub\n",
    "    #    ghists[i,:] = np.mean(hists[startindex:stopindex,:],axis=0)\n",
    "    histstruct.custom['hists_test_good'][name] = ghists\n",
    "    # list of separate test sets per run (allows for better visualization)\n",
    "    histstruct.custom['hists_test_bad'][name] = []\n",
    "    for badrun in badrunsls[year]:\n",
    "        (bhists,runnbs,lsnbs) = preparedatafromdf(select_runsls(df,[badrun]),returnrunls=True)\n",
    "        histstruct.custom['hists_test_bad'][name].append(bhists)\n",
    "    nbadsets = len(badrunsls[year])\n",
    "    # alternative version: one set of all bad runs together\n",
    "    #(bhists,runnbs,lsnbs) = preparedatafromdf(select_runsls(df,badrunsls))\n",
    "    #histdict.custom['hists_test_bad'][name] = bhists\n",
    "    #nbadsets = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extend the test set using artificial data generation\n",
    "\n",
    "skipthiscell = False # to prevent running this cell by accident\n",
    "\n",
    "if not skipthiscell:\n",
    "\n",
    "    histstruct.custom['hists_test_good_ext'] = {}\n",
    "    histstruct.custom['hists_test_bad_ext'] = {}\n",
    "    for name in histstruct.names:\n",
    "        print('generating data for '+name)\n",
    "        histstruct.custom['hists_test_good_ext'][name] = upsample_hist_set(histstruct.custom['hists_test_good'][name],\n",
    "                                                            figname='',ntarget=nbadsets*4e3,fourierstdfactor=20.)\n",
    "        histstruct.custom['hists_test_bad_ext'][name] = []\n",
    "        for badset in histstruct.custom['hists_test_bad'][name]:\n",
    "            histstruct.custom['hists_test_bad_ext'][name].append(upsample_hist_set(badset,figname='f',ntarget=4e3,\n",
    "                                                              fourierstdfactor=20.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the model on the test set\n",
    "\n",
    "use_ext = True\n",
    "\n",
    "xgood = 'hists_test_good'\n",
    "xbad = 'hists_test_bad'\n",
    "if use_ext:\n",
    "    xgood = xgood + '_ext'\n",
    "    xbad = xbad + '_ext'\n",
    "mse_good = np.zeros((len(histstruct.custom[xgood][histstruct.names[0]]),nhisttypes))\n",
    "mse_bad = [np.zeros((len(histstruct.custom[xbad][histstruct.names[0]][j]),nhisttypes)) for j in range(nbadsets)]\n",
    "histstruct.custom['mse_test_good'] = {}\n",
    "histstruct.custom['mse_test_bad'] = {}\n",
    "for i,name in enumerate(histstruct.names):\n",
    "    print('evaluating: '+name)\n",
    "    mse_good[:,i] = mseTopNRaw(histstruct.custom[xgood][name],histstruct.custom['models'][name].predict(histstruct.custom[xgood][name]), n=10)\n",
    "    histstruct.custom['mse_test_good'][name] = mse_good[:,i]\n",
    "    histstruct.custom['mse_test_bad'][name] = []\n",
    "    for j in range(nbadsets):\n",
    "        mse_bad[j][:,i] = mseTopNRaw(histstruct.custom[xbad][name][j],histstruct.custom['models'][name].predict(histstruct.custom[xbad][name][j]), n=10)\n",
    "        histstruct.custom['mse_test_bad'][name].append(mse_bad[j][:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a new plot of probability contours and overlay data points\n",
    "### (only 2D projections!)\n",
    "\n",
    "plt.close('all')\n",
    "colorlist = ['red','lightcoral','firebrick','chocolate','fuchsia','orange','purple']\n",
    "#colorlist = ['red']*nbadsets\n",
    "if len(colorlist)<nbadsets:\n",
    "    print('### ERROR ###: need more colors...')\n",
    "\n",
    "for dims,partialfitfunc in zip(dimslist,fitfunclist):\n",
    "    fig,ax = plotfit2d(histstruct,'mse_histograms',dims,partialfitfunc,doinitialplot=False,onlycontour=True,rangestd=50)\n",
    "    for j in range(len(mse_bad)): ax.plot(mse_bad[j][:,dims[0]],mse_bad[j][:,dims[1]],'.',color=colorlist[j],markersize=4)\n",
    "    ax.plot(mse_good[:,dims[0]],mse_good[:,dims[1]],'.b',markersize=4)\n",
    "\n",
    "# get the minimum log probability of histograms in good set\n",
    "print('--- good lumesections ---')\n",
    "logprob_good = np.log(fitfunc.pdf(mse_good))\n",
    "print('length of log prob array: '+str(len(logprob_good)))\n",
    "print('minimum of log prob: '+str(np.min(logprob_good)))\n",
    "#print(sorted(logprob_good))\n",
    "print('--- bad lumisections ---')\n",
    "logprob_bad_parts = [np.log(fitfunc.pdf(mse_bad[j])) for j in range(len(mse_bad))]\n",
    "#for lp in logprob_bad_parts: print(str(sorted(lp))+'\\n\\n')\n",
    "logprob_bad = np.concatenate(tuple(logprob_bad_parts))\n",
    "print('length of log prob array: '+str(len(logprob_bad)))\n",
    "print('maximum of log prob: '+str(np.max(logprob_bad)))\n",
    "#print(sorted(logprob_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a roc curve based on the test results above\n",
    "\n",
    "labels_good = np.zeros(len(logprob_good))\n",
    "labels_bad = np.ones(len(logprob_bad))\n",
    "\n",
    "labels = np.concatenate(tuple([labels_good,labels_bad]))\n",
    "scores = np.concatenate(tuple([-logprob_good,-logprob_bad]))\n",
    "maxnoninf = np.max(np.where(scores==np.inf,np.min(scores),scores))\n",
    "scores = np.where(scores==np.inf,maxnoninf,scores)\n",
    "\n",
    "auc = get_roc(scores,labels)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "get_confusion_matrix(scores,labels,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate particular lumisections: functionality\n",
    "\n",
    "def plotlsreco(histstruct, run, ls, doprint=False):\n",
    "    # plot the histograms for a given run/ls number with their reconstruction\n",
    "    msepoint = []\n",
    "    fig,axs = plt.subplots(2,4,figsize=(24,12))\n",
    "    # find index that given run and ls number correspond to\n",
    "    index = (set(list(np.where(histstruct.runnbs==run)[0])) & set(list(np.where(histstruct.lsnbs==ls)[0])))\n",
    "    if len(index)!=1: \n",
    "        print('index has unexpected shape: '+str(index))\n",
    "        return\n",
    "    (index,) = index\n",
    "    # determine the indices of the 'reference' histograms to be plotted as baseline\n",
    "    refhistindices = np.arange( len(histstruct.custom['hists_test_good'][histstruct.names[0]]) )\n",
    "    np.random.shuffle(refhistindices)\n",
    "    refhistindices = refhistindices[:20]\n",
    "    # loop over all histograms belongingto this lumisection and make the plots\n",
    "    for j,name in enumerate(histstruct.names):\n",
    "        hist = histstruct.histograms[name][index:index+1,:]\n",
    "        reco = histstruct.custom['models'][name].predict(hist)\n",
    "        mse = mseTop10Raw(hist,reco)[0]\n",
    "        msepoint.append(mse)\n",
    "        plot_sets([hist,reco,histstruct.custom['hists_test_good'][name][refhistindices]],\n",
    "                  ax=axs[int(j/4),j%4],\n",
    "                  title=name,\n",
    "                  colorlist=['black','red','blue'],labellist=['hist (run: '+str(int(run))+', ls: '+str(int(ls))+')','reco','good hists'],\n",
    "                  transparencylist=[1.,1.,0.3])\n",
    "        # additional prints\n",
    "        if doprint:\n",
    "            print('mse (this histogram): '+str(mse))\n",
    "            print('mse (average good): '+str(np.average(histstruct.custom['mse_test_good'][name])))\n",
    "    return {'msepoint':msepoint,'figure':fig}\n",
    "\n",
    "def plotrunreco(histstruct, run, doprint=False):\n",
    "    # call plotlsreco for all ls in a given run\n",
    "    lsnbs = histstruct.lsnbs[np.where(histstruct.runnbs==run)]\n",
    "    print('plotting {} lumisections...'.format(len(lsnbs)))\n",
    "    for lsnb in lsnbs:\n",
    "        _ = plotlsreco(histstruct,run,lsnb,doprint=doprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate particular lumisections: calling\n",
    "\n",
    "run = 297047\n",
    "ls = 10\n",
    "mode = 'ls'\n",
    "\n",
    "if mode=='ls':\n",
    "    # plot this particular run/ls\n",
    "    temp = plotlsreco(histstruct,run,ls,doprint=True)\n",
    "    msepoint = temp['msepoint']\n",
    "    logprob = np.log(fitfunc.pdf(np.array([msepoint])))\n",
    "    print('logprob: '+str(logprob))\n",
    "\n",
    "if mode=='run':\n",
    "    # plot given run\n",
    "    plotrunreco(histstruct,run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the method on the golden json\n",
    "\n",
    "mse_test_golden = np.zeros((len(histstruct.get_golden_indices()),len(histstruct.names)))\n",
    "\n",
    "for i,name in enumerate(histstruct.names):\n",
    "    mse_test_golden[:,i] = histstruct.custom['mse_histograms'][name][histstruct.get_golden_mask()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate how the method performs on golden json data (useful if not using golden json for training)\n",
    "\n",
    "print('evaluating pdf on mse points')\n",
    "logprob_test_golden = np.log(fitfunc.pdf(mse_test_golden))\n",
    "\n",
    "def get_runsls_inrange(logprob,logup,logdown,runnbs,lsnbs):\n",
    "    # get a list of tuples of (run number, ls number) corresponding to ls with log probability within a given range\n",
    "    # note: if logdown is larger than logup, no lower boundary is applied\n",
    "    if logdown > logup:\n",
    "        indices = np.nonzero(logprob<logup)[0]\n",
    "    else:\n",
    "        indices = np.nonzero((logprob>logdown) & (logprob<logup))[0]\n",
    "    runsinrange = runnbs[indices]\n",
    "    lsinrange = lsnbs[indices]\n",
    "    runslsinrange = []\n",
    "    for rr,lsr in zip(runsinrange,lsinrange):\n",
    "        runslsinrange.append((int(rr),int(lsr)))\n",
    "    return {'indices':indices,'runslsinrange':runslsinrange}\n",
    "\n",
    "temp = get_runsls_inrange(logprob_test_golden, 0, 100, histstruct.runnbs[histstruct.get_golden_mask()], histstruct.lsnbs[histstruct.get_golden_mask()])\n",
    "badrunsls = temp['runslsinrange']\n",
    "print('{} out of {} LS are within these boundaries'.format(len(badrunsls),len(logprob_test_golden)))\n",
    "\n",
    "# make plots\n",
    "nplotsmax = 1\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pdf = PdfPages('test.pdf')\n",
    "for i,(runnb,lsnb) in enumerate(badrunsls):\n",
    "    if i>=nplotsmax:\n",
    "        print('maximum number of plots reached')\n",
    "        break\n",
    "    print('------------------------')\n",
    "    temp = plotlsreco(histstruct,runnb,lsnb)\n",
    "    msepoint = temp['msepoint']\n",
    "    fig = temp['figure']\n",
    "    fig.show()\n",
    "    pdf.savefig(fig)\n",
    "    # only for 2 dimensions: extra contour plot\n",
    "    #if nhisttypes != 2: continue\n",
    "    #fig,ax = plt.subplots()\n",
    "    #contourplot = ax.contourf(x, y, np.log(fitfunc.pdfgrid(pos)))\n",
    "    #plt.colorbar(contourplot)\n",
    "    #ax.plot(msepoint[0],msepoint[1],'.k',markersize=10)\n",
    "    #ax.set_xlim((0.,xlim))\n",
    "    #ax.set_ylim((0.,ylim))\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### investigate other 'pathological' histograms in the training set\n",
    "# deprecated, not used anymore and not guaranteed to work anymore...\n",
    "\n",
    "logprob_train = np.log(fitfunc.pdf(mse_train))\n",
    "print('Minimum log prob value in training set: '+str(np.min(logprob_train)))\n",
    "logupboundary = 0\n",
    "loglowboundary = 71 # if larger than logupboundary, no lower boundary\n",
    "if loglowboundary > logupboundary:\n",
    "    indices = np.nonzero(logprob_train<logupboundary)[0]\n",
    "else:\n",
    "    indices = np.nonzero((logprob_train>loglowboundary) & (logprob_train<logupboundary))[0]\n",
    "nout = len(indices)\n",
    "print(str(nout)+' out of '+str(mse_train.shape[0])+' histograms are within these boundary.')\n",
    "\n",
    "# make list of run and ls numbers\n",
    "badruns = histstruct[0]['runnbs_train'][indices]\n",
    "badls = histstruct[0]['lsnbs_train'][indices]\n",
    "badrunsls = []\n",
    "for br,bls in zip(badruns,badls):\n",
    "    badrunsls.append((int(br),int(bls)))\n",
    "print(badrunsls)\n",
    "\n",
    "# make plots\n",
    "nplotsmax = 20\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pdf = PdfPages('test.pdf')\n",
    "#np.random.shuffle(indices)\n",
    "for i,index in enumerate(indices):\n",
    "    if i>=nplotsmax:\n",
    "        print('maximum number of plots reached')\n",
    "        break\n",
    "    print('------------------------')\n",
    "    msepoint = []\n",
    "    fig,axs = plt.subplots(2,4,figsize=(24,12))\n",
    "    for name in histstruct['names']:\n",
    "        hist = histstruct['hists_all'][name][index:index+1,:]\n",
    "        reco = histstruct['models'][name].predict(hist)\n",
    "        mse = histstruct['mse_train'][name][index]\n",
    "        runnb = histstruct[j]['runnbs_all'][index]\n",
    "        lsnb = histstruct[j]['lsnbs_all'][index]\n",
    "        msepoint.append(mse)\n",
    "        #fig,ax = plt.subplots()\n",
    "        CheckPredictions(hist[0],reco[0],mse,0,0,histstruct[j]['name']) \n",
    "        #plot_sets([hist,reco,histstruct[j]['X_test_good']],\n",
    "        #          ax=axs[int(j/4),j%4],\n",
    "        #          title=histstruct[j]['name'],\n",
    "        #          colorlist=['black','red','blue'],labellist=['hist (run: '+str(int(runnb))+', ls: '+str(int(lsnb))+')','reco','good hists'],\n",
    "        #          transparencylist=[1.,1.,0.3])\n",
    "        # additional prints\n",
    "        #print('mse (this histogram): '+str(mse))\n",
    "        #print('mse (average good): '+str(np.average(histstruct[j]['mse_test_good'])))\n",
    "    #fig.show()\n",
    "    pdf.savefig(fig)\n",
    "    # only for 2 dimensions: extra contour plot\n",
    "    if nhisttypes != 2: continue\n",
    "    fig,ax = plt.subplots()\n",
    "    contourplot = ax.contourf(x, y, np.log(fitfunc.pdfgrid(pos)))\n",
    "    plt.colorbar(contourplot)\n",
    "    ax.plot(msepoint[0],msepoint[1],'.k',markersize=10)\n",
    "    ax.set_xlim((0.,xlim))\n",
    "    ax.set_ylim((0.,ylim))\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
