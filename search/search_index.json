{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Some utilities and example notebooks for ML4DQM/DC This repository contains example code for the ML4DQM/DC project. It was developed with the idea of training autoencoders on the per-lumisection histograms stored in dedicated DQMIO files in order to (partially) automate the DQM and/or DC process. In the future, this repository is intended to be generally useful for any ML4DQM/DC study (i.e. any subsystem, any type of histogram, any classification method), but for historical reasons it is at this moment focused on the following subtopics: some 1D histograms related to the status of the pixel tracker. (support for 2D histograms is being added, currently loading the dataframes, getting numpy arrays of histograms and some plotting methods are implemented, see specifically the tutorial plot_histograms_2d.ipynb) using an autoencoder as classification algorithm, i.e. looking at the mean-squared-error between a histogram and its reconstruction as a measure for anomality. (support for other algorithms is in principle present, one just needs to define a class deriving from src/classifiers/HistogramClassifier. See some basic examples in src/classifiers based on an autoencoder or on a direct comparison with reference histograms. See also the tutorial autoencoder_combine.ipynb and template_combine.ipynb for example usage. Planned to be extended, especially for 2D histograms.) Structure of this repository: There are three important directories: tutorials, utils and src. utils contains a number of python notebooks and equivalent scripts with static functions for general use. src contains a class structure that should in principle allow a modular approach and easy extensions, for example towards other single-histogram classification algorithms (see subfolder classifiers) or ways of combining the output for several histogram types (see subfolder cloudfitters). tutorials contains a number of notebooks that can be used to get familiar with the code and its capabilities. Tutorials: Some tutorials are located in the tutorials folder in this repository, that should help you get started with the code. They can be grouped into different steps: Step 1: put the data in a more manageable format. The raw csv files that are our common input are not very easy to work with. Therefore you would probably first want to do something similar to what's done in the notebook read_and_write_data.ipynb. See the code and inline comments in that script and the functions it refers to for more detailed explanation. Its output is one single csv file per histogram type and per year, which is often much more convenient than the original csv files (which contain all histogram types together and are split per number of lines, not per run). All other functions and notebooks presuppose this first step. Step 2: plot the data. Next, you can run plot_histograms.ipynb and plot_histograms_loop.ipynb. These notebooks should help you get a feeling of what your histogram looks like in general, and perhaps help you find some anomalies that you can use for testing. For 2D histograms, look at plot_histograms_2d.ipynb instead. Step 3: train an autoencoder. The scripts autoencoder.ipynb and autoencoder_iterative.ipynb are used to train an autoencoder on the whole dataset or a particular subset respectively. Finally, autoencoder_combine.ipynb trains autoencoders on multiple types of histograms and combines the mse's for each. An example on how to implement another classification method is shown in template_combine.ipynb. Other remarks: The repository contains no data files. I was planning to put some example data files in a data folder, but the files are too big for github. However, the tutorial read_and_write_data.ipynb should help you get the data from where it is stored and put it in a useful format for further processing. Disclaimer: still largely in development stage... To get the tutorial notebooks running in SWAN (preferred method): Log in to SWAN. Go to Projects. Click the cloud icon that says 'Download Project from git' Paste the following url: https://github.com/LukaLambrecht/ML4DQM-DC.git. (alternative method): Log in to SWAN. Click on the leftmost icon on the top right ('new terminal'). Navigate to where you want this repository (the starting place is your CERNBox home directory). Paste this command: git clone https://github.com/LukaLambrecht/ML4DQM-DC.git (or however you usually clone a repository). Exit the terminal. The folder should now be where you cloned it, and you can open and run the notebooks in it in SWAN. Further documentation: Documentation for all the class definitions and functions in the relevant code directories: https://LukaLambrecht.github.io/ML4DQM-DC/ (note: this documentation is generated automatically from comments in the code and currently not yet in perfect shape, both regarding content and layout). Note that the website above does not include documentation for the tutorials (yet?). However, some comments in the tutorial notebooks should provide (enough?) explanation to follow along.","title":"Home"},{"location":"#some-utilities-and-example-notebooks-for-ml4dqmdc","text":"This repository contains example code for the ML4DQM/DC project. It was developed with the idea of training autoencoders on the per-lumisection histograms stored in dedicated DQMIO files in order to (partially) automate the DQM and/or DC process. In the future, this repository is intended to be generally useful for any ML4DQM/DC study (i.e. any subsystem, any type of histogram, any classification method), but for historical reasons it is at this moment focused on the following subtopics: some 1D histograms related to the status of the pixel tracker. (support for 2D histograms is being added, currently loading the dataframes, getting numpy arrays of histograms and some plotting methods are implemented, see specifically the tutorial plot_histograms_2d.ipynb) using an autoencoder as classification algorithm, i.e. looking at the mean-squared-error between a histogram and its reconstruction as a measure for anomality. (support for other algorithms is in principle present, one just needs to define a class deriving from src/classifiers/HistogramClassifier. See some basic examples in src/classifiers based on an autoencoder or on a direct comparison with reference histograms. See also the tutorial autoencoder_combine.ipynb and template_combine.ipynb for example usage. Planned to be extended, especially for 2D histograms.)","title":"Some utilities and example notebooks for ML4DQM/DC"},{"location":"#structure-of-this-repository","text":"There are three important directories: tutorials, utils and src. utils contains a number of python notebooks and equivalent scripts with static functions for general use. src contains a class structure that should in principle allow a modular approach and easy extensions, for example towards other single-histogram classification algorithms (see subfolder classifiers) or ways of combining the output for several histogram types (see subfolder cloudfitters). tutorials contains a number of notebooks that can be used to get familiar with the code and its capabilities.","title":"Structure of this repository:"},{"location":"#tutorials","text":"Some tutorials are located in the tutorials folder in this repository, that should help you get started with the code. They can be grouped into different steps: Step 1: put the data in a more manageable format. The raw csv files that are our common input are not very easy to work with. Therefore you would probably first want to do something similar to what's done in the notebook read_and_write_data.ipynb. See the code and inline comments in that script and the functions it refers to for more detailed explanation. Its output is one single csv file per histogram type and per year, which is often much more convenient than the original csv files (which contain all histogram types together and are split per number of lines, not per run). All other functions and notebooks presuppose this first step. Step 2: plot the data. Next, you can run plot_histograms.ipynb and plot_histograms_loop.ipynb. These notebooks should help you get a feeling of what your histogram looks like in general, and perhaps help you find some anomalies that you can use for testing. For 2D histograms, look at plot_histograms_2d.ipynb instead. Step 3: train an autoencoder. The scripts autoencoder.ipynb and autoencoder_iterative.ipynb are used to train an autoencoder on the whole dataset or a particular subset respectively. Finally, autoencoder_combine.ipynb trains autoencoders on multiple types of histograms and combines the mse's for each. An example on how to implement another classification method is shown in template_combine.ipynb.","title":"Tutorials:"},{"location":"#other-remarks","text":"The repository contains no data files. I was planning to put some example data files in a data folder, but the files are too big for github. However, the tutorial read_and_write_data.ipynb should help you get the data from where it is stored and put it in a useful format for further processing. Disclaimer: still largely in development stage...","title":"Other remarks:"},{"location":"#to-get-the-tutorial-notebooks-running-in-swan","text":"","title":"To get the tutorial notebooks running in SWAN"},{"location":"#preferred-method","text":"Log in to SWAN. Go to Projects. Click the cloud icon that says 'Download Project from git' Paste the following url: https://github.com/LukaLambrecht/ML4DQM-DC.git.","title":"(preferred method):"},{"location":"#alternative-method","text":"Log in to SWAN. Click on the leftmost icon on the top right ('new terminal'). Navigate to where you want this repository (the starting place is your CERNBox home directory). Paste this command: git clone https://github.com/LukaLambrecht/ML4DQM-DC.git (or however you usually clone a repository). Exit the terminal. The folder should now be where you cloned it, and you can open and run the notebooks in it in SWAN.","title":"(alternative method):"},{"location":"#further-documentation","text":"Documentation for all the class definitions and functions in the relevant code directories: https://LukaLambrecht.github.io/ML4DQM-DC/ (note: this documentation is generated automatically from comments in the code and currently not yet in perfect shape, both regarding content and layout). Note that the website above does not include documentation for the tutorials (yet?). However, some comments in the tutorial notebooks should provide (enough?) explanation to follow along.","title":"Further documentation:"},{"location":"omsapi/get_oms_data/","text":"get oms data get_oms_api() get an OMSAPI instance takes no input arguments, as the configuration parameters are unlikely to change very often if needed, these parameters can be changed in the file urls.py get_oms_data( omsapi, api_endpoint, runnb, extrafilters=[], sort=None, attributes=[]) query some data from OMS input arguments: - omsapi: an OMSAPI instance, e.g. created by get_oms_api() - api_endpoint: string, target information, e.g. 'runs' or 'lumisections' (see the readme for a link where the available endpoints are listed) - runnb: run number(s) to retrieve the info for, either integer (for single run) or tuple or list of two elements (first run and last run) (can also be None to not filter on run number but this is not recommended) - extrafilters: list of extra filters (apart from run number), each filter is supposed to be a dict of the form {'attribute_name': ,'value': ,'operator': } where must be a valid field name in the OMS data, its value, and chosen from \"EQ\", \"NEQ\", \"LT\", \"GT\", \"LE\", \"GE\" or \"LIKE\" - sort: valid field name in the OMS data by which to sort - attributes: list of valid field names in the OMS data to return (if not specified, all information is returned) get_oms_response_attribute( omsresponse, attribute ) small helper function to retrieve a list of values for a single attribute input arguments: - omsresponse: the json-like object returned by get_oms_data - attribute: name of one of the attributes present in omsresponse","title":"get_oms_data"},{"location":"omsapi/get_oms_data/#get-oms-data","text":"","title":"get oms data"},{"location":"omsapi/get_oms_data/#get95oms95api","text":"get an OMSAPI instance takes no input arguments, as the configuration parameters are unlikely to change very often if needed, these parameters can be changed in the file urls.py","title":"get_oms_api()"},{"location":"omsapi/get_oms_data/#get95oms95data-omsapi-api95endpoint-runnb-extrafilters-sortnone-attributes","text":"query some data from OMS input arguments: - omsapi: an OMSAPI instance, e.g. created by get_oms_api() - api_endpoint: string, target information, e.g. 'runs' or 'lumisections' (see the readme for a link where the available endpoints are listed) - runnb: run number(s) to retrieve the info for, either integer (for single run) or tuple or list of two elements (first run and last run) (can also be None to not filter on run number but this is not recommended) - extrafilters: list of extra filters (apart from run number), each filter is supposed to be a dict of the form {'attribute_name': ,'value': ,'operator': } where must be a valid field name in the OMS data, its value, and chosen from \"EQ\", \"NEQ\", \"LT\", \"GT\", \"LE\", \"GE\" or \"LIKE\" - sort: valid field name in the OMS data by which to sort - attributes: list of valid field names in the OMS data to return (if not specified, all information is returned)","title":"get_oms_data( omsapi, api_endpoint, runnb, extrafilters=[], sort=None, attributes=[])"},{"location":"omsapi/get_oms_data/#get95oms95response95attribute-omsresponse-attribute","text":"small helper function to retrieve a list of values for a single attribute input arguments: - omsresponse: the json-like object returned by get_oms_data - attribute: name of one of the attributes present in omsresponse","title":"get_oms_response_attribute( omsresponse, attribute )"},{"location":"omsapi/omsapi/","text":"omsapi OMSApiException(Exception) (no valid documentation found) OMSQuery(object) (no valid documentation found) __init__(self, base_url, resource, verbose, cookies, oms_auth, cert_verify, retry_on_err_sec, proxies) (no valid documentation found) _attr_exists(self, attr) (no valid documentation found) _load_meta(self) (no valid documentation found) _warn(self, message, raise_exc=False) (no valid documentation found) set_verbose(self, verbose) (no valid documentation found) set_validation(self, attribute_validation) (no valid documentation found) attrs(self, attributes=None) (no valid documentation found) filters(self, filters) (no valid documentation found) filter(self, attribute, value, operator=\"EQ\") (no valid documentation found) clear_filter(self) (no valid documentation found) sort(self, attribute, asc=True) (no valid documentation found) paginate(self, page=1, per_page=10) (no valid documentation found) include(self, key) (no valid documentation found) custom(self, key, value=None) (no valid documentation found) data_query(self) (no valid documentation found) data(self) (no valid documentation found) meta(self) (no valid documentation found) get_request(self, url, verify=False) (no valid documentation found) OMSAPIOAuth(object) (no valid documentation found) __init__(self, client_id, client_secret, audience=\"cmsoms-prod\", cert_verify=True, proxies={}, retry_on_err_sec=0) (no valid documentation found) auth_oidc(self) (no valid documentation found) auth_oidc_req(self) (no valid documentation found) OMSAPI(object) (no valid documentation found) __init__(self, api_url=\"https://cmsoms.cern.ch/agg/api\", api_version=\"v1\", verbose=True, cert_verify=True, retry_on_err_sec=0, proxies={}) (no valid documentation found) query(self, resource, query_validation=True) (no valid documentation found) auth_oidc(self, client_id, client_secret, audience=\"cmsoms-prod\", proxies={}) (no valid documentation found) auth_krb(self, cookie_path=\"ssocookies.txt\") (no valid documentation found) rm_file(filename) (no valid documentation found)","title":"omsapi"},{"location":"omsapi/omsapi/#omsapi","text":"","title":"omsapi"},{"location":"omsapi/omsapi/#omsapiexceptionexception","text":"(no valid documentation found)","title":"OMSApiException(Exception)"},{"location":"omsapi/omsapi/#omsqueryobject","text":"(no valid documentation found)","title":"OMSQuery(object)"},{"location":"omsapi/omsapi/#9595init9595self-base95url-resource-verbose-cookies-oms95auth-cert95verify-retry95on95err95sec-proxies","text":"(no valid documentation found)","title":"__init__(self, base_url, resource, verbose, cookies, oms_auth, cert_verify, retry_on_err_sec, proxies)"},{"location":"omsapi/omsapi/#95attr95existsself-attr","text":"(no valid documentation found)","title":"_attr_exists(self, attr)"},{"location":"omsapi/omsapi/#95load95metaself","text":"(no valid documentation found)","title":"_load_meta(self)"},{"location":"omsapi/omsapi/#95warnself-message-raise95excfalse","text":"(no valid documentation found)","title":"_warn(self, message, raise_exc=False)"},{"location":"omsapi/omsapi/#set95verboseself-verbose","text":"(no valid documentation found)","title":"set_verbose(self, verbose)"},{"location":"omsapi/omsapi/#set95validationself-attribute95validation","text":"(no valid documentation found)","title":"set_validation(self, attribute_validation)"},{"location":"omsapi/omsapi/#attrsself-attributesnone","text":"(no valid documentation found)","title":"attrs(self, attributes=None)"},{"location":"omsapi/omsapi/#filtersself-filters","text":"(no valid documentation found)","title":"filters(self, filters)"},{"location":"omsapi/omsapi/#filterself-attribute-value-operatoreq","text":"(no valid documentation found)","title":"filter(self, attribute, value, operator=\"EQ\")"},{"location":"omsapi/omsapi/#clear95filterself","text":"(no valid documentation found)","title":"clear_filter(self)"},{"location":"omsapi/omsapi/#sortself-attribute-asctrue","text":"(no valid documentation found)","title":"sort(self, attribute, asc=True)"},{"location":"omsapi/omsapi/#paginateself-page1-per95page10","text":"(no valid documentation found)","title":"paginate(self, page=1, per_page=10)"},{"location":"omsapi/omsapi/#includeself-key","text":"(no valid documentation found)","title":"include(self, key)"},{"location":"omsapi/omsapi/#customself-key-valuenone","text":"(no valid documentation found)","title":"custom(self, key, value=None)"},{"location":"omsapi/omsapi/#data95queryself","text":"(no valid documentation found)","title":"data_query(self)"},{"location":"omsapi/omsapi/#dataself","text":"(no valid documentation found)","title":"data(self)"},{"location":"omsapi/omsapi/#metaself","text":"(no valid documentation found)","title":"meta(self)"},{"location":"omsapi/omsapi/#get95requestself-url-verifyfalse","text":"(no valid documentation found)","title":"get_request(self, url, verify=False)"},{"location":"omsapi/omsapi/#omsapioauthobject","text":"(no valid documentation found)","title":"OMSAPIOAuth(object)"},{"location":"omsapi/omsapi/#9595init9595self-client95id-client95secret-audiencecmsoms-prod-cert95verifytrue-proxies-retry95on95err95sec0","text":"(no valid documentation found)","title":"__init__(self, client_id, client_secret, audience=\"cmsoms-prod\", cert_verify=True, proxies={}, retry_on_err_sec=0)"},{"location":"omsapi/omsapi/#auth95oidcself","text":"(no valid documentation found)","title":"auth_oidc(self)"},{"location":"omsapi/omsapi/#auth95oidc95reqself","text":"(no valid documentation found)","title":"auth_oidc_req(self)"},{"location":"omsapi/omsapi/#omsapiobject","text":"(no valid documentation found)","title":"OMSAPI(object)"},{"location":"omsapi/omsapi/#9595init9595self-api95urlhttpscmsomscernchaggapi-api95versionv1-verbosetrue-cert95verifytrue-retry95on95err95sec0-proxies","text":"(no valid documentation found)","title":"__init__(self, api_url=\"https://cmsoms.cern.ch/agg/api\", api_version=\"v1\", verbose=True, cert_verify=True, retry_on_err_sec=0, proxies={})"},{"location":"omsapi/omsapi/#queryself-resource-query95validationtrue","text":"(no valid documentation found)","title":"query(self, resource, query_validation=True)"},{"location":"omsapi/omsapi/#auth95oidcself-client95id-client95secret-audiencecmsoms-prod-proxies","text":"(no valid documentation found)","title":"auth_oidc(self, client_id, client_secret, audience=\"cmsoms-prod\", proxies={})"},{"location":"omsapi/omsapi/#auth95krbself-cookie95pathssocookiestxt","text":"(no valid documentation found)","title":"auth_krb(self, cookie_path=\"ssocookies.txt\")"},{"location":"omsapi/omsapi/#rm95filefilename","text":"(no valid documentation found)","title":"rm_file(filename)"},{"location":"omsapi/urls/","text":"urls","title":"urls"},{"location":"omsapi/urls/#urls","text":"","title":"urls"},{"location":"omsinterface/cert/","text":"cert","title":"cert"},{"location":"omsinterface/cert/#cert","text":"","title":"cert"},{"location":"omsinterface/connectiontools/","text":"connectiontools check_connectivity(url) (no valid documentation found) get_cookies(url, authmode, **kwargs) (no valid documentation found) get_cookies_from_certificate(url, certificate, **kwargs) (no valid documentation found) get_cookies_from_login(url, login, **kwargs) (no valid documentation found) _construct_certificate_authentication_url(login_redirect_url) (no valid documentation found) _extract_login_form( xml_response_content ) (no valid documentation found) _modify_xml_content( xml_response_content ) (no valid documentation found)","title":"connectiontools"},{"location":"omsinterface/connectiontools/#connectiontools","text":"","title":"connectiontools"},{"location":"omsinterface/connectiontools/#check95connectivityurl","text":"(no valid documentation found)","title":"check_connectivity(url)"},{"location":"omsinterface/connectiontools/#get95cookiesurl-authmode-kwargs","text":"(no valid documentation found)","title":"get_cookies(url, authmode, **kwargs)"},{"location":"omsinterface/connectiontools/#get95cookies95from95certificateurl-certificate-kwargs","text":"(no valid documentation found)","title":"get_cookies_from_certificate(url, certificate, **kwargs)"},{"location":"omsinterface/connectiontools/#get95cookies95from95loginurl-login-kwargs","text":"(no valid documentation found)","title":"get_cookies_from_login(url, login, **kwargs)"},{"location":"omsinterface/connectiontools/#95construct95certificate95authentication95urllogin95redirect95url","text":"(no valid documentation found)","title":"_construct_certificate_authentication_url(login_redirect_url)"},{"location":"omsinterface/connectiontools/#95extract95login95form-xml95response95content","text":"(no valid documentation found)","title":"_extract_login_form( xml_response_content )"},{"location":"omsinterface/connectiontools/#95modify95xml95content-xml95response95content","text":"(no valid documentation found)","title":"_modify_xml_content( xml_response_content )"},{"location":"omsinterface/get_oms_data/","text":"get oms data get_oms_data( mode, run, hltpathname='', authmode='login' ) (no valid documentation found)","title":"get_oms_data"},{"location":"omsinterface/get_oms_data/#get-oms-data","text":"","title":"get oms data"},{"location":"omsinterface/get_oms_data/#get95oms95data-mode-run-hltpathname-authmodelogin","text":"(no valid documentation found)","title":"get_oms_data( mode, run, hltpathname='', authmode='login' )"},{"location":"omsinterface/omstools/","text":"omstools check_oms_connectivity() (no valid documentation found) get_oms_cookies( authmode, **kwargs ) (no valid documentation found) _get_oms_resource_within_cern_gpn(relative_url) (no valid documentation found) _get_oms_resource_authenticated(relative_url, cookies) (no valid documentation found) get_oms_resource(table, parameters, **kwargs) (no valid documentation found) _get_single_resource(table, parameters, **kwargs) (no valid documentation found) get_run(run_number, **kwargs) (no valid documentation found) get_fill(fill_number, **kwargs) (no valid documentation found) _get_resources_page(table, parameters, page, page_size, **kwargs) (no valid documentation found) get_resources(table, parameters, page_size=PAGE_SIZE, silent=False, **kwargs) (no valid documentation found) get_runs(begin, end, **kwargs) (no valid documentation found) get_fills(begin, end, **kwargs) (no valid documentation found) get_lumisection_count(run_number, **kwargs) (no valid documentation found) get_lumisections( run_number=None, fill_number=None, start_time=None, end_time=None, **kwargs) (no valid documentation found) get_hltpathinfos(run_number, **kwargs) (no valid documentation found) get_hltpathrates(run_number, path_name, **kwargs) (no valid documentation found) get_all_hltpathrates(run_number, silent=False, **kwargs) (no valid documentation found) calc_page_count(resource_count, page_size) (no valid documentation found) flatten_resource(response) (no valid documentation found) progress_bar(current, total, text=\"\", filler=\"#\") (no valid documentation found) print_progress(current, total, text=\"\", args, *kwargs) (no valid documentation found)","title":"omstools"},{"location":"omsinterface/omstools/#omstools","text":"","title":"omstools"},{"location":"omsinterface/omstools/#check95oms95connectivity","text":"(no valid documentation found)","title":"check_oms_connectivity()"},{"location":"omsinterface/omstools/#get95oms95cookies-authmode-kwargs","text":"(no valid documentation found)","title":"get_oms_cookies( authmode, **kwargs )"},{"location":"omsinterface/omstools/#95get95oms95resource95within95cern95gpnrelative95url","text":"(no valid documentation found)","title":"_get_oms_resource_within_cern_gpn(relative_url)"},{"location":"omsinterface/omstools/#95get95oms95resource95authenticatedrelative95url-cookies","text":"(no valid documentation found)","title":"_get_oms_resource_authenticated(relative_url, cookies)"},{"location":"omsinterface/omstools/#get95oms95resourcetable-parameters-kwargs","text":"(no valid documentation found)","title":"get_oms_resource(table, parameters, **kwargs)"},{"location":"omsinterface/omstools/#95get95single95resourcetable-parameters-kwargs","text":"(no valid documentation found)","title":"_get_single_resource(table, parameters, **kwargs)"},{"location":"omsinterface/omstools/#get95runrun95number-kwargs","text":"(no valid documentation found)","title":"get_run(run_number, **kwargs)"},{"location":"omsinterface/omstools/#get95fillfill95number-kwargs","text":"(no valid documentation found)","title":"get_fill(fill_number, **kwargs)"},{"location":"omsinterface/omstools/#95get95resources95pagetable-parameters-page-page95size-kwargs","text":"(no valid documentation found)","title":"_get_resources_page(table, parameters, page, page_size, **kwargs)"},{"location":"omsinterface/omstools/#get95resourcestable-parameters-page95sizepage95size-silentfalse-kwargs","text":"(no valid documentation found)","title":"get_resources(table, parameters, page_size=PAGE_SIZE, silent=False, **kwargs)"},{"location":"omsinterface/omstools/#get95runsbegin-end-kwargs","text":"(no valid documentation found)","title":"get_runs(begin, end, **kwargs)"},{"location":"omsinterface/omstools/#get95fillsbegin-end-kwargs","text":"(no valid documentation found)","title":"get_fills(begin, end, **kwargs)"},{"location":"omsinterface/omstools/#get95lumisection95countrun95number-kwargs","text":"(no valid documentation found)","title":"get_lumisection_count(run_number, **kwargs)"},{"location":"omsinterface/omstools/#get95lumisections-run95numbernone-fill95numbernone-start95timenone-end95timenone-kwargs","text":"(no valid documentation found)","title":"get_lumisections( run_number=None, fill_number=None, start_time=None, end_time=None, **kwargs)"},{"location":"omsinterface/omstools/#get95hltpathinfosrun95number-kwargs","text":"(no valid documentation found)","title":"get_hltpathinfos(run_number, **kwargs)"},{"location":"omsinterface/omstools/#get95hltpathratesrun95number-path95name-kwargs","text":"(no valid documentation found)","title":"get_hltpathrates(run_number, path_name, **kwargs)"},{"location":"omsinterface/omstools/#get95all95hltpathratesrun95number-silentfalse-kwargs","text":"(no valid documentation found)","title":"get_all_hltpathrates(run_number, silent=False, **kwargs)"},{"location":"omsinterface/omstools/#calc95page95countresource95count-page95size","text":"(no valid documentation found)","title":"calc_page_count(resource_count, page_size)"},{"location":"omsinterface/omstools/#flatten95resourceresponse","text":"(no valid documentation found)","title":"flatten_resource(response)"},{"location":"omsinterface/omstools/#progress95barcurrent-total-text-filler","text":"(no valid documentation found)","title":"progress_bar(current, total, text=\"\", filler=\"#\")"},{"location":"omsinterface/omstools/#print95progresscurrent-total-text-args-kwargs","text":"(no valid documentation found)","title":"print_progress(current, total, text=\"\", args, *kwargs)"},{"location":"omsinterface/urls/","text":"urls","title":"urls"},{"location":"omsinterface/urls/#urls","text":"","title":"urls"},{"location":"src/HistStruct/","text":"HistStruct HistStruct(object) main data structure used within this framework a HistStruct object basically consists of a mutually consistent collection of numpy arrays, where each numpy array corresponds to one histogram type, with dimensions (number of histograms, number of bins). the HistStruct has functions to easily perform the following common tasks (among others): - select a subset of runs and/or lumisections (e.g. using a json file formatted selector), - prepare the data for machine learning training - evaluate classifiers (machine learning types or other) __init__( self ) empty initializer, setting all containers to empty defaults save( self, path ) save a HistStruct object to a pkl file load( self, path ) (no valid documentation found) add_dataframe( self, df, donormalize=True, rebinningfactor=1 ) add a dataframe to a HistStruct input arguments: - df is a pandas dataframe as read from the input csv files. - donormalize: boolean whether to normalize the histograms - rebinningfactor: factor by which to group bins together notes: - the new dataframe can contain one or more histogram types - the new dataframe must contain the same run and lumisection numbers (for each histogram type in it) as already present in the HistStruct, except if it is the first one to be added add_mask( self, name, mask ) add a mask to a HistStruct input arguments: - name: a name for the mask - mask: a 1D np array of booleans with same length as number of lumisections in HistStruct remove_mask( self, name ) inverse operation of add_mask add_json_mask( self, name, jsondict ) add a mask corresponding to a json dict add_goldenjson_mask( self, name ) add a mask corresponding to the golden json file add_dcsonjson_mask( self, name ) add a mask corresponding to the DCS-bit on json file add_hightstat_mask( self, name, histnames=None, entries_to_bins_ratio=100 ) add a mask corresponding to lumisections where all histograms have sufficient statistics input arguments: - histnames: list of histogram names to take into account for making the mask (default: all in the HistStruct) - entries_to_bins_ratio: criterion to determine if a histogram has sufficient statistics, number of entries divided by number of bins get_combined_mask( self, names ) get a combined mask given multiple mask names mostly for internal use; externally you can use get_histograms( histname, ) directly get_runnbs( self, masknames=None ) get the array of run numbers, optionally after masking get_lsnbs( self, masknames=None ) get the array of lumisection numbers, optionally after masking get_scores( self, histname=None, masknames=None ) get the array of scores for a given histogram type, optionally after masking if histname is None, return a dict matching histnames to arrays of scores get_histograms( self, histname=None, masknames=None ) get the array of histograms for a given type, optionally after masking if histname is None, return a dict matching histnames to arrays of histograms add_classifier( self, histname, classifier, evaluate=False ) add a histogram classifier for a given histogram name to the HistStruct classifier must be an object of type HistogramClassifier (i.e. of any class that derives from it) evaluate is a bool whether to evaluate the classifier (and store the result in the 'scores' attribute) evaluate_classifier( self, histname ) evaluate a histogram classifier for a given histogram name in the HistStruct the result is both returned and stored in the 'scores' attribute plot_ls( self, run, ls, recohist=None, recolabel='reco', refhists=None, refhistslabel='reference', doprint=False) plot the histograms for a given run/ls number versus their references and/or their reconstruction plot_run( self, run, recohist=None, recolabel='reco', refhists=None, refhistslabel='reference', doprint=False) call plot_ls for all lumisections in a given run","title":"HistStruct"},{"location":"src/HistStruct/#histstruct","text":"","title":"HistStruct"},{"location":"src/HistStruct/#histstructobject","text":"main data structure used within this framework a HistStruct object basically consists of a mutually consistent collection of numpy arrays, where each numpy array corresponds to one histogram type, with dimensions (number of histograms, number of bins). the HistStruct has functions to easily perform the following common tasks (among others): - select a subset of runs and/or lumisections (e.g. using a json file formatted selector), - prepare the data for machine learning training - evaluate classifiers (machine learning types or other)","title":"HistStruct(object)"},{"location":"src/HistStruct/#9595init9595-self","text":"empty initializer, setting all containers to empty defaults","title":"__init__( self )"},{"location":"src/HistStruct/#save-self-path","text":"save a HistStruct object to a pkl file","title":"save( self, path )"},{"location":"src/HistStruct/#load-self-path","text":"(no valid documentation found)","title":"load( self, path )"},{"location":"src/HistStruct/#add95dataframe-self-df-donormalizetrue-rebinningfactor1","text":"add a dataframe to a HistStruct input arguments: - df is a pandas dataframe as read from the input csv files. - donormalize: boolean whether to normalize the histograms - rebinningfactor: factor by which to group bins together notes: - the new dataframe can contain one or more histogram types - the new dataframe must contain the same run and lumisection numbers (for each histogram type in it) as already present in the HistStruct, except if it is the first one to be added","title":"add_dataframe( self, df, donormalize=True, rebinningfactor=1 )"},{"location":"src/HistStruct/#add95mask-self-name-mask","text":"add a mask to a HistStruct input arguments: - name: a name for the mask - mask: a 1D np array of booleans with same length as number of lumisections in HistStruct","title":"add_mask( self, name, mask )"},{"location":"src/HistStruct/#remove95mask-self-name","text":"inverse operation of add_mask","title":"remove_mask( self, name )"},{"location":"src/HistStruct/#add95json95mask-self-name-jsondict","text":"add a mask corresponding to a json dict","title":"add_json_mask( self, name, jsondict )"},{"location":"src/HistStruct/#add95goldenjson95mask-self-name","text":"add a mask corresponding to the golden json file","title":"add_goldenjson_mask( self, name )"},{"location":"src/HistStruct/#add95dcsonjson95mask-self-name","text":"add a mask corresponding to the DCS-bit on json file","title":"add_dcsonjson_mask( self, name )"},{"location":"src/HistStruct/#add95hightstat95mask-self-name-histnamesnone-entries95to95bins95ratio100","text":"add a mask corresponding to lumisections where all histograms have sufficient statistics input arguments: - histnames: list of histogram names to take into account for making the mask (default: all in the HistStruct) - entries_to_bins_ratio: criterion to determine if a histogram has sufficient statistics, number of entries divided by number of bins","title":"add_hightstat_mask( self, name, histnames=None, entries_to_bins_ratio=100 )"},{"location":"src/HistStruct/#get95combined95mask-self-names","text":"get a combined mask given multiple mask names mostly for internal use; externally you can use get_histograms( histname, ) directly","title":"get_combined_mask( self, names )"},{"location":"src/HistStruct/#get95runnbs-self-masknamesnone","text":"get the array of run numbers, optionally after masking","title":"get_runnbs( self, masknames=None )"},{"location":"src/HistStruct/#get95lsnbs-self-masknamesnone","text":"get the array of lumisection numbers, optionally after masking","title":"get_lsnbs( self, masknames=None )"},{"location":"src/HistStruct/#get95scores-self-histnamenone-masknamesnone","text":"get the array of scores for a given histogram type, optionally after masking if histname is None, return a dict matching histnames to arrays of scores","title":"get_scores( self, histname=None, masknames=None )"},{"location":"src/HistStruct/#get95histograms-self-histnamenone-masknamesnone","text":"get the array of histograms for a given type, optionally after masking if histname is None, return a dict matching histnames to arrays of histograms","title":"get_histograms( self, histname=None, masknames=None )"},{"location":"src/HistStruct/#add95classifier-self-histname-classifier-evaluatefalse","text":"add a histogram classifier for a given histogram name to the HistStruct classifier must be an object of type HistogramClassifier (i.e. of any class that derives from it) evaluate is a bool whether to evaluate the classifier (and store the result in the 'scores' attribute)","title":"add_classifier( self, histname, classifier, evaluate=False )"},{"location":"src/HistStruct/#evaluate95classifier-self-histname","text":"evaluate a histogram classifier for a given histogram name in the HistStruct the result is both returned and stored in the 'scores' attribute","title":"evaluate_classifier( self, histname )"},{"location":"src/HistStruct/#plot95ls-self-run-ls-recohistnone-recolabelreco-refhistsnone-refhistslabelreference-doprintfalse","text":"plot the histograms for a given run/ls number versus their references and/or their reconstruction","title":"plot_ls( self, run, ls, recohist=None, recolabel='reco', refhists=None, refhistslabel='reference', doprint=False)"},{"location":"src/HistStruct/#plot95run-self-run-recohistnone-recolabelreco-refhistsnone-refhistslabelreference-doprintfalse","text":"call plot_ls for all lumisections in a given run","title":"plot_run( self, run, recohist=None, recolabel='reco', refhists=None, refhistslabel='reference', doprint=False)"},{"location":"src/classifiers/AutoEncoder/","text":"AutoEncoder AutoEncoder(HistogramClassifier) histogram classfier based on the MSE of an autoencoder reconstruction the AutoEncoder derives from the generic HistogramClassifier. for this specific classifier, the output score of a histogram is the mean-square-error (MSE) between the original histogram and its autoencoder reconstruction. in essence, it is just a wrapper for a tensorflow model. __init__( self, model=None ) intializer from a tensorflow model the model is assumed to be fully trained on a suitable training set and ready for use TODO: perhaps the functionality for initializing and training the model can be absorbed in the AutoEncoder class, but this is not yet supported currently evaluate( self, histograms ) classification of a collection of histograms based on their autoencoder reconstruction","title":"AutoEncoder"},{"location":"src/classifiers/AutoEncoder/#autoencoder","text":"","title":"AutoEncoder"},{"location":"src/classifiers/AutoEncoder/#autoencoderhistogramclassifier","text":"histogram classfier based on the MSE of an autoencoder reconstruction the AutoEncoder derives from the generic HistogramClassifier. for this specific classifier, the output score of a histogram is the mean-square-error (MSE) between the original histogram and its autoencoder reconstruction. in essence, it is just a wrapper for a tensorflow model.","title":"AutoEncoder(HistogramClassifier)"},{"location":"src/classifiers/AutoEncoder/#9595init9595-self-modelnone","text":"intializer from a tensorflow model the model is assumed to be fully trained on a suitable training set and ready for use TODO: perhaps the functionality for initializing and training the model can be absorbed in the AutoEncoder class, but this is not yet supported currently","title":"__init__( self, model=None )"},{"location":"src/classifiers/AutoEncoder/#evaluate-self-histograms","text":"classification of a collection of histograms based on their autoencoder reconstruction","title":"evaluate( self, histograms )"},{"location":"src/classifiers/HistogramClassifier/","text":"HistogramClassifier HistogramClassifier(ABC) abstract base class for histogram classifying objects note that all concrete histogram classifiers must inherit from HistogramClassifier! a HistogramClassifier can be any object that classifies a histogram; in more detail: - the input is a collection of histograms (of the same type), represented by a numpy array of shape (nhists,nbins) for 1D histograms or (nhists,nybins,nxbins) for 2D histograms. - the output is an array of numbers of shape (nhists). - the processing between input and output can in principle be anything, but usually some sort of discriminating power is assumed. how to make a concrete HistogramClassifier class: - define a class that inherits from HistogramClassifier - make sure all functions with @abstractmethod are implemented in your class - it is recommended to start each overriding function with a call to super(), but this is not strictly necessary see also the existing examples! __init__( self ) empty intializer evaluate( self, histograms ) main function used to process a set of histograms input arguments: - histograms: numpy array of shape (nhists,nbins) or (nhists,nybins,nxbins). output: 1D numpy array of shape (nhists), one number per histogram.","title":"HistogramClassifier"},{"location":"src/classifiers/HistogramClassifier/#histogramclassifier","text":"","title":"HistogramClassifier"},{"location":"src/classifiers/HistogramClassifier/#histogramclassifierabc","text":"abstract base class for histogram classifying objects note that all concrete histogram classifiers must inherit from HistogramClassifier! a HistogramClassifier can be any object that classifies a histogram; in more detail: - the input is a collection of histograms (of the same type), represented by a numpy array of shape (nhists,nbins) for 1D histograms or (nhists,nybins,nxbins) for 2D histograms. - the output is an array of numbers of shape (nhists). - the processing between input and output can in principle be anything, but usually some sort of discriminating power is assumed. how to make a concrete HistogramClassifier class: - define a class that inherits from HistogramClassifier - make sure all functions with @abstractmethod are implemented in your class - it is recommended to start each overriding function with a call to super(), but this is not strictly necessary see also the existing examples!","title":"HistogramClassifier(ABC)"},{"location":"src/classifiers/HistogramClassifier/#9595init9595-self","text":"empty intializer","title":"__init__( self )"},{"location":"src/classifiers/HistogramClassifier/#evaluate-self-histograms","text":"main function used to process a set of histograms input arguments: - histograms: numpy array of shape (nhists,nbins) or (nhists,nybins,nxbins). output: 1D numpy array of shape (nhists), one number per histogram.","title":"evaluate( self, histograms )"},{"location":"src/classifiers/MaxPullClassifier/","text":"MaxPullClassifier pull( testhist, refhist ) calculate bin-per-bin pull between two histograms bin-per-bin pull is defined here preliminarily as (testhist(bin)-refhist(bin))/sqrt(refhist(bin)) notes: - bins in the denominator where refhist is < 1 are set to one! This is for histograms with absolute counts, and they should not be normalized! - instead another normalization is applied: the test histogram is multiplied by sum(refhist)/sum(testhist) before computing the pulls input arguments: - testhist, refhist: numpy arrays of the same shape output: numpy array of same shape as testhist and refhist maxabspull( testhist, refhist, n=1 ) calculate maximum of bin-per-bin pulls (in absolute value) between two histograms see definition of bin-per-bin pull in function pull (above) input arguments: - testhist, refhist: numpy arrays of the same shape - n: nubmer of largest pull values to average over (default: 1, just take single maximum) output: a float MaxPullClassifier(HistogramClassifier) histogram classification based on maximum pull between test histogram and reference histogram. specifically intended for 2D histograms, but should in principle work for 1D as well. see static function pull (above) for definition of bin-per-bin pull and other notes. __init__( self, refhist, n=1 ) initializer from a reference histogram input arguments: - refhist: a numpy array of shape (nbins) or (nybins,nxbins) - n: number of largest pull values to average over (default: 1, just take single maximum) evaluate( self, histograms ) classify the histograms based on their max bin-per-bin pull (in absolute value) with respect to a reference histogram getpull( self, histogram ) get the pull histogram for a given test histogram input arguments: histogram: a single histogram, i.e. numpy array of shape (nbins) for 1D or (nybins,nxbins) for 2D. output: numpy array of same shape as histogram containing bin-per-bin pull w.r.t. reference histogram","title":"MaxPullClassifier"},{"location":"src/classifiers/MaxPullClassifier/#maxpullclassifier","text":"","title":"MaxPullClassifier"},{"location":"src/classifiers/MaxPullClassifier/#pull-testhist-refhist","text":"calculate bin-per-bin pull between two histograms bin-per-bin pull is defined here preliminarily as (testhist(bin)-refhist(bin))/sqrt(refhist(bin)) notes: - bins in the denominator where refhist is < 1 are set to one! This is for histograms with absolute counts, and they should not be normalized! - instead another normalization is applied: the test histogram is multiplied by sum(refhist)/sum(testhist) before computing the pulls input arguments: - testhist, refhist: numpy arrays of the same shape output: numpy array of same shape as testhist and refhist","title":"pull( testhist, refhist )"},{"location":"src/classifiers/MaxPullClassifier/#maxabspull-testhist-refhist-n1","text":"calculate maximum of bin-per-bin pulls (in absolute value) between two histograms see definition of bin-per-bin pull in function pull (above) input arguments: - testhist, refhist: numpy arrays of the same shape - n: nubmer of largest pull values to average over (default: 1, just take single maximum) output: a float","title":"maxabspull( testhist, refhist, n=1 )"},{"location":"src/classifiers/MaxPullClassifier/#maxpullclassifierhistogramclassifier","text":"histogram classification based on maximum pull between test histogram and reference histogram. specifically intended for 2D histograms, but should in principle work for 1D as well. see static function pull (above) for definition of bin-per-bin pull and other notes.","title":"MaxPullClassifier(HistogramClassifier)"},{"location":"src/classifiers/MaxPullClassifier/#9595init9595-self-refhist-n1","text":"initializer from a reference histogram input arguments: - refhist: a numpy array of shape (nbins) or (nybins,nxbins) - n: number of largest pull values to average over (default: 1, just take single maximum)","title":"__init__( self, refhist, n=1 )"},{"location":"src/classifiers/MaxPullClassifier/#evaluate-self-histograms","text":"classify the histograms based on their max bin-per-bin pull (in absolute value) with respect to a reference histogram","title":"evaluate( self, histograms )"},{"location":"src/classifiers/MaxPullClassifier/#getpull-self-histogram","text":"get the pull histogram for a given test histogram input arguments: histogram: a single histogram, i.e. numpy array of shape (nbins) for 1D or (nybins,nxbins) for 2D. output: numpy array of same shape as histogram containing bin-per-bin pull w.r.t. reference histogram","title":"getpull( self, histogram )"},{"location":"src/classifiers/NMFClassifier/","text":"NMFClassifier NMFClassifier(HistogramClassifier) histogram classification based on nonnegative matrix factorization specifically intended for 2D histograms, but should in principle work for 1D as well. it is basically a wrapper for a sklearn.decomposition.NMF instance. __init__( self, histograms, ncomponents ) initializer from a collection of histograms input arguments: - histograms: a numpy array of shape (nhists,nbins) or (nhists,nybins,nxbins) that will be used to fit a NMF model - ncomponents: number of NMF components (aka clusters aka basis vectors) to use in the decomposition TODO: add keyword arguments to pass down to sklearn.decomposition.NMF evaluate( self, histograms, nmax ) classify the given histograms based on the MSE with respect to their reconstructed version input arguments: - histograms: numpy array of shape (nhists,nbins) or (nhists,nybins,nxbins) - nmax: number of largest elements to keep in mean square error calculation getcomponents( self ) return the NMF components (aka cluster centers aka basis vectors) output: a numpy array of shape (ncomponents,nbins) or (ncomponents,nybins,nxbins) reconstruct( self, histograms ) return the NMF reconstruction for a given set of histograms input arguments: - histograms: numpy array of shape (nhists,nbins) or (nhists,nybins,nxbins)","title":"NMFClassifier"},{"location":"src/classifiers/NMFClassifier/#nmfclassifier","text":"","title":"NMFClassifier"},{"location":"src/classifiers/NMFClassifier/#nmfclassifierhistogramclassifier","text":"histogram classification based on nonnegative matrix factorization specifically intended for 2D histograms, but should in principle work for 1D as well. it is basically a wrapper for a sklearn.decomposition.NMF instance.","title":"NMFClassifier(HistogramClassifier)"},{"location":"src/classifiers/NMFClassifier/#9595init9595-self-histograms-ncomponents","text":"initializer from a collection of histograms input arguments: - histograms: a numpy array of shape (nhists,nbins) or (nhists,nybins,nxbins) that will be used to fit a NMF model - ncomponents: number of NMF components (aka clusters aka basis vectors) to use in the decomposition TODO: add keyword arguments to pass down to sklearn.decomposition.NMF","title":"__init__( self, histograms, ncomponents )"},{"location":"src/classifiers/NMFClassifier/#evaluate-self-histograms-nmax","text":"classify the given histograms based on the MSE with respect to their reconstructed version input arguments: - histograms: numpy array of shape (nhists,nbins) or (nhists,nybins,nxbins) - nmax: number of largest elements to keep in mean square error calculation","title":"evaluate( self, histograms, nmax )"},{"location":"src/classifiers/NMFClassifier/#getcomponents-self","text":"return the NMF components (aka cluster centers aka basis vectors) output: a numpy array of shape (ncomponents,nbins) or (ncomponents,nybins,nxbins)","title":"getcomponents( self )"},{"location":"src/classifiers/NMFClassifier/#reconstruct-self-histograms","text":"return the NMF reconstruction for a given set of histograms input arguments: - histograms: numpy array of shape (nhists,nbins) or (nhists,nybins,nxbins)","title":"reconstruct( self, histograms )"},{"location":"src/classifiers/TemplateBasedClassifier/","text":"TemplateBasedClassifier mseTopN_templates( histograms, templates, n=-1 ) calculate the mse between each histogram in histograms and each histogram in templates input arguments: - histograms: 2D numpy array of shape (nhistograms, nbins) - templates: 2D numpy array of shape (ntemplates,nbins) - n: integer representing the number of (sorted) bin squared errors to take into account (default: all) output: 2D numpy array of shape (nhistograms,ntemplates) holding the mseTopN between each mseTopN_min( histograms, templates, n=-1 ) calculate the mse betwee a histogram and each template and return the minimum input arguments: - histograms: 2D numpy array of shape (nhistograms, nbins) - templates: 2D numpy array of shape (ntemplates,nbins) - n: integer representing the number of (sorted) bin squared errors to take into account (default: all) output: 1D numpy array of shape (nhistograms) holding the minimum mseTopN for each histogram mseTop10_min( histograms, templates ) special case of above with n=10 mseTopN_avg( histograms, templates, n=-1 ) calculate the mse betwee a histogram and each template and return the average input arguments: - histograms: 2D numpy array of shape (nhistograms, nbins) - templates: 2D numpy array of shape (ntemplates,nbins) - n: integer representing the number of (sorted) bin squared errors to take into account (default: all) output: 1D numpy array of shape (nhistograms) holding the average mseTopN for each histogram mseTop10_avg( histograms, templates ) special case of above with n=10 TemplateBasedClassifier(HistogramClassifier) histogram classifier based on a direct comparison with templates (i.e. reference histograms) __init__( self, templates, comparemethod='minmse' ) initializer from a set of templates (reference histograms) input arguments: - templates: a 2D numpy array of shape (nhistograms,nbins) - comparemethod: string representing the method by which to compare a histogram with a set of templates currently supported methods are: - minmse: minimum mean square error between histogram and all templates - avgmse: average mean square error between histogram and all templates evaluate( self, histograms ) classification of a collection of histograms based on their deviation from templates","title":"TemplateBasedClassifier"},{"location":"src/classifiers/TemplateBasedClassifier/#templatebasedclassifier","text":"","title":"TemplateBasedClassifier"},{"location":"src/classifiers/TemplateBasedClassifier/#msetopn95templates-histograms-templates-n-1","text":"calculate the mse between each histogram in histograms and each histogram in templates input arguments: - histograms: 2D numpy array of shape (nhistograms, nbins) - templates: 2D numpy array of shape (ntemplates,nbins) - n: integer representing the number of (sorted) bin squared errors to take into account (default: all) output: 2D numpy array of shape (nhistograms,ntemplates) holding the mseTopN between each","title":"mseTopN_templates( histograms, templates, n=-1 )"},{"location":"src/classifiers/TemplateBasedClassifier/#msetopn95min-histograms-templates-n-1","text":"calculate the mse betwee a histogram and each template and return the minimum input arguments: - histograms: 2D numpy array of shape (nhistograms, nbins) - templates: 2D numpy array of shape (ntemplates,nbins) - n: integer representing the number of (sorted) bin squared errors to take into account (default: all) output: 1D numpy array of shape (nhistograms) holding the minimum mseTopN for each histogram","title":"mseTopN_min( histograms, templates, n=-1 )"},{"location":"src/classifiers/TemplateBasedClassifier/#msetop1095min-histograms-templates","text":"special case of above with n=10","title":"mseTop10_min( histograms, templates )"},{"location":"src/classifiers/TemplateBasedClassifier/#msetopn95avg-histograms-templates-n-1","text":"calculate the mse betwee a histogram and each template and return the average input arguments: - histograms: 2D numpy array of shape (nhistograms, nbins) - templates: 2D numpy array of shape (ntemplates,nbins) - n: integer representing the number of (sorted) bin squared errors to take into account (default: all) output: 1D numpy array of shape (nhistograms) holding the average mseTopN for each histogram","title":"mseTopN_avg( histograms, templates, n=-1 )"},{"location":"src/classifiers/TemplateBasedClassifier/#msetop1095avg-histograms-templates","text":"special case of above with n=10","title":"mseTop10_avg( histograms, templates )"},{"location":"src/classifiers/TemplateBasedClassifier/#templatebasedclassifierhistogramclassifier","text":"histogram classifier based on a direct comparison with templates (i.e. reference histograms)","title":"TemplateBasedClassifier(HistogramClassifier)"},{"location":"src/classifiers/TemplateBasedClassifier/#9595init9595-self-templates-comparemethodminmse","text":"initializer from a set of templates (reference histograms) input arguments: - templates: a 2D numpy array of shape (nhistograms,nbins) - comparemethod: string representing the method by which to compare a histogram with a set of templates currently supported methods are: - minmse: minimum mean square error between histogram and all templates - avgmse: average mean square error between histogram and all templates","title":"__init__( self, templates, comparemethod='minmse' )"},{"location":"src/classifiers/TemplateBasedClassifier/#evaluate-self-histograms","text":"classification of a collection of histograms based on their deviation from templates","title":"evaluate( self, histograms )"},{"location":"src/cloudfitters/CloudFitter/","text":"CloudFitter CloudFitter(ABC) abstract base class for all point cloud fitting algorithms note that all concrete point cloud fitters must inherit from CloudFitter! how to make a concrete CloudFitter class: - define a class that inherits from CloudFitter - make sure all functions with @abstractmethod are implemented in your class - it is recommended to start each overriding function with a call to super(), but this is not strictly necessary see also the existing examples! __init__( self, points ) default intializer - points: 2D numpy array of shape (npoints,ndims) pdf( self, points ) evaluate the pdf (probability density function) at given points - points: a 2D numpy array of shape (npoints,ndims) output: a 1D array of shape (npoints)","title":"CloudFitter"},{"location":"src/cloudfitters/CloudFitter/#cloudfitter","text":"","title":"CloudFitter"},{"location":"src/cloudfitters/CloudFitter/#cloudfitterabc","text":"abstract base class for all point cloud fitting algorithms note that all concrete point cloud fitters must inherit from CloudFitter! how to make a concrete CloudFitter class: - define a class that inherits from CloudFitter - make sure all functions with @abstractmethod are implemented in your class - it is recommended to start each overriding function with a call to super(), but this is not strictly necessary see also the existing examples!","title":"CloudFitter(ABC)"},{"location":"src/cloudfitters/CloudFitter/#9595init9595-self-points","text":"default intializer - points: 2D numpy array of shape (npoints,ndims)","title":"__init__( self, points )"},{"location":"src/cloudfitters/CloudFitter/#pdf-self-points","text":"evaluate the pdf (probability density function) at given points - points: a 2D numpy array of shape (npoints,ndims) output: a 1D array of shape (npoints)","title":"pdf( self, points )"},{"location":"src/cloudfitters/ExponentialFitter/","text":"ExponentialFitter ExponentialFitter(CloudFitter) class for fitting an exponential distribution to a point cloud parameters - l: multidimensional lambda parameter of exponential __init__(self,points) constructor points is a np array of shape (npoints,ndims) pdf(self,points) get pdf at points","title":"ExponentialFitter"},{"location":"src/cloudfitters/ExponentialFitter/#exponentialfitter","text":"","title":"ExponentialFitter"},{"location":"src/cloudfitters/ExponentialFitter/#exponentialfittercloudfitter","text":"class for fitting an exponential distribution to a point cloud parameters - l: multidimensional lambda parameter of exponential","title":"ExponentialFitter(CloudFitter)"},{"location":"src/cloudfitters/ExponentialFitter/#9595init9595selfpoints","text":"constructor points is a np array of shape (npoints,ndims)","title":"__init__(self,points)"},{"location":"src/cloudfitters/ExponentialFitter/#pdfselfpoints","text":"get pdf at points","title":"pdf(self,points)"},{"location":"src/cloudfitters/GaussianKdeFitter/","text":"GaussianKdeFitter GaussianKdeFitter(CloudFitter) class for fitting a gaussian kernel density to a point cloud basically a wrapper for scipy.stats.gaussian_kde. parameters - kernel: scipy.stats.gaussian_kde object - cov: covariance matrix (use np.cov for now, maybe later replace by internal kernel.covariance) __init__(self,points,bw_method='scott') constructor input arguments: - points: a np array of shape (npoints,ndims) - bw_method: method to calculate the bandwidth of the gaussians, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html pdf(self,points) get pdf at points","title":"GaussianKdeFitter"},{"location":"src/cloudfitters/GaussianKdeFitter/#gaussiankdefitter","text":"","title":"GaussianKdeFitter"},{"location":"src/cloudfitters/GaussianKdeFitter/#gaussiankdefittercloudfitter","text":"class for fitting a gaussian kernel density to a point cloud basically a wrapper for scipy.stats.gaussian_kde. parameters - kernel: scipy.stats.gaussian_kde object - cov: covariance matrix (use np.cov for now, maybe later replace by internal kernel.covariance)","title":"GaussianKdeFitter(CloudFitter)"},{"location":"src/cloudfitters/GaussianKdeFitter/#9595init9595selfpointsbw95methodscott","text":"constructor input arguments: - points: a np array of shape (npoints,ndims) - bw_method: method to calculate the bandwidth of the gaussians, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html","title":"__init__(self,points,bw_method='scott')"},{"location":"src/cloudfitters/GaussianKdeFitter/#pdfselfpoints","text":"get pdf at points","title":"pdf(self,points)"},{"location":"src/cloudfitters/LogNormalFitter/","text":"LogNormalFitter LogNormalFitter(CloudFitter) class for fitting a log-normal distribution to a point cloud parameters: - mean: multidim mean of underlying normal - cov: multidim covariance matrix of underlying normal - mvn: scipy.stats multivariate_normal object built from the mean and cov __init__(self,points) constructor points is a np array of shape (npoints,ndims) pdf(self,points) get pdf at points","title":"LogNormalFitter"},{"location":"src/cloudfitters/LogNormalFitter/#lognormalfitter","text":"","title":"LogNormalFitter"},{"location":"src/cloudfitters/LogNormalFitter/#lognormalfittercloudfitter","text":"class for fitting a log-normal distribution to a point cloud parameters: - mean: multidim mean of underlying normal - cov: multidim covariance matrix of underlying normal - mvn: scipy.stats multivariate_normal object built from the mean and cov","title":"LogNormalFitter(CloudFitter)"},{"location":"src/cloudfitters/LogNormalFitter/#9595init9595selfpoints","text":"constructor points is a np array of shape (npoints,ndims)","title":"__init__(self,points)"},{"location":"src/cloudfitters/LogNormalFitter/#pdfselfpoints","text":"get pdf at points","title":"pdf(self,points)"},{"location":"src/cloudfitters/SeminormalFitter/","text":"SeminormalFitter SeminormalFitter(CloudFitter) class for fitting a 'seminormal' distribution to a point cloud this is not strictly speaking a probability distribution, only the first quadrant of the result of fitting a normal distribution to the data + its mirror image wrt the origin. parameters - cov: multidim covariance matrix of normal distribution - mvn: scipy.stats multivariate_normal object built from the cov __init__(self,points) constructor points is a np array of shape (npoints,ndims) note: points can also be an array or list with length 0, in that case the object is initialized empty. use this followed by the 'load' method to load a previously saved fit! pdf(self,points) get pdf at points save(self,path) save the covariance matrix as a .npy file specified by path load(self,path) load a covariance matrix from a .npy file specified by path and build the fit from it","title":"SeminormalFitter"},{"location":"src/cloudfitters/SeminormalFitter/#seminormalfitter","text":"","title":"SeminormalFitter"},{"location":"src/cloudfitters/SeminormalFitter/#seminormalfittercloudfitter","text":"class for fitting a 'seminormal' distribution to a point cloud this is not strictly speaking a probability distribution, only the first quadrant of the result of fitting a normal distribution to the data + its mirror image wrt the origin. parameters - cov: multidim covariance matrix of normal distribution - mvn: scipy.stats multivariate_normal object built from the cov","title":"SeminormalFitter(CloudFitter)"},{"location":"src/cloudfitters/SeminormalFitter/#9595init9595selfpoints","text":"constructor points is a np array of shape (npoints,ndims) note: points can also be an array or list with length 0, in that case the object is initialized empty. use this followed by the 'load' method to load a previously saved fit!","title":"__init__(self,points)"},{"location":"src/cloudfitters/SeminormalFitter/#pdfselfpoints","text":"get pdf at points","title":"pdf(self,points)"},{"location":"src/cloudfitters/SeminormalFitter/#saveselfpath","text":"save the covariance matrix as a .npy file specified by path","title":"save(self,path)"},{"location":"src/cloudfitters/SeminormalFitter/#loadselfpath","text":"load a covariance matrix from a .npy file specified by path and build the fit from it","title":"load(self,path)"},{"location":"utils/autoencoder_utils/","text":"autoencoder utils mseTop10(y_true, y_pred) MSE top 10 loss function for autoencoder training input arguments: - y_true and y_pred: two numpy arrays of equal shape, typically a histogram and its autoencoder reconstruction. if two-dimensional, the arrays are assumed to have shape (nhists,nbins)! output: - mean squared error between y_true and y_pred, where only the 10 bins with largest squared error are taken into account. if y_true and y_pred are 2D arrays, this function returns 1D array (mseTop10 for each histogram) mseTop10Raw(y_true, y_pred) same as mseTop10 but without using tf or K the version including tf or K seemed to cause randomly dying kernels, no clear reason could be found, but it was solved using this loss function instead. verified that it gives exactly the same output as the function above on some random arrays. contrary to mseTop10, this function only works for arrays with 2D shapes (so shape (nhists,nbins)), not for (nbins,). mseTopNRaw(y_true, y_pred, n=10) generalization of mseTop10Raw to any number of bins to take into account note: now generalized to also work for 2D histograms, i.e. arrays of shape (nhists,nybins,nxbins)! hence this is the most general method and preferred above mseTop10 and mseTop10Raw, which are only kept for reference input arguments: - y_true, y_pred: numpy arrays between which to calculate the mean square difference, of shape (nhists,nbins) or (nhists,nybins,nxbins) - n: number of largest elements to keep for averaging output: numpy array of shape (nhists) chiSquared(y_true, y_pred) chi2 loss functionfor autoencoder training input arguments: - y_true and y_pred: two numpy arrays of equal shape, typically a histogram and its autoencoder reconstruction. if two-dimensional, the arrays are assumed to have shape (nhists,nbins)! output: - relative mean squared error between y_true and y_pred, if y_true and y_pred are 2D arrays, this function returns 1D array (chiSquared for each histogram) chiSquaredTop10(y_true, y_pred) same as chiSquared but take into account only 10 largest values in averaging. calculate_roc(scores, labels, scoreax) calculate a roc curve input arguments: - scores is a 1D numpy array containing output scores of any algorithm - labels is a 1D numpy array (equally long as scores) containing labels note that 1 for signal and 0 for background is assumed! this convention is only used to define what scores belong to signal or background; the scores itself can be anything (not limited to (0,1)), as long as the target for signal is higher than the target for background - scoreax is an array of score thresholds for which to compute the signal and background efficiency, assumed to be sorted in increasing order (i.e. from loose to tight) output: tuple of two np arrays (signal efficiency and background efficiency) get_roc(scores, labels, mode='lin', npoints=100, doprint=False, doplot=True, plotmode='classic') make a ROC curve input arguments: - scores is a 1D numpy array containing output scores of any algorithm - labels is a 1D numpy array (equally long as scores) containing labels note that 1 for signal and 0 for background is assumed! this convention is only used to define what scores belong to signal or background; the scores itself can be anything (not limited to (0,1)), as long as the target for signal is higher than the target for background - mode: how to determine the points where to calculate signal and background efficiencies; options are: - 'lin': np.linspace between min and max score - 'geom': np. geomspace between min and max score - 'full': one point per score instance - npoints: number of points where to calculate the signal and background efficiencies (ignored if mode is 'full') - doprint: boolean whether to print score thresholds and corresponding signal and background efficiencies - doplot: boolean whether to make a plot or simply return the auc. - plotmode: how to plot the roc curve; options are: - 'classic' = signal efficiency afo background efficiency get_roc_from_hists(hists, labels, predicted_hists, mode='lin', npoints=100, doprint=False, doplot=True, plotmode='classic') make a ROC curve without manually calculating the scores the output score is the mseTop10Raw between the histograms and their reconstruction - input arguments: - hists and predicted_hists are 2D numpy arrays of shape (nhistograms,nbins) - other arguments: see get_roc get_confusion_matrix(scores, labels, wp) plot a confusion matrix scores and labels are defined in the same way as for get_roc wp is the chosen working point (i.e. any score above wp is flagged as signal, any below is flagged as background) get_confusion_matrix_from_hists(hists, labels, predicted_hists, msewp) plot a confusion matrix without manually calculating the scores the output score is the mse between the histograms and their reconstruction getautoencoder(input_size,arch,act=[],opt='adam',loss=mseTop10) get a trainable autoencoder model input args: - input_size: size of vector that autoencoder will operate on - arch: list of number of nodes per hidden layer (excluding input and output layer) - act: list of activations per layer (default: tanh) - opt: optimizer to use (default: adam) - loss: loss function to use (defualt: mseTop10) train_simple_autoencoder(hists,nepochs=-1,modelname='') create and train a very simple keras model the model consists of one hidden layer (with half as many units as there are input bins), tanh activation, adam optimizer and mseTop10 loss. input args: - hists is a 2D numpy array of shape (nhistograms, nbins) - nepochs is the number of epochs to use (has a default value if left unspecified) - modelname is a file name to save the model in (default: model is not saved to a file)","title":"autoencoder_utils"},{"location":"utils/autoencoder_utils/#autoencoder-utils","text":"","title":"autoencoder utils"},{"location":"utils/autoencoder_utils/#msetop10y95true-y95pred","text":"MSE top 10 loss function for autoencoder training input arguments: - y_true and y_pred: two numpy arrays of equal shape, typically a histogram and its autoencoder reconstruction. if two-dimensional, the arrays are assumed to have shape (nhists,nbins)! output: - mean squared error between y_true and y_pred, where only the 10 bins with largest squared error are taken into account. if y_true and y_pred are 2D arrays, this function returns 1D array (mseTop10 for each histogram)","title":"mseTop10(y_true, y_pred)"},{"location":"utils/autoencoder_utils/#msetop10rawy95true-y95pred","text":"same as mseTop10 but without using tf or K the version including tf or K seemed to cause randomly dying kernels, no clear reason could be found, but it was solved using this loss function instead. verified that it gives exactly the same output as the function above on some random arrays. contrary to mseTop10, this function only works for arrays with 2D shapes (so shape (nhists,nbins)), not for (nbins,).","title":"mseTop10Raw(y_true, y_pred)"},{"location":"utils/autoencoder_utils/#msetopnrawy95true-y95pred-n10","text":"generalization of mseTop10Raw to any number of bins to take into account note: now generalized to also work for 2D histograms, i.e. arrays of shape (nhists,nybins,nxbins)! hence this is the most general method and preferred above mseTop10 and mseTop10Raw, which are only kept for reference input arguments: - y_true, y_pred: numpy arrays between which to calculate the mean square difference, of shape (nhists,nbins) or (nhists,nybins,nxbins) - n: number of largest elements to keep for averaging output: numpy array of shape (nhists)","title":"mseTopNRaw(y_true, y_pred, n=10)"},{"location":"utils/autoencoder_utils/#chisquaredy95true-y95pred","text":"chi2 loss functionfor autoencoder training input arguments: - y_true and y_pred: two numpy arrays of equal shape, typically a histogram and its autoencoder reconstruction. if two-dimensional, the arrays are assumed to have shape (nhists,nbins)! output: - relative mean squared error between y_true and y_pred, if y_true and y_pred are 2D arrays, this function returns 1D array (chiSquared for each histogram)","title":"chiSquared(y_true, y_pred)"},{"location":"utils/autoencoder_utils/#chisquaredtop10y95true-y95pred","text":"same as chiSquared but take into account only 10 largest values in averaging.","title":"chiSquaredTop10(y_true, y_pred)"},{"location":"utils/autoencoder_utils/#calculate95rocscores-labels-scoreax","text":"calculate a roc curve input arguments: - scores is a 1D numpy array containing output scores of any algorithm - labels is a 1D numpy array (equally long as scores) containing labels note that 1 for signal and 0 for background is assumed! this convention is only used to define what scores belong to signal or background; the scores itself can be anything (not limited to (0,1)), as long as the target for signal is higher than the target for background - scoreax is an array of score thresholds for which to compute the signal and background efficiency, assumed to be sorted in increasing order (i.e. from loose to tight) output: tuple of two np arrays (signal efficiency and background efficiency)","title":"calculate_roc(scores, labels, scoreax)"},{"location":"utils/autoencoder_utils/#get95rocscores-labels-modelin-npoints100-doprintfalse-doplottrue-plotmodeclassic","text":"make a ROC curve input arguments: - scores is a 1D numpy array containing output scores of any algorithm - labels is a 1D numpy array (equally long as scores) containing labels note that 1 for signal and 0 for background is assumed! this convention is only used to define what scores belong to signal or background; the scores itself can be anything (not limited to (0,1)), as long as the target for signal is higher than the target for background - mode: how to determine the points where to calculate signal and background efficiencies; options are: - 'lin': np.linspace between min and max score - 'geom': np. geomspace between min and max score - 'full': one point per score instance - npoints: number of points where to calculate the signal and background efficiencies (ignored if mode is 'full') - doprint: boolean whether to print score thresholds and corresponding signal and background efficiencies - doplot: boolean whether to make a plot or simply return the auc. - plotmode: how to plot the roc curve; options are: - 'classic' = signal efficiency afo background efficiency","title":"get_roc(scores, labels, mode='lin', npoints=100, doprint=False, doplot=True, plotmode='classic')"},{"location":"utils/autoencoder_utils/#get95roc95from95histshists-labels-predicted95hists-modelin-npoints100-doprintfalse-doplottrue-plotmodeclassic","text":"make a ROC curve without manually calculating the scores the output score is the mseTop10Raw between the histograms and their reconstruction - input arguments: - hists and predicted_hists are 2D numpy arrays of shape (nhistograms,nbins) - other arguments: see get_roc","title":"get_roc_from_hists(hists, labels, predicted_hists, mode='lin', npoints=100, doprint=False, doplot=True, plotmode='classic')"},{"location":"utils/autoencoder_utils/#get95confusion95matrixscores-labels-wp","text":"plot a confusion matrix scores and labels are defined in the same way as for get_roc wp is the chosen working point (i.e. any score above wp is flagged as signal, any below is flagged as background)","title":"get_confusion_matrix(scores, labels, wp)"},{"location":"utils/autoencoder_utils/#get95confusion95matrix95from95histshists-labels-predicted95hists-msewp","text":"plot a confusion matrix without manually calculating the scores the output score is the mse between the histograms and their reconstruction","title":"get_confusion_matrix_from_hists(hists, labels, predicted_hists, msewp)"},{"location":"utils/autoencoder_utils/#getautoencoderinput95sizearchactoptadamlossmsetop10","text":"get a trainable autoencoder model input args: - input_size: size of vector that autoencoder will operate on - arch: list of number of nodes per hidden layer (excluding input and output layer) - act: list of activations per layer (default: tanh) - opt: optimizer to use (default: adam) - loss: loss function to use (defualt: mseTop10)","title":"getautoencoder(input_size,arch,act=[],opt='adam',loss=mseTop10)"},{"location":"utils/autoencoder_utils/#train95simple95autoencoderhistsnepochs-1modelname","text":"create and train a very simple keras model the model consists of one hidden layer (with half as many units as there are input bins), tanh activation, adam optimizer and mseTop10 loss. input args: - hists is a 2D numpy array of shape (nhistograms, nbins) - nepochs is the number of epochs to use (has a default value if left unspecified) - modelname is a file name to save the model in (default: model is not saved to a file)","title":"train_simple_autoencoder(hists,nepochs=-1,modelname='')"},{"location":"utils/clustering_utils/","text":"clustering utils dummy() general remark: the functions in this script are currently not supported anymore please ignore clustering_utils for now, it will probably be removed or completely reworked vecdist(moments,index) (no valid documentation found) costhetadist(moments,index) (no valid documentation found) avgnndist(moments,index,nn) (no valid documentation found) getavgnndist(hists,nmoments,xmin,xmax,nbins,nneighbours) (no valid documentation found) filteranomalous(df,nmoments=3,rmouterflow=True,rmlargest=0.,doplot=True,) (no valid documentation found)","title":"clustering_utils"},{"location":"utils/clustering_utils/#clustering-utils","text":"","title":"clustering utils"},{"location":"utils/clustering_utils/#dummy","text":"general remark: the functions in this script are currently not supported anymore please ignore clustering_utils for now, it will probably be removed or completely reworked","title":"dummy()"},{"location":"utils/clustering_utils/#vecdistmomentsindex","text":"(no valid documentation found)","title":"vecdist(moments,index)"},{"location":"utils/clustering_utils/#costhetadistmomentsindex","text":"(no valid documentation found)","title":"costhetadist(moments,index)"},{"location":"utils/clustering_utils/#avgnndistmomentsindexnn","text":"(no valid documentation found)","title":"avgnndist(moments,index,nn)"},{"location":"utils/clustering_utils/#getavgnndisthistsnmomentsxminxmaxnbinsnneighbours","text":"(no valid documentation found)","title":"getavgnndist(hists,nmoments,xmin,xmax,nbins,nneighbours)"},{"location":"utils/clustering_utils/#filteranomalousdfnmoments3rmouterflowtruermlargest0doplottrue","text":"(no valid documentation found)","title":"filteranomalous(df,nmoments=3,rmouterflow=True,rmlargest=0.,doplot=True,)"},{"location":"utils/csv_utils/","text":"csv utils get_data_dirs(year='2017', eras=[], dim=1) yield all data directories note that the location of the data is hard-coded; this function might break for newer or later reprocessings of the data. - year is a string, either '2017' or '2018' - era is a list containing a selection of era names (default empty list = all eras) - dim is either 1 or 2 (for 1D or 2D plots) get_csv_files(inputdir) yields paths to all csv files in input directory note that the output paths consist of input_dir/filename this function is only meant for 1-level down searching, i.e. the .csv files listed directly under input_dir. sort_filenames(filelist) sort filenames in numerical order (e.g. 2 before 10) note that the number is supposed to be in ..._ . format read_csv(csv_file) read csv file into pandas dataframe csv_file is the path to the csv file to be read write_csv(dataframe,csvfilename) write a dataframe to a csv file note: just a wrapper for builtin dataframe.to_csv read_and_merge_csv(csv_files, histnames=[], runnbs=[]) read and merge list of csv files into a single df csv_files is a list of paths to files to merge into a df histnames is a list of the types of histograms to keep (default: all) runnbs is a list of run numbers to keep (default: all) write_skimmed_csv(histnames, year, eras=['all'], dim=1) read all available data for a given year/era and make a file per histogram type input arguments: - histnames: list of histogram names for which to make a separate file - year: data-taking year (in string format) - eras: data-taking eras for which to make a separate file (in string format) use 'all' to make a file with all eras merged, i.e. a full data taking year - dim: dimension of histograms (1 or 2), needed to retrieve the correct folder containing input files output: - one csv file per year/era and per histogram type note: this function can take quite a while to run!","title":"csv_utils"},{"location":"utils/csv_utils/#csv-utils","text":"","title":"csv utils"},{"location":"utils/csv_utils/#get95data95dirsyear2017-eras-dim1","text":"yield all data directories note that the location of the data is hard-coded; this function might break for newer or later reprocessings of the data. - year is a string, either '2017' or '2018' - era is a list containing a selection of era names (default empty list = all eras) - dim is either 1 or 2 (for 1D or 2D plots)","title":"get_data_dirs(year='2017', eras=[], dim=1)"},{"location":"utils/csv_utils/#get95csv95filesinputdir","text":"yields paths to all csv files in input directory note that the output paths consist of input_dir/filename this function is only meant for 1-level down searching, i.e. the .csv files listed directly under input_dir.","title":"get_csv_files(inputdir)"},{"location":"utils/csv_utils/#sort95filenamesfilelist","text":"sort filenames in numerical order (e.g. 2 before 10) note that the number is supposed to be in ..._ . format","title":"sort_filenames(filelist)"},{"location":"utils/csv_utils/#read95csvcsv95file","text":"read csv file into pandas dataframe csv_file is the path to the csv file to be read","title":"read_csv(csv_file)"},{"location":"utils/csv_utils/#write95csvdataframecsvfilename","text":"write a dataframe to a csv file note: just a wrapper for builtin dataframe.to_csv","title":"write_csv(dataframe,csvfilename)"},{"location":"utils/csv_utils/#read95and95merge95csvcsv95files-histnames-runnbs","text":"read and merge list of csv files into a single df csv_files is a list of paths to files to merge into a df histnames is a list of the types of histograms to keep (default: all) runnbs is a list of run numbers to keep (default: all)","title":"read_and_merge_csv(csv_files, histnames=[], runnbs=[])"},{"location":"utils/csv_utils/#write95skimmed95csvhistnames-year-erasall-dim1","text":"read all available data for a given year/era and make a file per histogram type input arguments: - histnames: list of histogram names for which to make a separate file - year: data-taking year (in string format) - eras: data-taking eras for which to make a separate file (in string format) use 'all' to make a file with all eras merged, i.e. a full data taking year - dim: dimension of histograms (1 or 2), needed to retrieve the correct folder containing input files output: - one csv file per year/era and per histogram type note: this function can take quite a while to run!","title":"write_skimmed_csv(histnames, year, eras=['all'], dim=1)"},{"location":"utils/dataframe_utils/","text":"dataframe utils get_histnames(df) get a list of (unique) histogram names present in a df df is a dataframe read from an input csv file. select_histnames(df, histnames) keep only a subset of histograms in a df histnames is a list of histogram names to keep in the df. get_runs(df) return a list of (unique) run numbers present in a df df is a dataframe read from an input csv file. select_runs(df, runnbs) keep only a subset of runs in a df runnbs is a list of run numbers to keep in the df. get_ls(df) return a list of ls numbers present in a df note that the numbers are not required to be unique! note: no check is done on the run number! select_ls(df, lsnbs) keep only a subset of lumisection numbers in a df lsnbs is a list of lumisection numbers to keep in the df. note: no check is done on the run number! get_runsls(df) return a dictionary with runs and lumisections in a dataframe (same format as e.g. golden json) select_json(df, jsonfile) keep only lumisections that are in the given json file select_runsls(df, jsondict) equivalent to select_json but using a pre-loaded json dict instead of a json file on disk select_golden(df) keep only golden lumisections in df select_notgolden(df) keep all but golden lumisections in df select_dcson(df) keep only lumisections in df that have DCS-bit on select_dcsoff(df) keep only lumisections in df that have DCS-bit off select_pixelgood(df) keep only lumisections in df that are in good pixel json select_pixelbad(df) keep only lumisections in df that are in bad pixel json get_highstat(df, entries_to_bins_ratio=100) return a select object of runs and ls of histograms with high statistics select_highstat(df, entries_to_bins_ratio=100) keep only lumisection in df with high statistics get_hist_values(df) same as builtin \"df['histo'].values\" but convert strings to np arrays input arguments: - df: a dataframe containing histograms (assumed to be of a single type!) note: this function works for both 1D and 2D histograms, the distinction is made based on whether or not 'Ybins' is present as a column in the dataframe update: 'Ybins' is also present for 1D histograms, but has value 1! output: a tuple containing the following elements: - np array of shape (nhists,nbins) (for 1D) or (nhists,nybins,nxbins) (for 2D) - np array of run numbers of length nhists - np array of lumisection numbers of length nhists warning: no check is done to assure that all histograms are of the same type!","title":"dataframe_utils"},{"location":"utils/dataframe_utils/#dataframe-utils","text":"","title":"dataframe utils"},{"location":"utils/dataframe_utils/#get95histnamesdf","text":"get a list of (unique) histogram names present in a df df is a dataframe read from an input csv file.","title":"get_histnames(df)"},{"location":"utils/dataframe_utils/#select95histnamesdf-histnames","text":"keep only a subset of histograms in a df histnames is a list of histogram names to keep in the df.","title":"select_histnames(df, histnames)"},{"location":"utils/dataframe_utils/#get95runsdf","text":"return a list of (unique) run numbers present in a df df is a dataframe read from an input csv file.","title":"get_runs(df)"},{"location":"utils/dataframe_utils/#select95runsdf-runnbs","text":"keep only a subset of runs in a df runnbs is a list of run numbers to keep in the df.","title":"select_runs(df, runnbs)"},{"location":"utils/dataframe_utils/#get95lsdf","text":"return a list of ls numbers present in a df note that the numbers are not required to be unique! note: no check is done on the run number!","title":"get_ls(df)"},{"location":"utils/dataframe_utils/#select95lsdf-lsnbs","text":"keep only a subset of lumisection numbers in a df lsnbs is a list of lumisection numbers to keep in the df. note: no check is done on the run number!","title":"select_ls(df, lsnbs)"},{"location":"utils/dataframe_utils/#get95runslsdf","text":"return a dictionary with runs and lumisections in a dataframe (same format as e.g. golden json)","title":"get_runsls(df)"},{"location":"utils/dataframe_utils/#select95jsondf-jsonfile","text":"keep only lumisections that are in the given json file","title":"select_json(df, jsonfile)"},{"location":"utils/dataframe_utils/#select95runslsdf-jsondict","text":"equivalent to select_json but using a pre-loaded json dict instead of a json file on disk","title":"select_runsls(df, jsondict)"},{"location":"utils/dataframe_utils/#select95goldendf","text":"keep only golden lumisections in df","title":"select_golden(df)"},{"location":"utils/dataframe_utils/#select95notgoldendf","text":"keep all but golden lumisections in df","title":"select_notgolden(df)"},{"location":"utils/dataframe_utils/#select95dcsondf","text":"keep only lumisections in df that have DCS-bit on","title":"select_dcson(df)"},{"location":"utils/dataframe_utils/#select95dcsoffdf","text":"keep only lumisections in df that have DCS-bit off","title":"select_dcsoff(df)"},{"location":"utils/dataframe_utils/#select95pixelgooddf","text":"keep only lumisections in df that are in good pixel json","title":"select_pixelgood(df)"},{"location":"utils/dataframe_utils/#select95pixelbaddf","text":"keep only lumisections in df that are in bad pixel json","title":"select_pixelbad(df)"},{"location":"utils/dataframe_utils/#get95highstatdf-entries95to95bins95ratio100","text":"return a select object of runs and ls of histograms with high statistics","title":"get_highstat(df, entries_to_bins_ratio=100)"},{"location":"utils/dataframe_utils/#select95highstatdf-entries95to95bins95ratio100","text":"keep only lumisection in df with high statistics","title":"select_highstat(df, entries_to_bins_ratio=100)"},{"location":"utils/dataframe_utils/#get95hist95valuesdf","text":"same as builtin \"df['histo'].values\" but convert strings to np arrays input arguments: - df: a dataframe containing histograms (assumed to be of a single type!) note: this function works for both 1D and 2D histograms, the distinction is made based on whether or not 'Ybins' is present as a column in the dataframe update: 'Ybins' is also present for 1D histograms, but has value 1! output: a tuple containing the following elements: - np array of shape (nhists,nbins) (for 1D) or (nhists,nybins,nxbins) (for 2D) - np array of run numbers of length nhists - np array of lumisection numbers of length nhists warning: no check is done to assure that all histograms are of the same type!","title":"get_hist_values(df)"},{"location":"utils/generate_data_2d_utils/","text":"generate data 2d utils goodnoise_nd(shape, fstd=None, kmaxscale=0.25, ncomponents=3) generate one sample of 'good' noise consisting of fourier components generalization of goodnoise (see generate_data_utils) to arbitrary number of dimensions input args: - shape: a tuple, shape of the noise array to be sampled note: in case of 1D, a comma is needed e.g. shape = (30,) else it will be automatically parsed to int and raise an error - fstd: an array of shape given by shape argument, used for scaling of the amplitude of the noise bin-by-bin (default: no scaling). - kmaxscale: scale factor to limit maximum frequency (lower kmaxscale means smoother noise) note: can be a tuple with same length as shape, to scale differently in different dimensions. - ncomponents: number of random sines to add per dimension note: can be a tuple with same length as shape, to use a different number of components in different dimensions. output: - numpy array of shape detailed by shape argument containing the noise whitenoise_nd(shape, fstd=None) generate one sample of white noise (standard normally distributed, uncorrelated between bins) generalization of whitenoise (see generate_data_utils) to arbitrary number of dimensions input args: - shape: a tuple, shape of the noise array to be sampled note: in case of 1D, a comma is needed e.g. shape = (30,) else it will be automatically parsed to int and raise an error - fstd: an array of shape given by shape argument, used for scaling of the amplitude of the noise bin-by-bin (default: no scaling). output: - numpy array of shape detailed by shape argument containing the noise random_lico_nd(hists) generate one linear combination of histograms with random coefficients in (0,1) summing to 1. generalization of random_lico (see generate_data_utils) to arbitrary number of dimensions. input args: - numpy array of shape (nhists, ) output: - numpy array of shape ( ), containing the new histogram fourier_noise_nd(hists, outfilename='', figname='', nresamples=1, nonnegative=True, stdfactor=15., kmaxscale=0.25, ncomponents=3) apply fourier noise on random histograms with simple flat amplitude scaling. generalization of fourier_noise (see generate_data_utils) to arbitrary number of dimensions. input args: - hists: numpy array of shape (nhists, ) used for seeding - outfilename: path to csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples to draw per input histogram - nonnegative: boolean whether to set all bins to minimum zero after applying noise - stdfactor: factor to scale magnitude of noise (larger factor = smaller noise) - kmaxscale and ncomponents: see goodnoise_nd white_noise_nd(hists, figname='', nresamples=1, nonnegative=True, stdfactor=15.) apply white noise to the histograms in hists. generalization of white_noise (see generate_data_utils) to arbitrary number of dimensions. input args: - hists: np array (nhists, ) containing input histograms - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples to draw per input histogram - nonnegative: boolean whether to set all bins to minimum zero after applying noise - stdfactor: scaling factor of white noise amplitude (higher factor = smaller noise) resample_lico_nd(hists, nresamples=1, nonnegative=True) take random linear combinations of input histograms generalization of fourier_noise (see generate_data_utils) to arbitrary number of dimensions. input args: - hists: numpy array of shape (nhists, ) used for seeding - nresamples: number of samples to draw - nonnegative: boolean whether to set all bins to minimum zero after applying noise note: coefficients in linear combination are always nonnegative, so this setting is superfluous is input histograms are all nonnegative","title":"generate_data_2d_utils"},{"location":"utils/generate_data_2d_utils/#generate-data-2d-utils","text":"","title":"generate data 2d utils"},{"location":"utils/generate_data_2d_utils/#goodnoise95ndshape-fstdnone-kmaxscale025-ncomponents3","text":"generate one sample of 'good' noise consisting of fourier components generalization of goodnoise (see generate_data_utils) to arbitrary number of dimensions input args: - shape: a tuple, shape of the noise array to be sampled note: in case of 1D, a comma is needed e.g. shape = (30,) else it will be automatically parsed to int and raise an error - fstd: an array of shape given by shape argument, used for scaling of the amplitude of the noise bin-by-bin (default: no scaling). - kmaxscale: scale factor to limit maximum frequency (lower kmaxscale means smoother noise) note: can be a tuple with same length as shape, to scale differently in different dimensions. - ncomponents: number of random sines to add per dimension note: can be a tuple with same length as shape, to use a different number of components in different dimensions. output: - numpy array of shape detailed by shape argument containing the noise","title":"goodnoise_nd(shape, fstd=None, kmaxscale=0.25, ncomponents=3)"},{"location":"utils/generate_data_2d_utils/#whitenoise95ndshape-fstdnone","text":"generate one sample of white noise (standard normally distributed, uncorrelated between bins) generalization of whitenoise (see generate_data_utils) to arbitrary number of dimensions input args: - shape: a tuple, shape of the noise array to be sampled note: in case of 1D, a comma is needed e.g. shape = (30,) else it will be automatically parsed to int and raise an error - fstd: an array of shape given by shape argument, used for scaling of the amplitude of the noise bin-by-bin (default: no scaling). output: - numpy array of shape detailed by shape argument containing the noise","title":"whitenoise_nd(shape, fstd=None)"},{"location":"utils/generate_data_2d_utils/#random95lico95ndhists","text":"generate one linear combination of histograms with random coefficients in (0,1) summing to 1. generalization of random_lico (see generate_data_utils) to arbitrary number of dimensions. input args: - numpy array of shape (nhists, ) output: - numpy array of shape ( ), containing the new histogram","title":"random_lico_nd(hists)"},{"location":"utils/generate_data_2d_utils/#fourier95noise95ndhists-outfilename-figname-nresamples1-nonnegativetrue-stdfactor15-kmaxscale025-ncomponents3","text":"apply fourier noise on random histograms with simple flat amplitude scaling. generalization of fourier_noise (see generate_data_utils) to arbitrary number of dimensions. input args: - hists: numpy array of shape (nhists, ) used for seeding - outfilename: path to csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples to draw per input histogram - nonnegative: boolean whether to set all bins to minimum zero after applying noise - stdfactor: factor to scale magnitude of noise (larger factor = smaller noise) - kmaxscale and ncomponents: see goodnoise_nd","title":"fourier_noise_nd(hists, outfilename='', figname='', nresamples=1, nonnegative=True,  stdfactor=15., kmaxscale=0.25, ncomponents=3)"},{"location":"utils/generate_data_2d_utils/#white95noise95ndhists-figname-nresamples1-nonnegativetrue-stdfactor15","text":"apply white noise to the histograms in hists. generalization of white_noise (see generate_data_utils) to arbitrary number of dimensions. input args: - hists: np array (nhists, ) containing input histograms - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples to draw per input histogram - nonnegative: boolean whether to set all bins to minimum zero after applying noise - stdfactor: scaling factor of white noise amplitude (higher factor = smaller noise)","title":"white_noise_nd(hists, figname='', nresamples=1, nonnegative=True, stdfactor=15.)"},{"location":"utils/generate_data_2d_utils/#resample95lico95ndhists-nresamples1-nonnegativetrue","text":"take random linear combinations of input histograms generalization of fourier_noise (see generate_data_utils) to arbitrary number of dimensions. input args: - hists: numpy array of shape (nhists, ) used for seeding - nresamples: number of samples to draw - nonnegative: boolean whether to set all bins to minimum zero after applying noise note: coefficients in linear combination are always nonnegative, so this setting is superfluous is input histograms are all nonnegative","title":"resample_lico_nd(hists, nresamples=1, nonnegative=True)"},{"location":"utils/generate_data_utils/","text":"generate data utils goodnoise(nbins, fstd=None) generate one sample of 'good' noise consisting of fourier components input args: - nbins: number of bins, length of noise array to be sampled - fstd: an array of length nbins used for scaling of the amplitude of the noise bin-by-bin. output: - numpy array of length nbins containing the noise badnoise(nbins, fstd=None) generate one sample of 'bad' noise consisting of fourier components (higher frequency and amplitude than 'good' noise) input args and output: simlar to goodnoise WARNING: NOT NECESSARILY REPRESENTATIVE OF ANOMALIES TO BE EXPECTED, DO NOT USE whitenoise(nbins, fstd=None) generate one sample of white noise (uncorrelated between bins) input args and output: similar to goodnoise random_lico(hists) generate one linear combination of histograms with random coefficients in (0,1) summing to 1 input args: - numpy array of shape (nhists,nbins), the rows of which will be linearly combined output: - numpy array of shape (nbins), containing the new histogram smoother(inarray, halfwidth) smooth the rows of a 2D array using the 2*halfwidth+1 surrounding values. mse_correlation_vector(hists, index) calculate mse of a histogram at given index wrt all other histograms input args: - hists: numpy array of shape (nhists,nbins) containing the histograms - index: the index (must be in (0,len(hists)-1)) of the histogram in question output: - numpy array of length nhists containing mse of the indexed histogram with respect to all other histograms WARNING: can be slow if called many times on a large collection of histograms with many bins. moments_correlation_vector(moments, index) calculate moment distance of hist at index wrt all other hists very similar to mse_correlation_vector but using histogram moments instead of full histograms for speed-up plot_data_and_gen(nplot, datahist, genhist, figname='fig.png') plot a couple of random examples from rhist (data), ghist (resampled 'good') and bhist (resampled 'bad') input arguments: - nplot: integer, maximum number of examples to plot - datahist, genhist: numpy arrays of shape (nhists,nbins) - figname: name of figure to plot plot_seed_and_gen(seedhist, genhist, figname='fig.png') plot a couple of random examples from rhist (data), ghist (resampled 'good') and bhist (resampled 'bad') input arguments: - datahist, genhist: numpy arrays of shape (nhists,nbins) - figname: name of figure to plot plot_noise(noise, histstd=None, figname='fig.png') plot histograms in noise (numpy array of shape (nhists,nbins)) optional argument histstd plots +- histstd as boundaries fourier_noise_on_mean(hists, outfilename='', figname='', nresamples=0, nonnegative=True) apply fourier noise on the bin-per-bin mean histogram, with amplitude scaling based on bin-per-bin std histogram. input args: - hists: numpy array of shape (nhists,nbins) used for determining mean and std - outfilename: path to csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples to draw (default: number of input histograms / 10) - nonnegative: boolean whether to set all bins to minimum zero after applying noise MOSTLY SUITABLE AS HELP FUNCTION FOR RESAMPLE_SIMILAR_FOURIER_NOISE, NOT AS GENERATOR IN ITSELF advantages: mean histogram is almost certainly 'good' because of averaging, eliminate bad histograms disadvantages: deviations from mean are small, does not model systematic shifts by lumi. fourier_noise(hists, outfilename='', figname='', nresamples=1, nonnegative=True, stdfactor=15.) apply fourier noise on random histograms with simple flat amplitude scaling. input args: - hists: numpy array of shape (nhists,nbins) used for seeding - outfilename: path to csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples to draw per input histogram - nonnegative: boolean whether to set all bins to minimum zero after applying noise - stdfactor: factor to scale magnitude of noise (larger factor = smaller noise) advantages: resampled histograms will have statistically same features as original input set disadvantages: also 'bad' histograms will be resampled if included in hists upsample_hist_set(hists,ntarget,fourierstdfactor=15.,figname='f') wrapper for fourier_noise allowing for a fixed target number of histograms instead of a fixed resampling factor useful function for quickly generating a fixed number of resampled histograms, without bothering too much about what exact resampling technique or detailed settings would be most appropriate. white_noise(hists, figname='', stdfactor=15.) apply white noise to the histograms in hists. input args: - hists: np array (nhists,nbins) containing input histograms - figname: path to figure plotting examples (default: no plotting) - stdfactor: scaling factor of white noise amplitude (higher factor = smaller noise) resample_bin_per_bin(hists, outfilename='', figname='', nresamples=0, nonnegative=True, smoothinghalfwidth=2) do resampling from bin-per-bin probability distributions input args: - hists: np array (nhists,nbins) containing the histograms to draw new samples from - outfilename: path to csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples to draw (default: 1/10 of number of input histograms) - nonnegative: boolean whether or not to put all bins to minimum zero after applying noise - smoothinghalfwidth: halfwidth of smoothing procedure to apply on the result (default: no smoothing) advantages: no arbitrary noise modeling disadvantages: bins are considered independent, shape of historams not taken into account, does not work well on small number of input histograms, does not work well on histograms with systematic shifts resample_similar_bin_per_bin( allhists, selhists, outfilename='', figname='', nresamples=1, nonnegative=True, keeppercentage=1.) resample from bin-per-bin probability distributions, but only from similar looking histograms. input args: - allhists: np array (nhists,nbins) containing all available histograms (to determine mean) - selhists: np array (nhists,nbins) conataining selected histograms used as seeds (e.g. 'good' histograms) - outfilename: path of csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples per input histogram in selhists - nonnegative: boolean whether or not to put all bins to minimum zero after applying noise - keeppercentage: percentage (between 1 and 100) of histograms in allhists to use per input histogram advantages: no assumptions on shape of noise, can handle systematic shifts in histograms disadvantages: bins are treated independently from each other resample_similar_fourier_noise( allhists, selhists, outfilename='', figname='', nresamples=1, nonnegative=True, keeppercentage=1.) apply fourier noise on mean histogram, where the mean is determined from a set of similar-looking histograms input args: - allhists: np array (nhists,nbins) containing all available histograms (to determine mean) - selhists: np array (nhists,nbins) conataining selected histograms used as seeds (e.g. 'good' histograms) - outfilename: path of csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples per input histogram in selhists - nonnegative: boolean whether or not to put all bins to minimum zero after applying noise - keeppercentage: percentage (between 1 and 100) of histograms in allhists to use per input histogram advantages: most of fourier_noise_on_mean but can additionally handle shifting histograms, apart from fourier noise, also white noise can be applied. disadvantages: does not filter out odd histograms as long as enough other odd histograms look more or less similar resample_similar_lico( allhists, selhists, outfilename='', figname='', nresamples=1, nonnegative=True, keeppercentage=1.) take linear combinations of similar histograms input arguments: - allhists: 2D np array (nhists,nbins) with all available histograms, used to take linear combinations - selhists: 2D np array (nhists,nbins) with selected hists used for seeding (e.g. 'good' histograms) - outfilename: path to csv file to write result to (default: no writing) - figname: path to figure plotting examples (defautl: no plotting) - nresamples: number of combinations to make per input histogram - nonnegative: boolean whether to make all final histograms nonnegative - keeppercentage: percentage (between 0. and 100.) of histograms in allhists to use per input histogram advantages: no assumptions on noise disadvantages: sensitive to outlying histograms (more than with averaging) mc_sampling(hists, nMC=10000 , nresamples=10) resampling of a histogram using MC methods Drawing random points from a space defined by the range of the histogram in all axes. Points are \"accepted\" if the fall under the sampled histogram: f(x) - sampled distribution x_r, y_r -> randomly sampled point if y_r<=f(x_r), fill the new distribution at bin corresponding to x_r with weight: weight = (sum of input hist)/(#mc points accepted) this is equal to weight = (MC space volume)/(# all MC points)","title":"generate_data_utils"},{"location":"utils/generate_data_utils/#generate-data-utils","text":"","title":"generate data utils"},{"location":"utils/generate_data_utils/#goodnoisenbins-fstdnone","text":"generate one sample of 'good' noise consisting of fourier components input args: - nbins: number of bins, length of noise array to be sampled - fstd: an array of length nbins used for scaling of the amplitude of the noise bin-by-bin. output: - numpy array of length nbins containing the noise","title":"goodnoise(nbins, fstd=None)"},{"location":"utils/generate_data_utils/#badnoisenbins-fstdnone","text":"generate one sample of 'bad' noise consisting of fourier components (higher frequency and amplitude than 'good' noise) input args and output: simlar to goodnoise WARNING: NOT NECESSARILY REPRESENTATIVE OF ANOMALIES TO BE EXPECTED, DO NOT USE","title":"badnoise(nbins, fstd=None)"},{"location":"utils/generate_data_utils/#whitenoisenbins-fstdnone","text":"generate one sample of white noise (uncorrelated between bins) input args and output: similar to goodnoise","title":"whitenoise(nbins, fstd=None)"},{"location":"utils/generate_data_utils/#random95licohists","text":"generate one linear combination of histograms with random coefficients in (0,1) summing to 1 input args: - numpy array of shape (nhists,nbins), the rows of which will be linearly combined output: - numpy array of shape (nbins), containing the new histogram","title":"random_lico(hists)"},{"location":"utils/generate_data_utils/#smootherinarray-halfwidth","text":"smooth the rows of a 2D array using the 2*halfwidth+1 surrounding values.","title":"smoother(inarray, halfwidth)"},{"location":"utils/generate_data_utils/#mse95correlation95vectorhists-index","text":"calculate mse of a histogram at given index wrt all other histograms input args: - hists: numpy array of shape (nhists,nbins) containing the histograms - index: the index (must be in (0,len(hists)-1)) of the histogram in question output: - numpy array of length nhists containing mse of the indexed histogram with respect to all other histograms WARNING: can be slow if called many times on a large collection of histograms with many bins.","title":"mse_correlation_vector(hists, index)"},{"location":"utils/generate_data_utils/#moments95correlation95vectormoments-index","text":"calculate moment distance of hist at index wrt all other hists very similar to mse_correlation_vector but using histogram moments instead of full histograms for speed-up","title":"moments_correlation_vector(moments, index)"},{"location":"utils/generate_data_utils/#plot95data95and95gennplot-datahist-genhist-fignamefigpng","text":"plot a couple of random examples from rhist (data), ghist (resampled 'good') and bhist (resampled 'bad') input arguments: - nplot: integer, maximum number of examples to plot - datahist, genhist: numpy arrays of shape (nhists,nbins) - figname: name of figure to plot","title":"plot_data_and_gen(nplot, datahist, genhist, figname='fig.png')"},{"location":"utils/generate_data_utils/#plot95seed95and95genseedhist-genhist-fignamefigpng","text":"plot a couple of random examples from rhist (data), ghist (resampled 'good') and bhist (resampled 'bad') input arguments: - datahist, genhist: numpy arrays of shape (nhists,nbins) - figname: name of figure to plot","title":"plot_seed_and_gen(seedhist, genhist, figname='fig.png')"},{"location":"utils/generate_data_utils/#plot95noisenoise-histstdnone-fignamefigpng","text":"plot histograms in noise (numpy array of shape (nhists,nbins)) optional argument histstd plots +- histstd as boundaries","title":"plot_noise(noise, histstd=None, figname='fig.png')"},{"location":"utils/generate_data_utils/#fourier95noise95on95meanhists-outfilename-figname-nresamples0-nonnegativetrue","text":"apply fourier noise on the bin-per-bin mean histogram, with amplitude scaling based on bin-per-bin std histogram. input args: - hists: numpy array of shape (nhists,nbins) used for determining mean and std - outfilename: path to csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples to draw (default: number of input histograms / 10) - nonnegative: boolean whether to set all bins to minimum zero after applying noise MOSTLY SUITABLE AS HELP FUNCTION FOR RESAMPLE_SIMILAR_FOURIER_NOISE, NOT AS GENERATOR IN ITSELF advantages: mean histogram is almost certainly 'good' because of averaging, eliminate bad histograms disadvantages: deviations from mean are small, does not model systematic shifts by lumi.","title":"fourier_noise_on_mean(hists, outfilename='', figname='', nresamples=0, nonnegative=True)"},{"location":"utils/generate_data_utils/#fourier95noisehists-outfilename-figname-nresamples1-nonnegativetrue-stdfactor15","text":"apply fourier noise on random histograms with simple flat amplitude scaling. input args: - hists: numpy array of shape (nhists,nbins) used for seeding - outfilename: path to csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples to draw per input histogram - nonnegative: boolean whether to set all bins to minimum zero after applying noise - stdfactor: factor to scale magnitude of noise (larger factor = smaller noise) advantages: resampled histograms will have statistically same features as original input set disadvantages: also 'bad' histograms will be resampled if included in hists","title":"fourier_noise(hists, outfilename='', figname='', nresamples=1, nonnegative=True, stdfactor=15.)"},{"location":"utils/generate_data_utils/#upsample95hist95sethistsntargetfourierstdfactor15fignamef","text":"wrapper for fourier_noise allowing for a fixed target number of histograms instead of a fixed resampling factor useful function for quickly generating a fixed number of resampled histograms, without bothering too much about what exact resampling technique or detailed settings would be most appropriate.","title":"upsample_hist_set(hists,ntarget,fourierstdfactor=15.,figname='f')"},{"location":"utils/generate_data_utils/#white95noisehists-figname-stdfactor15","text":"apply white noise to the histograms in hists. input args: - hists: np array (nhists,nbins) containing input histograms - figname: path to figure plotting examples (default: no plotting) - stdfactor: scaling factor of white noise amplitude (higher factor = smaller noise)","title":"white_noise(hists, figname='', stdfactor=15.)"},{"location":"utils/generate_data_utils/#resample95bin95per95binhists-outfilename-figname-nresamples0-nonnegativetrue-smoothinghalfwidth2","text":"do resampling from bin-per-bin probability distributions input args: - hists: np array (nhists,nbins) containing the histograms to draw new samples from - outfilename: path to csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples to draw (default: 1/10 of number of input histograms) - nonnegative: boolean whether or not to put all bins to minimum zero after applying noise - smoothinghalfwidth: halfwidth of smoothing procedure to apply on the result (default: no smoothing) advantages: no arbitrary noise modeling disadvantages: bins are considered independent, shape of historams not taken into account, does not work well on small number of input histograms, does not work well on histograms with systematic shifts","title":"resample_bin_per_bin(hists, outfilename='', figname='', nresamples=0, nonnegative=True, smoothinghalfwidth=2)"},{"location":"utils/generate_data_utils/#resample95similar95bin95per95bin-allhists-selhists-outfilename-figname-nresamples1-nonnegativetrue-keeppercentage1","text":"resample from bin-per-bin probability distributions, but only from similar looking histograms. input args: - allhists: np array (nhists,nbins) containing all available histograms (to determine mean) - selhists: np array (nhists,nbins) conataining selected histograms used as seeds (e.g. 'good' histograms) - outfilename: path of csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples per input histogram in selhists - nonnegative: boolean whether or not to put all bins to minimum zero after applying noise - keeppercentage: percentage (between 1 and 100) of histograms in allhists to use per input histogram advantages: no assumptions on shape of noise, can handle systematic shifts in histograms disadvantages: bins are treated independently from each other","title":"resample_similar_bin_per_bin( allhists, selhists, outfilename='', figname='', nresamples=1, nonnegative=True, keeppercentage=1.)"},{"location":"utils/generate_data_utils/#resample95similar95fourier95noise-allhists-selhists-outfilename-figname-nresamples1-nonnegativetrue-keeppercentage1","text":"apply fourier noise on mean histogram, where the mean is determined from a set of similar-looking histograms input args: - allhists: np array (nhists,nbins) containing all available histograms (to determine mean) - selhists: np array (nhists,nbins) conataining selected histograms used as seeds (e.g. 'good' histograms) - outfilename: path of csv file to write results to (default: no writing) - figname: path to figure plotting examples (default: no plotting) - nresamples: number of samples per input histogram in selhists - nonnegative: boolean whether or not to put all bins to minimum zero after applying noise - keeppercentage: percentage (between 1 and 100) of histograms in allhists to use per input histogram advantages: most of fourier_noise_on_mean but can additionally handle shifting histograms, apart from fourier noise, also white noise can be applied. disadvantages: does not filter out odd histograms as long as enough other odd histograms look more or less similar","title":"resample_similar_fourier_noise( allhists, selhists, outfilename='', figname='', nresamples=1, nonnegative=True, keeppercentage=1.)"},{"location":"utils/generate_data_utils/#resample95similar95lico-allhists-selhists-outfilename-figname-nresamples1-nonnegativetrue-keeppercentage1","text":"take linear combinations of similar histograms input arguments: - allhists: 2D np array (nhists,nbins) with all available histograms, used to take linear combinations - selhists: 2D np array (nhists,nbins) with selected hists used for seeding (e.g. 'good' histograms) - outfilename: path to csv file to write result to (default: no writing) - figname: path to figure plotting examples (defautl: no plotting) - nresamples: number of combinations to make per input histogram - nonnegative: boolean whether to make all final histograms nonnegative - keeppercentage: percentage (between 0. and 100.) of histograms in allhists to use per input histogram advantages: no assumptions on noise disadvantages: sensitive to outlying histograms (more than with averaging)","title":"resample_similar_lico( allhists, selhists, outfilename='', figname='', nresamples=1, nonnegative=True, keeppercentage=1.)"},{"location":"utils/generate_data_utils/#mc95samplinghists-nmc10000-nresamples10","text":"resampling of a histogram using MC methods Drawing random points from a space defined by the range of the histogram in all axes. Points are \"accepted\" if the fall under the sampled histogram: f(x) - sampled distribution x_r, y_r -> randomly sampled point if y_r<=f(x_r), fill the new distribution at bin corresponding to x_r with weight: weight = (sum of input hist)/(#mc points accepted) this is equal to weight = (MC space volume)/(# all MC points)","title":"mc_sampling(hists, nMC=10000 , nresamples=10)"},{"location":"utils/hist_utils/","text":"hist utils crophists(hists, slices) perform cropping on a sit of histograms input arguments: - hists is a numpy array of shape (nhistograms,nbins) for 1D or (nhistograms,nybins,nxbins) for 2D - slices is a list of slice objects (builtin python type) of length 1 (for 1D) or 2 (for 2D) rebinhists(hists, factor) perform rebinning on a set of histograms input arguments: - hists is a numpy array of shape (nhistograms,nbins) for 1D or (nhistograms,nybins,nxbins) for 2D - factor is the rebinning factor, or a tuple (y axis rebinning factor, x axis rebinning factor), which must be a divisors of the respective number of bins. normalizehists(hists) perform normalization for 1D histograms, the sum of bin contents is set equal one for each histogram for 2D histograms, the bin contents are scaled so the maximum is 1 for each histogram (maybe later make more flexible by adding normalization stragy as argument) averagehists(hists, nout) partition hists (of shape (nhistograms,nbins) or (nhistograms,nybins,nxbins)) into nout parts and take the average histogram of each part moment(bins, counts, order) get n-th central moment of a histogram - bins is a 1D or 2D np array holding the bin centers (shape (nbins) or (nhistograms,nbins)) - array is a 2D np array containing the bin counts (shape (nhistograms,nbins)) - order is the order of the moment to calculate (0 = maximum, 1 = mean value) note: for now only 1D histograms are supported! histmean(bins, counts) special case of moment calculation (with order=1) histrms(bins, counts) special case of moment calculation histmoments(bins, counts, orders) apply moment calculation for a list of orders the return type is a numpy array of shape (nhistograms,nmoments) preparedatafromnpy(dataname, cropslices=None, rebinningfactor=None, donormalize=True, doplot=False) read a .npy file and output the histograms args: see e.g. preparedatafromdf note: not yet tested for 2D histograms, but is expected to work... preparedatafromdf(df, returnrunls=False, cropslices=None, rebinningfactor=None, donormalize=False, doplot=False) prepare the data contained in a dataframe in the form of a numpy array args: - returnrunls: boolean whether to return a tuple of (histograms, run numbers, lumisection numbers). (default: return only histograms) - cropslices: list of slices by which to crop the historams (default: no cropping) - rebinningfactor: an integer (or tuple of integers for 2D histograms) to downsample/rebin the histograms (default: no rebinning) - donormalize: boolean whether to normalize the data - doplot: if True, some example plots are made showing the histograms preparedatafromcsv(dataname, returnrunls=False, cropslices=None, rebinningfactor=None, donormalize=True, doplot=False) prepare the data contained in a dataframe csv file in the form of a numpy array args: - returnrunls: boolean whether to return a tuple of (histograms, run numbers, lumisection numbers). (default: return only histograms) - cropslices: list of slices by which to crop the historams (default: no cropping) - rebinningfactor: an integer (or tuple of integers for 2D histograms) to downsample/rebin the histograms (default: no rebinning) - donormalize: boolean whether to normalize the data - doplot: if True, some example plots are made showing the histograms","title":"hist_utils"},{"location":"utils/hist_utils/#hist-utils","text":"","title":"hist utils"},{"location":"utils/hist_utils/#crophistshists-slices","text":"perform cropping on a sit of histograms input arguments: - hists is a numpy array of shape (nhistograms,nbins) for 1D or (nhistograms,nybins,nxbins) for 2D - slices is a list of slice objects (builtin python type) of length 1 (for 1D) or 2 (for 2D)","title":"crophists(hists, slices)"},{"location":"utils/hist_utils/#rebinhistshists-factor","text":"perform rebinning on a set of histograms input arguments: - hists is a numpy array of shape (nhistograms,nbins) for 1D or (nhistograms,nybins,nxbins) for 2D - factor is the rebinning factor, or a tuple (y axis rebinning factor, x axis rebinning factor), which must be a divisors of the respective number of bins.","title":"rebinhists(hists, factor)"},{"location":"utils/hist_utils/#normalizehistshists","text":"perform normalization for 1D histograms, the sum of bin contents is set equal one for each histogram for 2D histograms, the bin contents are scaled so the maximum is 1 for each histogram (maybe later make more flexible by adding normalization stragy as argument)","title":"normalizehists(hists)"},{"location":"utils/hist_utils/#averagehistshists-nout","text":"partition hists (of shape (nhistograms,nbins) or (nhistograms,nybins,nxbins)) into nout parts and take the average histogram of each part","title":"averagehists(hists, nout)"},{"location":"utils/hist_utils/#momentbins-counts-order","text":"get n-th central moment of a histogram - bins is a 1D or 2D np array holding the bin centers (shape (nbins) or (nhistograms,nbins)) - array is a 2D np array containing the bin counts (shape (nhistograms,nbins)) - order is the order of the moment to calculate (0 = maximum, 1 = mean value) note: for now only 1D histograms are supported!","title":"moment(bins, counts, order)"},{"location":"utils/hist_utils/#histmeanbins-counts","text":"special case of moment calculation (with order=1)","title":"histmean(bins, counts)"},{"location":"utils/hist_utils/#histrmsbins-counts","text":"special case of moment calculation","title":"histrms(bins, counts)"},{"location":"utils/hist_utils/#histmomentsbins-counts-orders","text":"apply moment calculation for a list of orders the return type is a numpy array of shape (nhistograms,nmoments)","title":"histmoments(bins, counts, orders)"},{"location":"utils/hist_utils/#preparedatafromnpydataname-cropslicesnone-rebinningfactornone-donormalizetrue-doplotfalse","text":"read a .npy file and output the histograms args: see e.g. preparedatafromdf note: not yet tested for 2D histograms, but is expected to work...","title":"preparedatafromnpy(dataname, cropslices=None, rebinningfactor=None, donormalize=True, doplot=False)"},{"location":"utils/hist_utils/#preparedatafromdfdf-returnrunlsfalse-cropslicesnone-rebinningfactornone-donormalizefalse-doplotfalse","text":"prepare the data contained in a dataframe in the form of a numpy array args: - returnrunls: boolean whether to return a tuple of (histograms, run numbers, lumisection numbers). (default: return only histograms) - cropslices: list of slices by which to crop the historams (default: no cropping) - rebinningfactor: an integer (or tuple of integers for 2D histograms) to downsample/rebin the histograms (default: no rebinning) - donormalize: boolean whether to normalize the data - doplot: if True, some example plots are made showing the histograms","title":"preparedatafromdf(df, returnrunls=False, cropslices=None, rebinningfactor=None, donormalize=False, doplot=False)"},{"location":"utils/hist_utils/#preparedatafromcsvdataname-returnrunlsfalse-cropslicesnone-rebinningfactornone-donormalizetrue-doplotfalse","text":"prepare the data contained in a dataframe csv file in the form of a numpy array args: - returnrunls: boolean whether to return a tuple of (histograms, run numbers, lumisection numbers). (default: return only histograms) - cropslices: list of slices by which to crop the historams (default: no cropping) - rebinningfactor: an integer (or tuple of integers for 2D histograms) to downsample/rebin the histograms (default: no rebinning) - donormalize: boolean whether to normalize the data - doplot: if True, some example plots are made showing the histograms","title":"preparedatafromcsv(dataname, returnrunls=False, cropslices=None, rebinningfactor=None, donormalize=True, doplot=False)"},{"location":"utils/json_utils/","text":"json utils loadjson( jsonfile ) load the content of a json file into a python object input arguments: - jsonfile: the name (or full path if needed) to the json file to be read output: - an dict object as specified in the note below note: the json file is supposed to contain an object like this example: { \"294927\": [ [ 55,85 ], [ 95,105] ], \"294928\": [ [1,33 ] ] } although no explicit checking is done in this function, objects that don't have this structure will probably lead to errors further in the code writejson( jsondict, outputfile, overwrite=False ) inverse function of loadjson input arguments - jsondict: dict object to be written to a json file - outputfile: output file to be written, extension '.json' will be appended automatically - overwrite: boolean whether to overwrite outputfile if it exists (default: throw exception) injson_single( run, lumi, jsondict ) helper function for injson, only for internal use input arguments: - run and lumi are integers - jsondict is an object loaded from a json file output: - boolean whether the run/lumi combination is in the json dict injson( run, lumi, jsonfile=None, jsondict=None ) find if a run and lumi combination is in a given json file input arguments: - run and lumi: integers or (equally long) arrays of integers - jsonfile: a path to a json file - jsondict: a dict loaded from a json file note: either jsonfile or jsondict must not be None! output: boolean or array of booleans (depending on run and lumi) isgolden(run, lumi) find if a run and lumi combination is in the golden json file input arguments: - run and lumi: either integers or (equally long) arrays of integers isdcson(run, lumi) find if a run and lumi combination is in DCS-only json file input arguments: - run and lumi: either integers or (equally long) arrays of integers ispixelgood(run, lumi) find if a run and lumi combination is in the json with good pixel flag note: this json was custom generated in run regisitry and not official! ispixelbad(run, lumi) find if a run and lumi combination is in the json with bad pixel flag note: this json was custom generated in run registry and not official! note: not simply the negation of ispixelgood! json has more relaxed conditions on DCS-like criteria. plainlist_to_rangelist( plainlist ) helper function for tuplelist_to_jsondict, only for internal use input arguments: - plainlist: a list of integers in increasing order, must have length >= 2 output: - a list lists representing ranges example: [1,2,3,5,6] -> [ [1,3], [5,6] ] rangelist_to_plainlist( rangelist ) inverse function of plainlist_to_rangelist, for internal use only tuplelist_to_jsondict( tuplelist ) convert a list of tuples of format (run number, [lumisection numbers]) to json dict jsondict_to_tuplelist( jsondict ) inverse function of tuplelist_to_jsondict get_lcs( jsonlist ) return a jsondict object that is the largest common subset (LCS) between the jsondict objects in jsonlist input arguments: - jsonlist: a list of dicts in the conventional json format, so each element in jsonlist must be e.g. { \"294927\": [ [ 55,85 ], [ 95,105] ], \"294928\": [ [1,33 ] ] } remark: this is probably not the most efficient implementation, open for improvement...","title":"json_utils"},{"location":"utils/json_utils/#json-utils","text":"","title":"json utils"},{"location":"utils/json_utils/#loadjson-jsonfile","text":"load the content of a json file into a python object input arguments: - jsonfile: the name (or full path if needed) to the json file to be read output: - an dict object as specified in the note below note: the json file is supposed to contain an object like this example: { \"294927\": [ [ 55,85 ], [ 95,105] ], \"294928\": [ [1,33 ] ] } although no explicit checking is done in this function, objects that don't have this structure will probably lead to errors further in the code","title":"loadjson( jsonfile )"},{"location":"utils/json_utils/#writejson-jsondict-outputfile-overwritefalse","text":"inverse function of loadjson input arguments - jsondict: dict object to be written to a json file - outputfile: output file to be written, extension '.json' will be appended automatically - overwrite: boolean whether to overwrite outputfile if it exists (default: throw exception)","title":"writejson( jsondict, outputfile, overwrite=False )"},{"location":"utils/json_utils/#injson95single-run-lumi-jsondict","text":"helper function for injson, only for internal use input arguments: - run and lumi are integers - jsondict is an object loaded from a json file output: - boolean whether the run/lumi combination is in the json dict","title":"injson_single( run, lumi, jsondict )"},{"location":"utils/json_utils/#injson-run-lumi-jsonfilenone-jsondictnone","text":"find if a run and lumi combination is in a given json file input arguments: - run and lumi: integers or (equally long) arrays of integers - jsonfile: a path to a json file - jsondict: a dict loaded from a json file note: either jsonfile or jsondict must not be None! output: boolean or array of booleans (depending on run and lumi)","title":"injson( run, lumi, jsonfile=None, jsondict=None )"},{"location":"utils/json_utils/#isgoldenrun-lumi","text":"find if a run and lumi combination is in the golden json file input arguments: - run and lumi: either integers or (equally long) arrays of integers","title":"isgolden(run, lumi)"},{"location":"utils/json_utils/#isdcsonrun-lumi","text":"find if a run and lumi combination is in DCS-only json file input arguments: - run and lumi: either integers or (equally long) arrays of integers","title":"isdcson(run, lumi)"},{"location":"utils/json_utils/#ispixelgoodrun-lumi","text":"find if a run and lumi combination is in the json with good pixel flag note: this json was custom generated in run regisitry and not official!","title":"ispixelgood(run, lumi)"},{"location":"utils/json_utils/#ispixelbadrun-lumi","text":"find if a run and lumi combination is in the json with bad pixel flag note: this json was custom generated in run registry and not official! note: not simply the negation of ispixelgood! json has more relaxed conditions on DCS-like criteria.","title":"ispixelbad(run, lumi)"},{"location":"utils/json_utils/#plainlist95to95rangelist-plainlist","text":"helper function for tuplelist_to_jsondict, only for internal use input arguments: - plainlist: a list of integers in increasing order, must have length >= 2 output: - a list lists representing ranges example: [1,2,3,5,6] -> [ [1,3], [5,6] ]","title":"plainlist_to_rangelist( plainlist )"},{"location":"utils/json_utils/#rangelist95to95plainlist-rangelist","text":"inverse function of plainlist_to_rangelist, for internal use only","title":"rangelist_to_plainlist( rangelist )"},{"location":"utils/json_utils/#tuplelist95to95jsondict-tuplelist","text":"convert a list of tuples of format (run number, [lumisection numbers]) to json dict","title":"tuplelist_to_jsondict( tuplelist )"},{"location":"utils/json_utils/#jsondict95to95tuplelist-jsondict","text":"inverse function of tuplelist_to_jsondict","title":"jsondict_to_tuplelist( jsondict )"},{"location":"utils/json_utils/#get95lcs-jsonlist","text":"return a jsondict object that is the largest common subset (LCS) between the jsondict objects in jsonlist input arguments: - jsonlist: a list of dicts in the conventional json format, so each element in jsonlist must be e.g. { \"294927\": [ [ 55,85 ], [ 95,105] ], \"294928\": [ [1,33 ] ] } remark: this is probably not the most efficient implementation, open for improvement...","title":"get_lcs( jsonlist )"},{"location":"utils/plot_utils/","text":"plot utils plot_hists(histlist, colorlist=[], labellist=[], transparency=1, xlims=(0,-1), title=None, xaxtitle=None, yaxtitle=None, bkgcolor=None, bkgcmap='spring') plot some histograms (in histlist) in one figure using specified colors and/or labels - histlist is a list of 1D arrays containing the histograms (or a 2D array of shape (nhistograms,nbins)) - colorlist is a list or array containing colors (in string format) note: it can also be a single string representing a color (in pyplot), then all histograms will take this color - labellist is a list or array containing labels for in legend output: tuple of figure and axis objects, that can be used to further tune the look of the figure or save it plot_hists_multi(histlist, colorlist=[], labellist=[], transparency=1, xlims=(0,-1), title=None, xaxtitle=None, yaxtitle=None) plot many histograms (in histlist) in one figure using specified colors and/or labels - histlist is a list of 1D arrays containing the histograms (or a 2D array of shape (nhistograms,nbins)) - colorlist is a list or array containing numbers to be mapped to colors - labellist is a list or array containing labels for in legend output: tuple of figure and axis objects, that can be used to further tune the look of the figure or save it plot_hist_2d(hist, fig=None, ax=None, title=None, xaxtitle=None, yaxtitle=None, caxrange=None) plot a 2D histogram - hist is a 2D numpy array of shape (nxbins, nybins) notes: - if the histogram contains only nonnegative values, values below 1e-12 will not be plotted (i.e. they will be shown as white spots in the plot) to discriminate zero from small but nonzero - if the histogram contains negative values, the color axis will be symmetrized around zero plot_hists_2d(hists, ncols=4, title = None, subtitles=None, xaxtitle=None, yaxtitle=None, caxrange=None) plot multiple 2D histograms next to each other - hists: list of 2D numpy arrays of shape (nxbins,nybins), or an equivalent 3D numpy array - ncols: number of columns to use plot_hists_2d_gif(hists, titles = None, xaxtitle=None, yaxtitle=None, duration=0.3, figname='temp_gif.gif') (no valid documentation found) plot_hists_from_df(df, histtype, nhists) plot a number of histograms in a dataframe - df is the dataframe from which to plot - histtype is the name of the histogram type (e.g. 'chargeInner_PXLayer_1') - nhists is the number of histograms to plot plot_sets(setlist, fig=None, ax=None, colorlist=[], labellist=[], transparencylist=[], xlims=(0,-1), title=None, xaxtitle=None, yaxtitle=None) plot multiple sets of histograms to compare the shapes - setlist is a list of 2D numpy arrays containing histograms - fig and ax: a pyplot figure and axis object (if one of both is none a new figure is created) - title is a string that will be used as the title for the ax object other parameters are lists of which each element applies to one list of histograms plot_anomalous(histlist, ls, highlight=-1, hrange=-1) histlist and ls are a list of histograms and corresponding lumisection numbers lsnumber is the lumisection number of the histogram to highlight hrange is the number of histograms before and after lsnumber to plot (default: whole run) plot_moments(moments, ls, dims, fig=None, ax=None, markersize=10) moments is an (nhists,nmoments) array dims is a tuple of two or three values between 0 and nmoments-1 plot_distance(dists, ls=None, rmlargest=0., doplot=True, title=None, xaxtitle='lumisection number', yaxtitle='distance metric') (no valid documentation found) plot_loss(data, xlims=None, title=None, xaxtitle='epoch', yaxtitle='loss') plot the training and validation loss data is the object returned by the .fit method when called upon a keras model e.g. history = .fit( ) plot_loss(history,'a title') plot_mse(mse, rmlargest=0., doplot=True, title=None, xaxtitle='lumisection number', yaxtitle='mse') plot the mse's and return the mean and std input args: - mse is a 1D numpy array of mse scores - doplot: boolean whether to make a plot or simply return mean and std - rmlargest: fraction of largest mse's to remove (to avoid being too sensitive to outliers) plot_score_dist( scores, labels, nbins=20, normalize=False, title='output score distributions for signal and background', xaxtitle='output score', yaxtitle=None) make a plot showing the distributions of the output scores for signal and background plot_fit_2d( points, fitfunc=None, logprob=False, onlycontour=False, xlims=5, ylims=5, onlypositive=False, xaxtitle=None, yaxtitle=None ) make a scatter plot of a 2D point cloud with fitted contour input arguments: - points: a numpy array of shape (npoints,ndims) - fitfunc: an object of type CloudFitter (see src/cloudfitters) or any other object that implements a pdf(points) method - logprob: boolean whether to plot log probability or normal probability - onlycontour: a boolean whether to draw only the fit or include the data points - xlims and ylims: tuples of (low,high) note: can be an integer, in which case the range will be determined automatically from the formula low = mean-xlims std, high = mean+xlims std, where mean and std are determined from the points array. - onlypositive: overrides previous argument to set lower bound of plotting range at 0 in both dimensions. - xaxtitle and yaxtitle: titles for axes.","title":"plot_utils"},{"location":"utils/plot_utils/#plot-utils","text":"","title":"plot utils"},{"location":"utils/plot_utils/#plot95histshistlist-colorlist-labellist-transparency1-xlims0-1-titlenone-xaxtitlenone-yaxtitlenone-bkgcolornone-bkgcmapspring","text":"plot some histograms (in histlist) in one figure using specified colors and/or labels - histlist is a list of 1D arrays containing the histograms (or a 2D array of shape (nhistograms,nbins)) - colorlist is a list or array containing colors (in string format) note: it can also be a single string representing a color (in pyplot), then all histograms will take this color - labellist is a list or array containing labels for in legend output: tuple of figure and axis objects, that can be used to further tune the look of the figure or save it","title":"plot_hists(histlist, colorlist=[], labellist=[], transparency=1, xlims=(0,-1), title=None, xaxtitle=None, yaxtitle=None, bkgcolor=None, bkgcmap='spring')"},{"location":"utils/plot_utils/#plot95hists95multihistlist-colorlist-labellist-transparency1-xlims0-1-titlenone-xaxtitlenone-yaxtitlenone","text":"plot many histograms (in histlist) in one figure using specified colors and/or labels - histlist is a list of 1D arrays containing the histograms (or a 2D array of shape (nhistograms,nbins)) - colorlist is a list or array containing numbers to be mapped to colors - labellist is a list or array containing labels for in legend output: tuple of figure and axis objects, that can be used to further tune the look of the figure or save it","title":"plot_hists_multi(histlist, colorlist=[], labellist=[], transparency=1, xlims=(0,-1), title=None, xaxtitle=None, yaxtitle=None)"},{"location":"utils/plot_utils/#plot95hist952dhist-fignone-axnone-titlenone-xaxtitlenone-yaxtitlenone-caxrangenone","text":"plot a 2D histogram - hist is a 2D numpy array of shape (nxbins, nybins) notes: - if the histogram contains only nonnegative values, values below 1e-12 will not be plotted (i.e. they will be shown as white spots in the plot) to discriminate zero from small but nonzero - if the histogram contains negative values, the color axis will be symmetrized around zero","title":"plot_hist_2d(hist, fig=None, ax=None, title=None, xaxtitle=None, yaxtitle=None, caxrange=None)"},{"location":"utils/plot_utils/#plot95hists952dhists-ncols4-title-none-subtitlesnone-xaxtitlenone-yaxtitlenone-caxrangenone","text":"plot multiple 2D histograms next to each other - hists: list of 2D numpy arrays of shape (nxbins,nybins), or an equivalent 3D numpy array - ncols: number of columns to use","title":"plot_hists_2d(hists, ncols=4, title = None, subtitles=None, xaxtitle=None, yaxtitle=None, caxrange=None)"},{"location":"utils/plot_utils/#plot95hists952d95gifhists-titles-none-xaxtitlenone-yaxtitlenone-duration03-fignametemp95gifgif","text":"(no valid documentation found)","title":"plot_hists_2d_gif(hists, titles = None, xaxtitle=None, yaxtitle=None, duration=0.3, figname='temp_gif.gif')"},{"location":"utils/plot_utils/#plot95hists95from95dfdf-histtype-nhists","text":"plot a number of histograms in a dataframe - df is the dataframe from which to plot - histtype is the name of the histogram type (e.g. 'chargeInner_PXLayer_1') - nhists is the number of histograms to plot","title":"plot_hists_from_df(df, histtype, nhists)"},{"location":"utils/plot_utils/#plot95setssetlist-fignone-axnone-colorlist-labellist-transparencylist-xlims0-1-titlenone-xaxtitlenone-yaxtitlenone","text":"plot multiple sets of histograms to compare the shapes - setlist is a list of 2D numpy arrays containing histograms - fig and ax: a pyplot figure and axis object (if one of both is none a new figure is created) - title is a string that will be used as the title for the ax object other parameters are lists of which each element applies to one list of histograms","title":"plot_sets(setlist, fig=None, ax=None, colorlist=[], labellist=[], transparencylist=[], xlims=(0,-1), title=None, xaxtitle=None, yaxtitle=None)"},{"location":"utils/plot_utils/#plot95anomaloushistlist-ls-highlight-1-hrange-1","text":"histlist and ls are a list of histograms and corresponding lumisection numbers lsnumber is the lumisection number of the histogram to highlight hrange is the number of histograms before and after lsnumber to plot (default: whole run)","title":"plot_anomalous(histlist, ls, highlight=-1, hrange=-1)"},{"location":"utils/plot_utils/#plot95momentsmoments-ls-dims-fignone-axnone-markersize10","text":"moments is an (nhists,nmoments) array dims is a tuple of two or three values between 0 and nmoments-1","title":"plot_moments(moments, ls, dims, fig=None, ax=None, markersize=10)"},{"location":"utils/plot_utils/#plot95distancedists-lsnone-rmlargest0-doplottrue-titlenone-xaxtitlelumisection-number-yaxtitledistance-metric","text":"(no valid documentation found)","title":"plot_distance(dists, ls=None, rmlargest=0., doplot=True, title=None, xaxtitle='lumisection number', yaxtitle='distance metric')"},{"location":"utils/plot_utils/#plot95lossdata-xlimsnone-titlenone-xaxtitleepoch-yaxtitleloss","text":"plot the training and validation loss data is the object returned by the .fit method when called upon a keras model e.g. history = .fit( ) plot_loss(history,'a title')","title":"plot_loss(data, xlims=None, title=None, xaxtitle='epoch', yaxtitle='loss')"},{"location":"utils/plot_utils/#plot95msemse-rmlargest0-doplottrue-titlenone-xaxtitlelumisection-number-yaxtitlemse","text":"plot the mse's and return the mean and std input args: - mse is a 1D numpy array of mse scores - doplot: boolean whether to make a plot or simply return mean and std - rmlargest: fraction of largest mse's to remove (to avoid being too sensitive to outliers)","title":"plot_mse(mse, rmlargest=0., doplot=True, title=None, xaxtitle='lumisection number', yaxtitle='mse')"},{"location":"utils/plot_utils/#plot95score95dist-scores-labels-nbins20-normalizefalse-titleoutput-score-distributions-for-signal-and-background-xaxtitleoutput-score-yaxtitlenone","text":"make a plot showing the distributions of the output scores for signal and background","title":"plot_score_dist( scores, labels, nbins=20, normalize=False, title='output score distributions for signal and background', xaxtitle='output score', yaxtitle=None)"},{"location":"utils/plot_utils/#plot95fit952d-points-fitfuncnone-logprobfalse-onlycontourfalse-xlims5-ylims5-onlypositivefalse-xaxtitlenone-yaxtitlenone","text":"make a scatter plot of a 2D point cloud with fitted contour input arguments: - points: a numpy array of shape (npoints,ndims) - fitfunc: an object of type CloudFitter (see src/cloudfitters) or any other object that implements a pdf(points) method - logprob: boolean whether to plot log probability or normal probability - onlycontour: a boolean whether to draw only the fit or include the data points - xlims and ylims: tuples of (low,high) note: can be an integer, in which case the range will be determined automatically from the formula low = mean-xlims std, high = mean+xlims std, where mean and std are determined from the points array. - onlypositive: overrides previous argument to set lower bound of plotting range at 0 in both dimensions. - xaxtitle and yaxtitle: titles for axes.","title":"plot_fit_2d( points, fitfunc=None, logprob=False, onlycontour=False, xlims=5, ylims=5, onlypositive=False, xaxtitle=None, yaxtitle=None )"},{"location":"utils/refruns_utils/","text":"refruns utils get_reference_run( runnb, jsonlist=None, jsonfile='json_allRunsRefRuns.json' ) get the reference run for a given run number input arguments: - runnb: integer representing a run number. - jsonlist: list matching run numbers to reference run numbers. note: the list is supposed to contain dicts with keys 'run_number' and 'reference_run_number', this convention is based on the json file provided by the tracker group. note: if jsonlist is None, jsonfile (see below) will be opened and a jsonlist read from it. - jsonfile: path to json file matching run numbers to reference run numbers. note: the json file must contain a list of dicts with keys 'run_number' and 'reference_run_number', as explained above. note: ignored if jsonlist is not None. output: integer representing the reference run number for the given run. if the given run is not in the json, -1 is returned.","title":"refruns_utils"},{"location":"utils/refruns_utils/#refruns-utils","text":"","title":"refruns utils"},{"location":"utils/refruns_utils/#get95reference95run-runnb-jsonlistnone-jsonfilejson95allrunsrefrunsjson","text":"get the reference run for a given run number input arguments: - runnb: integer representing a run number. - jsonlist: list matching run numbers to reference run numbers. note: the list is supposed to contain dicts with keys 'run_number' and 'reference_run_number', this convention is based on the json file provided by the tracker group. note: if jsonlist is None, jsonfile (see below) will be opened and a jsonlist read from it. - jsonfile: path to json file matching run numbers to reference run numbers. note: the json file must contain a list of dicts with keys 'run_number' and 'reference_run_number', as explained above. note: ignored if jsonlist is not None. output: integer representing the reference run number for the given run. if the given run is not in the json, -1 is returned.","title":"get_reference_run( runnb, jsonlist=None, jsonfile='json_allRunsRefRuns.json' )"}]}