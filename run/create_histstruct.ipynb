{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a HistStruct object**\n",
    "\n",
    "Use this script or something similar to create and save a HistStruct object that can be used as an input for later steps (training and testing of classifiers).  \n",
    "The HistStruct should contain all histograms (all lumisections, all types) that will be needed in later steps,\n",
    "with suitable masks to select training, testing and/or other subsets.  \n",
    "\n",
    "This script is not fixed. Depending on your needs you might need different definitions of the training set, the good and bad test sets, application runs, histogram types etc.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "print('importing external modules...')\n",
    "print('  import os'); import os\n",
    "print('  import sys'); import sys\n",
    "print('  import importlib'); import importlib\n",
    "\n",
    "# local modules: utils\n",
    "print('importing utils...')\n",
    "sys.path.append('../utils')\n",
    "print('  import csv_utils as csvu'); import csv_utils as csvu\n",
    "print('  import json_utils as jsonu'); import json_utils as jsonu\n",
    "print('  import dataframe_utils as dfu'); import dataframe_utils as dfu\n",
    "print('refreshing utils...')\n",
    "importlib.reload(csvu)\n",
    "importlib.reload(jsonu)\n",
    "importlib.reload(dfu)\n",
    "\n",
    "# local modules: src\n",
    "print('importing src...')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "print('  import HistStruct'); import HistStruct\n",
    "print('refreshing src...')\n",
    "importlib.reload(HistStruct)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define properties\n",
    "\n",
    "# define a list of good 'reference' runs (found by eye)\n",
    "# should be replaced at some point by the reference runs defined by the DQM/DC team.\n",
    "goodrunsls = {'2017':\n",
    "              {\n",
    "                \"297056\":[[-1]],\n",
    "                \"297177\":[[-1]],\n",
    "                \"301449\":[[-1]],\n",
    "              },\n",
    "              '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "             {  \"315267\":[[-1]] \n",
    "             }}\n",
    "\n",
    "# define core test set of clearly bad runs (found by eye)\n",
    "badrunsls = {'2017':\n",
    "                {\n",
    "                \"297287\":[[-1]],\n",
    "                \"297288\":[[-1]],\n",
    "                \"297289\":[[-1]],\n",
    "                \"299316\":[[-1]],\n",
    "                \"299324\":[[-1]],\n",
    "                \"299326\":[[-1]],\n",
    "                \"301086\":[[88,126]] # only bad for size_PXDisk_+1 -> maybe do not use for now (unclear what are real anomalies)\n",
    "                },\n",
    "            '2018': # needs to be re-checked, not guaranteed to be fully correct or representative.\n",
    "                {\n",
    "                #\"317479\":[[-1]],\n",
    "                \"317480\":[[-1]],\n",
    "                \"317481\":[[-1]],\n",
    "                \"317482\":[[-1]],\n",
    "                #\"319847\":[[1,35]]\n",
    "            }}\n",
    "\n",
    "# set year to use\n",
    "year = '2017'\n",
    "\n",
    "# set histogram names to use \n",
    "histnames = [\n",
    "            'chargeInner_PXLayer_2',\n",
    "             'chargeInner_PXLayer_3',\n",
    "             'charge_PXDisk_+1','charge_PXDisk_+2','charge_PXDisk_+3',\n",
    "             'size_PXLayer_1','size_PXLayer_2',\n",
    "             'size_PXLayer_3'\n",
    "            ]\n",
    "\n",
    "# set whether to train globally or locally\n",
    "training_mode = 'local'\n",
    "\n",
    "if training_mode == 'global':\n",
    "    # train globally on a large set of runs (e.g. entire 2017 data with DCS-bit on and sufficient statistics)\n",
    "    runsls_training = None # use none to not add a mask for training (can e.g. use DCS-bit on and high statistics masks)\n",
    "    runsls_good = None # use none to not add a mask for good runs (can e.g. use averages of training set)\n",
    "    runsls_bad = badrunsls[year] # predefined bad runs\n",
    "    \n",
    "elif training_mode == 'local':\n",
    "    # train locally on a small set of runs\n",
    "    # - either on n runs preceding a chosen application run,\n",
    "    # - or on the run associated as reference to the chosen application run.\n",
    "    #   (not yet defined properly, use first approach for now.)\n",
    "    \n",
    "    # select application run\n",
    "    available_runs = dfu.get_runs( dfu.select_dcson( csvu.read_csv('../data/DF'+year+'_'+histnames[0]+'.csv') ) )\n",
    "    run_application = 306458\n",
    "    run_application_index = available_runs.index(run_application)\n",
    "    # select training set\n",
    "    usereference = False\n",
    "    if usereference:\n",
    "        run_reference = rru.get_reference_run( run_application, jsonfile='../utils/json_allRunsRefRuns.json' )\n",
    "        if run_reference<0:\n",
    "            raise Exception('no valid reference run has been defined for run {}'.format(run_application))\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(run_reference,[-1])])\n",
    "    else:\n",
    "        ntraining = 5 # number of training runs (preceding the application run)\n",
    "        offset = 0 # normal case: offset = 0 (just use ntraining previous runs)\n",
    "        runsls_training = jsonu.tuplelist_to_jsondict([(el,[-1]) for el in available_runs[run_application_index-ntraining-offset:run_application_index-offset]])\n",
    "    # put the usual bad runs as bad set and the application run as good set\n",
    "    runsls_bad = badrunsls[year]\n",
    "    runsls_good = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    # alternative: put the application run as bad set and the training runs as good set\n",
    "    #runsls_bad = jsonu.tuplelist_to_jsondict([(run_application,[-1])])\n",
    "    #runsls_good = runsls_training\n",
    "\n",
    "print('The following masks will be defined:')\n",
    "print('for the training set: ')\n",
    "print('  {}'.format(runsls_training))\n",
    "print('for the good test set:')\n",
    "print('  {}'.format(runsls_good))\n",
    "print('for the bad test set:')\n",
    "print('  {}'.format(runsls_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the data based on the configuration defined above\n",
    "    \n",
    "# create the HistStruct object\n",
    "histstruct = HistStruct.HistStruct()\n",
    "# loop over the histogram types to take into account\n",
    "for histname in histnames:\n",
    "    print('adding {}...'.format(histname))\n",
    "    # read the histograms from the csv file\n",
    "    filename = '../data/DF'+year+'_'+histname+'.csv'\n",
    "    df = csvu.read_csv( filename )\n",
    "    # in case of local training, we can remove most of the histograms\n",
    "    if( runsls_training is not None and runsls_good is not None and runsls_bad is not None ):\n",
    "        runsls_total = {k: v for d in (runsls_training, runsls_good, runsls_bad) for k, v in d.items()}\n",
    "        df = dfu.select_runsls( df, runsls_total )\n",
    "    # add the histograms to the HistStuct (note the available preprocessing options, e.g. normalizing which is switched on by default)!\n",
    "    histstruct.add_dataframe( df )\n",
    "print('added {} lumisections with {} histograms each to the dataframe.'.format(len(histstruct.runnbs),len(histstruct.histnames)))\n",
    "    \n",
    "# add default masks for DCS-bit on, golden json, and high statistics selection\n",
    "histstruct.add_dcsonjson_mask( 'dcson' )\n",
    "histstruct.add_goldenjson_mask('golden' )\n",
    "histstruct.add_highstat_mask( 'highstat' )\n",
    "\n",
    "# add custom masks for the training and test sets\n",
    "if runsls_training is not None: histstruct.add_json_mask( 'training', runsls_training )\n",
    "if runsls_good is not None: histstruct.add_json_mask( 'good', runsls_good )\n",
    "nbadruns = 0\n",
    "if runsls_bad is not None:\n",
    "    histstruct.add_json_mask( 'bad', runsls_bad )\n",
    "    # special case for bad runs: add a mask per bad run (different bad runs have different characteristics)\n",
    "    nbadruns = len(runsls_bad.keys())\n",
    "    for i,badrun in enumerate(runsls_bad.keys()):\n",
    "        histstruct.add_json_mask( 'bad{}'.format(i), {badrun:runsls_bad[badrun]} )\n",
    "    \n",
    "# save the HistStruct\n",
    "histstruct.save( 'test.zip' )\n",
    "    \n",
    "print('created a histstruct with the following properties:')\n",
    "print('- number of histogram types: {}'.format(len(histstruct.histnames)))\n",
    "print('- number of lumisections: {}'.format(len(histstruct.lsnbs)))\n",
    "print('- masks: {}'.format(list(histstruct.masks.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
