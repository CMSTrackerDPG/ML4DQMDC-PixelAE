{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuration file for training and evaluating autoencoder models on a set of histograms**\n",
    "\n",
    "This file contains all settings and variables needed to define the configuration of the full processing chain. See the readme file for a list of all available parameters with some explanation of what they do.  \n",
    "\n",
    "Before using this configuration file, a valid HistStruct object that serves as an input to everything must be defined and stored.\n",
    "This HistStruct object should contain all histograms (all lumisections and all histogram types) that will be needed for training and testing.\n",
    "See create\\_histstruct.ipynb for an example script to create such a HistStruct object.  \n",
    "\n",
    "This configuration file should first be run separately, in order to configure (but not yet train) the autoencoder models and save them to the HistStruct. See below for an example of how these autoencoder models can be defined and added to the HistStruct.  \n",
    "\n",
    "Next, this configuration file can be imported in all following steps (training, fitting and testing).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external modules\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# local modules: utils\n",
    "sys.path.append('../utils')\n",
    "import autoencoder_utils as aeu\n",
    "from autoencoder_utils import mseTop10\n",
    "import generate_data_utils as gdu\n",
    "from notebook_utils.notebook_to_script import save_notebook_as_script\n",
    "\n",
    "# local modules: src\n",
    "print('importing src...')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/classifiers')\n",
    "sys.path.append('../src/cloudfitters')\n",
    "print('  import HistStruct'); import HistStruct\n",
    "print('  import AutoEncoder'); import AutoEncoder\n",
    "print('  import GaussianKdeFitter'); import GaussianKdeFitter\n",
    "print('refreshing src...')\n",
    "importlib.reload(HistStruct)\n",
    "importlib.reload(AutoEncoder)\n",
    "importlib.reload(GaussianKdeFitter)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for loading the data\n",
    "\n",
    "HISTSTRUCT_FILE_NAME = 'test.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters defining training and evaluation masks\n",
    "\n",
    "# for training\n",
    "TRAINING_MASKS = ['dcson','highstat', 'training']\n",
    "\n",
    "# for good test set\n",
    "TEST_GOOD_MASKS = [['dcson','highstat','good']]\n",
    "ngoodsets = len(TEST_GOOD_MASKS)\n",
    "TEST_GOOD_PARTITIONS = [-1]*ngoodsets\n",
    "\n",
    "# for bad test set\n",
    "TEST_BAD_MASKS = [['dcson','highstat','bad{}'.format(i)] for i in [0,1,2,3,4,5,6]]\n",
    "nbadsets = len(TEST_BAD_MASKS)\n",
    "TEST_BAD_PARTITIONS = [-1]*nbadsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the histstruct and extract some information (needed for GaussianKdeFitter)\n",
    "\n",
    "histstruct = HistStruct.HistStruct.load( HISTSTRUCT_FILE_NAME, load_classifiers=False )\n",
    "npoints = histstruct.get_histograms( histname=histstruct.histnames[0], masknames=TRAINING_MASKS ).shape[0]\n",
    "ndims = len(histstruct.histnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for plotting the input histograms\n",
    "\n",
    "DO_INITIAL_PLOT = True\n",
    "\n",
    "# example for local training\n",
    "INITIAL_PLOT_SETTINGS = ([ {'masknames':[['dcson','highstat','training'],['dcson','highstat','good']],\n",
    "                            'labellist':['training set','application run'],\n",
    "                            'colorlist':['blue','green']},\n",
    "                           {'masknames':[['dcson','highstat','good'],['dcson','highstat','bad']],\n",
    "                            'labellist':['application run','bad test sets'],\n",
    "                            'colorlist':['green','red']} ])\n",
    "\n",
    "# example for global training (with additional label 'good' included in histstruct)\n",
    "#INITIAL_PLOT_SETTINGS = ([ {'masknames':[['dcson','highstat','good'],['dcson','highstat','bad{}'.format(i)]],\n",
    "#                            'labellist':['typical good histograms','bad'],\n",
    "#                            'colorlist':['blue','red'],\n",
    "#                            'transparencylist':[0.01,1.]} for i in range(nbadsets) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for extend the training set using artificial data\n",
    "\n",
    "EXTEND_TRAINING = True\n",
    "EXTEND_TRAINING_FUNCTION = gdu.upsample_hist_set\n",
    "EXTEND_TRAINING_OPTIONS = {'figname':'','ntarget':5e4}\n",
    "EXTEND_TRAINING_PARTITIONS = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for defining and training an autoencoder for each element\n",
    "\n",
    "DO_TRAINING = True\n",
    "\n",
    "TRAINING_OPTIONS = {'epochs':40,'batch_size':500,'shuffle':False,'verbose':1,'validation_split':0.1}\n",
    "SAVE_MODELS = False\n",
    "SAVE_MODELS_DIR = 'test_models'\n",
    "SAVE_MODELS_BASENAME = 'autoencoder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setting up the classifiers\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # (do not run this cell again when importing the configuration file at later stages)\n",
    "\n",
    "    histstruct = HistStruct.HistStruct.load( HISTSTRUCT_FILE_NAME, load_classifiers=False, verbose=True )\n",
    "\n",
    "    if DO_TRAINING:\n",
    "    \n",
    "        for histname in histstruct.histnames:\n",
    "            input_size = histstruct.get_histograms( histname=histname ).shape[1]\n",
    "            arch = [int(input_size/2.)]\n",
    "            model = aeu.getautoencoder(input_size,arch)\n",
    "            classifier = AutoEncoder.AutoEncoder( model=model )\n",
    "            histstruct.add_classifier(histname,classifier)\n",
    "\n",
    "    # in case of false: load models\n",
    "\n",
    "    else:\n",
    "\n",
    "        modelloc = '../models/autoencoders_global_training_dcson_highstat_v20210622'\n",
    "        modelbasename = ''\n",
    "        for histname in histstruct.histnames:\n",
    "            print('loading model for {}'.format(histname))\n",
    "            modelname = modelbasename+'_'+histname+'.h5'\n",
    "            modelname = os.path.join(modelloc,modelname)\n",
    "            classifier = AutoEncoder.AutoEncoder.load( modelname,custom_objects={'mseTop10':mseTop10} )\n",
    "            histstruct.add_classifier(histname,classifier)\n",
    "        \n",
    "    # save modified histstruct\n",
    "    savename = os.path.splitext(HISTSTRUCT_FILE_NAME)[0]+'_configured.pkl'\n",
    "    histstruct.save( savename )\n",
    "    \n",
    "    # delete the loaded histstruct to free some memory\n",
    "    del histstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for plotting the multidemensional mse and fitting a distribution\n",
    "\n",
    "CLOUDFITTER_TYPE = GaussianKdeFitter.GaussianKdeFitter\n",
    "CLOUDFITTER_PLOT_TRAINING = True\n",
    "CLOUDFITTER_PLOT_TEST = True\n",
    "\n",
    "# settings for GaussianKdeFitter\n",
    "\n",
    "scott_bw = npoints**(-1./(ndims+4))\n",
    "bw_method = 20*scott_bw\n",
    "CLOUDFITTER_OPTIONS = {'bw_method':bw_method}\n",
    "\n",
    "# settings for HyperRectangleFitter\n",
    "quantiles = ([0.00062,0.0006,0.00015,0.00015,\n",
    "             0.0003,0.0003,0.00053,0.00065])\n",
    "#CLOUDFITTER_OPTIONS = {'quantiles':quantiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for extending the test set using artificial data\n",
    "\n",
    "EXTEND_TEST_GOOD = True\n",
    "EXTEND_TEST_GOOD_FUNCTION = gdu.upsample_hist_set\n",
    "EXTEND_TEST_GOOD_OPTIONS = {'figname':'','ntarget':7*5e3,'fourierstdfactor':20.}\n",
    "EXTEND_TEST_GOOD_PARTITIONS = [-1]*ngoodsets\n",
    "\n",
    "EXTEND_TEST_BAD = True \n",
    "EXTEND_TEST_BAD_FUNCTION = gdu.upsample_hist_set\n",
    "EXTEND_TEST_BAD_OPTIONS = {'figname':'','ntarget':5e3,'fourierstdfactor':20.}\n",
    "EXTEND_TEST_GOOD_PARTITIONS = [-1]*nbadsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for making roc curves and related test statistics\n",
    "\n",
    "PLOT_SCORE_DIST = True\n",
    "PLOT_SCORE_DIST_OPTIONS = {'siglabel':'anomalous', 'sigcolor':'r', \n",
    "                   'bcklabel':'good', 'bckcolor':'g', \n",
    "                   'nbins':200, 'normalize':True,\n",
    "                   'xaxtitle':'negative logarithmic probability',\n",
    "                   'yaxtitle':'number of lumisections (normalized)'}\n",
    "\n",
    "PLOT_ROC_CURVE = True\n",
    "PLOT_ROC_CURVE_OPTIONS = {'mode':'geom', 'doprint':False}\n",
    "\n",
    "PLOT_CONFUSION_MATRIX = True\n",
    "PLOT_CONFUSION_MATRIX_OPTIONS = {'wp':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for investigating particular runs and/or lumisections\n",
    "\n",
    "INSPECT_MODE = 'run'\n",
    "INSPECT_RUN = 306458\n",
    "INSPECT_LS = 204 \n",
    "INSPECT_MASKS = ['dcson','highstat']\n",
    "INSPECT_PLOT_SCORE = True\n",
    "\n",
    "INSPECT_RECO_MODE = 'auto'\n",
    "INSPECT_REFERENCE_MASKS = ['highstat','dcson','training']\n",
    "INSPECT_REFERENCE_PARTITIONS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for evaluating the model on a real set\n",
    "\n",
    "DO_EVAL = True\n",
    "EVAL_MASKS = ['golden', 'highstat', 'good']\n",
    "EVAL_SCORE_UP = 50\n",
    "EVAL_SCORE_DOWN = None\n",
    "\n",
    "EVAL_NMAXPLOTS = 1\n",
    "EVAL_OUTFILENAME = 'autoencoder_golden_json_flags'\n",
    "\n",
    "EVAL_RECO_MODE = 'auto'\n",
    "EVAL_REFERENCE_MASKS = ['highstat','dcson','training']\n",
    "EVAL_REFERENCE_PARTITIONS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_notebook_as_script( 'example_configuration_for_autoencoder_cfg.ipynb' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
