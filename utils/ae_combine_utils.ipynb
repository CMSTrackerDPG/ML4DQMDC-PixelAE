{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouping some useful functions for autoencoder_combine and autoencoder_iterative**  \n",
    "These utilities mainly consist of a commom data structure and functions to fit and plot distributions to the point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "\n",
    "# external modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "# local modules\n",
    "import csv_utils\n",
    "import json_utils\n",
    "import dataframe_utils\n",
    "import hist_utils\n",
    "import clustering_utils\n",
    "import generate_data_utils\n",
    "import autoencoder_utils\n",
    "from notebook_utils.notebook_to_script import save_notebook_as_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading the main datastructure combining the information from several histograms\n",
    "\n",
    "class histstructure:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.names = [] # list of histogram names\n",
    "        self.histograms = {} # dict mapping histogram name to 2D numpy array of histograms\n",
    "        self.entries = {} # dict mapping histogram name to 1D numpy array of number of entries per histogram\n",
    "        self.runnbs = [] # 1D numpy array of run numbers (same length as histograms)\n",
    "        self.lsnbs = [] # 1D numpy array of lumisection numbers (same length as histograms)\n",
    "        self.custom = {} # this dict remains empty, so the histstruct can be extended at runtime\n",
    "    \n",
    "    def create(self,year,histnames,jsonselector=None,highstatonly=False,dcsononly=False):\n",
    "        ### create the histstructure given the arguments provided\n",
    "        # most arguments are self-explanatory\n",
    "        # remarks:\n",
    "        # - if jsonselector is None, no selection will be done on run/ls number, i.e. all runs and lumisections are kept\n",
    "        # - if jsonselector contains a single negative run number as key, templates will be used (e.g. averaging the dataset) instead of actual ls from the data\n",
    "        #   for example, if jsonselector = {\"-15\":[[-1]]}, the dataset will be split in 15 parts and each part will be averaged to yield a single histogram (per type)\n",
    "        \n",
    "        dotemplates = False\n",
    "        ntemplates = 0\n",
    "        if( (jsonselector is not None) and (len(jsonselector)==1) and (int(list(jsonselector.keys())[0])<0) ): \n",
    "            dotemplates=True\n",
    "            ntemplates = -int(jsonselector.keys()[0])\n",
    "            \n",
    "        dfstruct = {} # temporary structure for dataframes\n",
    "        self.names = []\n",
    "        self.histograms = {}\n",
    "        self.entries = {}\n",
    "        runlist = []\n",
    "        selectorlist = []\n",
    "        for histname in histnames:\n",
    "            histfile = 'data/DF'+str(year)+'_'+histname+'.csv'\n",
    "            name = histfile.replace('.csv','')\n",
    "            # for each type of histogram, add the full data to the structure \n",
    "            # also build additional selectors depending on all histogram types simulaneously \n",
    "            print('reading '+histfile)\n",
    "            df = csv_utils.read_csv(histfile)\n",
    "            # select runs/lumisections if requested\n",
    "            if( (jsonselector is not None) and (not dotemplates) ):\n",
    "                df = dataframe_utils.select_runsls(df,jsonselector)\n",
    "            dfstruct[name] = df\n",
    "            # build high statistics selector if requested\n",
    "            if highstatonly: selectorlist.append( dataframe_utils.get_highstat(df) ) # select high statistics\n",
    "            else: selectorlist.append( dataframe_utils.get_runsls(df) ) # do no selection\n",
    "\n",
    "        # make combined selector now that we know selectors for each histogram type individually\n",
    "        totalselector = json_utils.get_lcs(selectorlist)\n",
    "\n",
    "        for i,name in enumerate(dfstruct.keys()):\n",
    "            print('adding '+name)\n",
    "            self.names.append(name)\n",
    "            df_temp = dataframe_utils.select_runsls(dfstruct[name],totalselector) # apply selector\n",
    "            if dcsononly: df_temp = dataframe_utils.select_dcson(df_temp) # include only DCS-on json\n",
    "            # determine statistics (must be done before normalizing)\n",
    "            self.entries[name] = np.array(df_temp['entries'])\n",
    "            # prepare the data\n",
    "            (hists_all,runnbs_all,lsnbs_all) = hist_utils.preparedatafromdf(df_temp,returnrunls=True,onlygolden=False,rebinningfactor=1)\n",
    "            # calculate templates if needed\n",
    "            if dotemplates:\n",
    "                hists_all = hist_tools.averagehists(hists_all,ntemplates)\n",
    "                runnbs_all = np.zeros(len(hists_all))\n",
    "                lsnbs_all = np.arange(len(hists_all))\n",
    "            # add the histograms to the structure\n",
    "            self.histograms[name] = hists_all\n",
    "            runnbs_all = runnbs_all.astype(int)\n",
    "            lsnbs_all = lsnbs_all.astype(int)\n",
    "            # if processing first histogram type, add run numbers, lsnumbers and golden indices to histstruct\n",
    "            if i==0:\n",
    "                self.runnbs = runnbs_all\n",
    "                self.lsnbs = lsnbs_all\n",
    "            # else check consistency\n",
    "            else:\n",
    "                if( not ( (runnbs_all==self.runnbs).all() and (lsnbs_all==self.lsnbs).all() ) ):\n",
    "                    print('### WARNING ###: incompatible run and lumisection numbers')\n",
    "        # delete temporary data structure\n",
    "        del dfstruct\n",
    "    \n",
    "    def get_golden_mask(self):\n",
    "        # return a boolean mask on the lumisections whether or not they belong to the golden json\n",
    "        mask = np.array( json_utils.isgolden(self.runnbs,self.lsnbs) )\n",
    "        return mask\n",
    "    \n",
    "    def get_golden_indices(self):\n",
    "        # return an array of indices of lumisections that belong to the golden json\n",
    "        indices = np.arange(len(self.runnbs))[self.get_golden_mask()]\n",
    "        return indices\n",
    "    \n",
    "    def get_perrun_indices(self):\n",
    "        # return a list of arrays of indices of lumisections, one element in the list represents one run\n",
    "        unique_runs = np.unique(self.runnbs)\n",
    "        perrun_indices = []\n",
    "        for ur in unique_runs:\n",
    "            perrun_indices.append( np.arange(len(self.runnbs))[self.runnbs==ur] )\n",
    "        return perrun_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### functions for fitting a normal-like or gaussian kernel distribution to a point cloud of mse's and making plots\n",
    "\n",
    "def get_mse_array(histstruct,valkey,dims=[]):\n",
    "    if len(dims)==0:\n",
    "        dims = list(range(len(histstruct.names)))\n",
    "    coords = np.expand_dims( histstruct.custom[valkey][histstruct.names[dims[0]]], axis=1 )\n",
    "    for dim in dims[1:]:\n",
    "        coords = np.concatenate( ( coords, np.expand_dims(histstruct.custom[valkey][histstruct.names[dim]], axis=1) ), axis=1 )\n",
    "    return coords\n",
    "\n",
    "def fitseminormal(histstruct,valkey,dims=[],fitnew=True,savefit=False):\n",
    "    coords = get_mse_array(histstruct,valkey,dims=dims)\n",
    "    if fitnew:\n",
    "        fitfunc = clustering_utils.seminormal(coords)\n",
    "        if savefit:\n",
    "            fitfunc.save('seminormal_fit_'+xname+'_'+yname+'.npy')\n",
    "    else:\n",
    "        fitfunc = clustering_utilsseminormal()\n",
    "        fitfunc.load('seminormal_fit_'+xname.replace('2018','2017')+'_'+yname.replace('2018','2017')+'.npy')\n",
    "    \n",
    "    return fitfunc\n",
    "\n",
    "def fitgaussiankde(histstruct,valkey,dims=[],maxnpoints=-1):\n",
    "    coords = get_mse_array(histstruct,valkey,dims=dims)\n",
    "    if( maxnpoints>0 and maxnpoints<len(coords) ): coords = coords[ np.random.choice(list(range(len(coords))),size=maxnpoints,replace=False) ]\n",
    "    fitfunc = clustering_utils.gaussiankde(coords)\n",
    "    return fitfunc\n",
    "\n",
    "def plotfit2d(histstruct,valkey,dims,fitfunc,doinitialplot=True,onlycontour=False,rangestd=30):\n",
    "    \n",
    "    xname = histstruct.names[dims[0]]\n",
    "    yname = histstruct.names[dims[1]]\n",
    "    xvals = histstruct.custom[valkey][xname]\n",
    "    yvals = histstruct.custom[valkey][yname]\n",
    "    \n",
    "    if doinitialplot:\n",
    "        # make an initial scatter plot of the data points\n",
    "        fig,ax = plt.subplots()\n",
    "        ax.plot(xvals,yvals,'.',markersize=1)\n",
    "        plt.xticks(rotation=90)\n",
    "        ax.set_xlabel(xname+' MSE')\n",
    "        ax.set_ylabel(yname+' MSE')\n",
    "        \n",
    "    # determine plotting range as a fixed zoom from scatter plot\n",
    "    #xlim = ax.get_xlim()[1]\n",
    "    #ylim = ax.get_ylim()[1]\n",
    "    #zoomxlim = xlim/1.\n",
    "    #zoomylim = ylim/1.\n",
    "    # determine plotting range as a fixed number of stds\n",
    "    zoomxlim = rangestd*np.sqrt(fitfunc.cov[0,0])\n",
    "    zoomylim = rangestd*np.sqrt(fitfunc.cov[1,1])\n",
    "    \n",
    "    x,y = np.mgrid[0:zoomxlim:zoomxlim/100.,\n",
    "                   0:zoomylim:zoomylim/100.]\n",
    "    pos = np.dstack((x, y))\n",
    "\n",
    "    # make a new plot of probability contours and overlay data points\n",
    "    fig,ax = plt.subplots()\n",
    "    contourplot = ax.contourf(x, y, np.log(fitfunc.pdfgrid(pos)),30)\n",
    "    plt.colorbar(contourplot)\n",
    "    if not onlycontour: ax.plot(xvals,yvals,'.b',markersize=2)\n",
    "    ax.set_xlim((0,zoomxlim))\n",
    "    ax.set_ylim((0,zoomylim))\n",
    "    #plt.xticks(rotation=90)\n",
    "    ax.set_xlabel(xname+' MSE')\n",
    "    ax.set_ylabel(yname+' MSE')\n",
    "    ax.ticklabel_format(axis='both', style='sci', scilimits=(0,0))\n",
    "    \n",
    "    return (fig,ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### normalizer class (used for 1D mse arrays)\n",
    "# still experimental, not enough checks on inputs etc.\n",
    "\n",
    "class msenormalizer:\n",
    "    \n",
    "    # parameters:\n",
    "    # std: std of array\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.std = 1.\n",
    "        \n",
    "    def fit(self,array):\n",
    "        self.std = np.std(array)\n",
    "        return self.apply(array)\n",
    "    \n",
    "    def apply(self,array):\n",
    "        return array/self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_notebook_as_script( 'ae_combine_utils.ipynb' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
