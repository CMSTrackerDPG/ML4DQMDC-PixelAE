{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A collection of useful basic functions.**  \n",
    "Functionality includes (among others):\n",
    "- reading the raw input csv files and producing more manageable csv files (grouped per histogram type).\n",
    "- reading csv files into dataframes and performing basic operations (e.g. selecting DCS-bit on data or golden json data).\n",
    "- some plotting functions.\n",
    "- preparing data for machine learning, starting from e.g. the dataframes read from a csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "# as this notebook is at the basis, it does not include other notebooks within this project, only external python modules\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### some functions that point to the data directories (hard-coded for now!)\n",
    "# example usage of these functions: see function write_skimmed_csv within this same notebook\n",
    "\n",
    "def get_data_dirs(year='2017',eras=[],dim=1):\n",
    "    ### yield all data directories\n",
    "    # note that the location of the data is hard-coded;\n",
    "    # this function might break for newer or later reprocessings of the data.\n",
    "    # - year is a string, either '2017' or '2018'\n",
    "    # - era is a list containing a selection of era names\n",
    "    #   (default empty list = all eras)\n",
    "    # - dim is either 1 or 2 (for 1D or 2D plots)\n",
    "    if(year=='2017' and len(eras)==0): eras = ['B','C','D','E','F']\n",
    "    if(year=='2018' and len(eras)==0): eras = ['A','B','C','D']\n",
    "    basedir = '/eos/project/c/cmsml4dc/ML_2020/UL'+year+'_Data/'\n",
    "    for era in eras:\n",
    "        eradir = basedir+'DF'+year+era+'_'+str(dim)+'D_Complete'\n",
    "        if not os.path.exists(eradir):\n",
    "            print('### ERROR ###: requested directory '+eradir+' does not seem to exist...')\n",
    "            return\n",
    "        yield eradir\n",
    "\n",
    "def get_csv_files(inputdir):\n",
    "    ### yields paths to all csv files in input directory\n",
    "    # note that the output paths consist of input_dir/filename\n",
    "    # this function is only meant for 1-level down searching,\n",
    "    # i.e. the .csv files listed directly under input_dir.\n",
    "    for el in os.listdir(inputdir):\n",
    "        if el[-4:]=='.csv':\n",
    "            yield os.path.join(inputdir,el)\n",
    "\n",
    "def sort_filenames(filelist):\n",
    "    ### sort filenames in numerical order (e.g. 2 before 10)\n",
    "    # note that the number is supposed to be in ..._<number>.<extension> format\n",
    "    nlist = []\n",
    "    for f in filelist:\n",
    "        temp = f.split('.')[0]\n",
    "        temp = temp[temp.rfind('_')+1:]\n",
    "        nlist.append(int(temp))\n",
    "    return [f for _,f in sorted(zip(nlist,filelist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### some functions to load one or more csv files into pandas dataframe (df) and make a subselection of the histograms contained in them\n",
    "\n",
    "def read_csv(csv_file):\n",
    "    ### read csv file into pandas dataframe\n",
    "    # csv_file is the path to the csv file to be read\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.sort_values(by=['fromrun','fromlumi'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "# getter and selector for histogram names \n",
    "\n",
    "def get_histnames(df):\n",
    "    ### get a list of (unique) histogram names present in a df\n",
    "    # df is a dataframe (e.g. the return value of read_csv)\n",
    "    histnamelist = []\n",
    "    for i in list(df.index):\n",
    "        val = df.at[i,'hname'] \n",
    "        if val not in histnamelist: \n",
    "            histnamelist.append(val)\n",
    "    return histnamelist\n",
    "    \n",
    "def select_histnames(df,histnames):\n",
    "    ### keep only a subset of histograms in a df\n",
    "    # histnames is a list of histogram names to keep in the df.\n",
    "    df = df[df['hname'].isin(histnames)]\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "# getter and selector for run numbers\n",
    "\n",
    "def get_runs(df):\n",
    "    ### return a list of (unique) run numbers present in a df\n",
    "    # df is a dataframe\n",
    "    runlist = []\n",
    "    for i in list(df.index):\n",
    "        val = df.at[i,'fromrun'] \n",
    "        if val not in runlist: \n",
    "            runlist.append(val)\n",
    "    return runlist\n",
    "\n",
    "def select_runs(df,runnbs):\n",
    "    ### keep only a subset of runs in a df\n",
    "    # runnbs is a list of run numbers to keep in the df.\n",
    "    df = df[df['fromrun'].isin(runnbs)]\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "# getter and selector for lumisection numbers\n",
    "# note: no check is done on the run number so mostly useful if the input df already contains only a single run\n",
    "\n",
    "def get_ls(df):\n",
    "    ### return a list of ls numbers present in a df\n",
    "    # not that the numbers are not required to be unique\n",
    "    lslist = []\n",
    "    for i in list(df.index):\n",
    "        val = df.at[i,'fromlumi']\n",
    "        lslist.append(val)\n",
    "    return lslist\n",
    "\n",
    "def select_ls(df,lsnbs):\n",
    "    ### keep only a subset of lumisection numbers in a df\n",
    "    # lsnbs is a list of lumisection numbers to keep in the df.\n",
    "    df = df[df['fromlumi'].isin(runnbs)]\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "# more advanced getter and selector for multiple runs, each with their own lumisection range\n",
    "# note: here the datatype used for this kind of selection is a list of tuples.\n",
    "#       each tuple in the list is of the form (run number,[lumisection numbers]),\n",
    "#       where [-1] implies all lumisections in that run.\n",
    "#       In the future it might be best to implement similar functions using a json file format instead of this custom data format,\n",
    "#       for easier integration in whatever already exists...\n",
    "\n",
    "def get_runsls(df):\n",
    "    ### return a list of tuples of format (runnb,[lsnbs]) in a df\n",
    "    runslslist = get_runs(df)\n",
    "    for i,run in enumerate(runslslist):\n",
    "        runslslist[i] = (run,get_ls(select_runs(df,[run])))\n",
    "    return runslslist\n",
    "\n",
    "def select_runsls(df,select):\n",
    "    ### keep only a subset of runs and ls in df\n",
    "    # select is a list of tuples of format (runnb,[lsnbs])\n",
    "    # (use [lsnbs]=[-1] to keep whole run)\n",
    "    partialdfs = []\n",
    "    for el in select:\n",
    "        thisdf = df[df['fromrun']==el[0]]\n",
    "        if(el[1][0]!=-1):\n",
    "            thisdf = thisdf[thisdf['fromlumi'].isin(el[1])]\n",
    "        partialdfs.append(thisdf)\n",
    "    df = pd.concat(partialdfs,ignore_index=True)\n",
    "    df.sort_values(by=['fromrun','fromlumi'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "# getter and selector for sufficient statistics\n",
    "# same remark about data format holds here as it holds for the above.\n",
    "\n",
    "def get_highstat(df,entries_to_bins_ratio=100):\n",
    "    ### return a select object of runs and ls of histograms with high statistics\n",
    "    return get_runsls(df[df['entries']/df['Xbins']>entries_to_bins_ratio])\n",
    "\n",
    "def select_highstat(df,entries_to_bins_ratio=100):\n",
    "    return select_runsls(df,get_highstat(df,entries_to_bins_ratio))\n",
    "\n",
    "# other functions that more or less fit into this block\n",
    "\n",
    "def read_and_merge_csv(csv_files,histnames=[],runnbs=[]):\n",
    "    ### read and merge list of csv files into a single df\n",
    "    # csv_files is a list of paths to files to merge into a df\n",
    "    # histnames is a list of the types of histograms to keep (default: all)\n",
    "    # runnbs is a list of run numbers to keep (default: all)\n",
    "    dflist = []\n",
    "    for f in csv_files:\n",
    "        dffile = read_csv(f)\n",
    "        if len(histnames)>0: \n",
    "            dffile = select_histnames(dffile,histnames)\n",
    "        if len(runnbs)>0:\n",
    "            dffile = dffile[dffile['fromrun'].isin(runnbs)]\n",
    "        dflist.append(dffile)\n",
    "    df = pd.concat(dflist,ignore_index=True)\n",
    "    df.sort_values(by=['fromrun','fromlumi'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_lcs(list_of_selects):\n",
    "    ### return a select object that is the largest common subset between the select objects in list_of_selects\n",
    "    # by 'select object' we mean the list of tuples that can be used to select specific runs/lumisections in a dataframe (described above).\n",
    "    # remark: this is probably not the most efficient implementation...\n",
    "    if(len(list_of_selects)==1): return list_of_selects[0]\n",
    "    lcs = []\n",
    "    for runobject in list_of_selects[0]:\n",
    "        runnb = runobject[0]\n",
    "        ls = runobject[1]\n",
    "        allcommon = True\n",
    "        for select in list_of_selects[1:]:\n",
    "            thiscommon = False\n",
    "            for otherrunobject in select:\n",
    "                if otherrunobject[0]==runnb:\n",
    "                    commonls = list(set(ls) & set(otherrunobject[1]))\n",
    "                    if len(commonls)>0:\n",
    "                        thiscommon = True\n",
    "                        ls = commonls\n",
    "            if not thiscommon: \n",
    "                allcommon = False\n",
    "                break\n",
    "        if allcommon:\n",
    "            lcs.append((runnb,ls))\n",
    "    return lcs\n",
    "\n",
    "def write_skimmed_csv(histnames,year):\n",
    "    ### read all available data for a given year\n",
    "    # and write a separate csv file for each histogram type in histnames;\n",
    "    # each csv file will contain one single histogram type \n",
    "    # for all runs and lumisections for the given year.\n",
    "    # note: this function can take quite a while to run!\n",
    "    datadirs = list(get_data_dirs(year))\n",
    "    csvfiles = []\n",
    "    for datadir in datadirs:\n",
    "        csvfiles += sort_filenames(list(get_csv_files(datadir)))\n",
    "    # read histograms into df\n",
    "    temp = read_and_merge_csv(csvfiles,histnames)\n",
    "    # write df to files\n",
    "    for histname in histnames:\n",
    "        seldf = select_histnames(temp,[histname])\n",
    "        histname = histname.replace(' ','_')\n",
    "        seldf.to_csv('DF'+year+'_'+histname+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions to find if a lumisection belongs to DCS, GOLDEN or neither\n",
    "\n",
    "def injson(run,lumi,jsonfile):\n",
    "    ### find if a run and lumi combination is in a given json file\n",
    "    # run and lumi are either integers or (equally long) arrays of integers\n",
    "    # jsonfile is a path to a json file\n",
    "    # output is a boolean or array of booleans respectively\n",
    "    if not os.path.exists(jsonfile):\n",
    "        print('requested json file '+jsonfile+' does not seem to exist...')\n",
    "    with open(jsonfile) as f: gdict = json.load(f)\n",
    "    if not hasattr(run,'__len__') and not isinstance(run,str):\n",
    "        run = [run]; lumi = [lumi]\n",
    "    res = np.zeros(len(run),dtype=np.int8)\n",
    "    for i,(r,l) in enumerate(zip(run,lumi)):\n",
    "        r = str(r)\n",
    "        if not r in gdict: continue\n",
    "        glumis = gdict[r]\n",
    "        inlumis = False\n",
    "        for lumis in glumis:\n",
    "            if(l>=lumis[0] and l<=lumis[1]): \n",
    "                inlumis = True\n",
    "                break\n",
    "        if inlumis: res[i] = 1\n",
    "    res = res.astype(np.bool)\n",
    "    if len(res)==1: res = res[0]\n",
    "    return res\n",
    "\n",
    "def isgolden(run,lumi):\n",
    "    ### find if a run and lumi combination is in golden json file\n",
    "    # run and lumi are either integers or (equally long) arrays of integers\n",
    "    \n",
    "    # old golden jsons (prompt reco):\n",
    "    #jsonloc2017 = '/eos/project/c/cmsml4dc/ML_2020/Scripts2020/GoldenJSON17.json'\n",
    "    #jsonloc2018 = 'goldenJSON2018.json' # temporary and manually copied from twiki, removed now.\n",
    "    # new golden jsons (rereco)\n",
    "    jsonloc2017 = 'utils/json_GOLDEN_2017.txt' \n",
    "    # ultralegacy reprocessing; from: /afs/cern.ch/cms/CAF/CMSCOMM/COMM_DQM/certification/Collisions17/13TeV/Legacy_2017/Cert_294927-306462_13TeV_UL2017_Collisions17_GoldenJSON.txt\n",
    "    jsonloc2018 = 'utils/json_GOLDEN_2018.txt' \n",
    "    # legacy reprocessing; from: /afs/cern.ch/cms/CAF/CMSCOMM/COMM_DQM/certification/Collisions18/13TeV/Legacy_2018/Cert_314472-325175_13TeV_Legacy2018_Collisions18_JSON.txt\n",
    "    \n",
    "    return injson(run,lumi,jsonloc2017) + injson(run,lumi,jsonloc2018)\n",
    "\n",
    "def select_golden(df):\n",
    "    ### keep only golden lumisections in df\n",
    "    dfres = df[isgolden(df['fromrun'].values,df['fromlumi'].values)]\n",
    "    dfres.reset_index(drop=True,inplace=True)\n",
    "    return dfres\n",
    "\n",
    "def select_notgolden(df):\n",
    "    ### keep all but golden lumisections in df\n",
    "    dfres = df[np.invert(isgolden(df['fromrun'].values,df['fromlumi'].values))]\n",
    "    dfres.reset_index(drop=True,inplace=True)\n",
    "    return dfres\n",
    "\n",
    "def isdcson(run,lumi):\n",
    "    ### find if a run and lumi combination is in DCS-only json file\n",
    "    # run and lumi are either integers or arrays of integers\n",
    "    \n",
    "    jsonloc2017 = 'utils/json_DCSONLY_2017.txt' \n",
    "    # from: /afs/cern.ch/cms/CAF/CMSCOMM/COMM_DQM/certification/Collisions17/13TeV/DCSOnly/json_DCSONLY.txt\n",
    "    jsonloc2018 = 'utils/json_DCSONLY_2018.txt' \n",
    "    # from: /afs/cern.ch/cms/CAF/CMSCOMM/COMM_DQM/certification/Collisions18/13TeV/DCSOnly/json_DCSONLY.txt\n",
    "    return injson(run,lumi,jsonloc2017) + injson(run,lumi,jsonloc2018)\n",
    "\n",
    "def select_dcson(df):\n",
    "    ### keep only lumisections in df that have DCS-bit on\n",
    "    dfres = df[isdcson(df['fromrun'].values,df['fromlumi'].values)]\n",
    "    dfres.reset_index(drop=True,inplace=True)\n",
    "    return dfres\n",
    "\n",
    "def select_dcsoff(df):\n",
    "    ### keep only lumisections in df that have DCS-bit off\n",
    "    dfres = df[np.invert(isdcson(df['fromrun'].values,df['fromlumi'].values))]\n",
    "    dfres.reset_index(drop=True,inplace=True)\n",
    "    return dfres\n",
    "\n",
    "### deprecated functions ###\n",
    "# either not used anymore since a long time (so potentially need updates)\n",
    "# or known to be wrong/senseless/unuseful\n",
    "\n",
    "def isgolden_fast(run,lumi,gdict):\n",
    "    ### faster method using an already loaded dict\n",
    "    # run and lumi are integers\n",
    "    run = str(run)\n",
    "    if not run in gdict: return False\n",
    "    glumis = gdict[run]\n",
    "    for lumis in glumis:\n",
    "        if(lumi>=lumis[0] and lumi<=lumis[1]): \n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def isbad(run,lumi):\n",
    "    jsonloc2017 = '/eos/project/c/cmsml4dc/ML_2020/Scripts2020/JsonBAD17.json'\n",
    "    # no 2018 json file for bad runs available yet!\n",
    "    # NOTE: turns out this is not official, just something that Francesco created based on an autoencoder...\n",
    "    # do not use for official tests.\n",
    "    return injson(run,lumi,jsonloc2017)\n",
    "\n",
    "def get_bad(df):\n",
    "    ### return a list of bad lumisections, without modifying df\n",
    "    runlist = []; lslist = []\n",
    "    for i in range(len(df)):\n",
    "        r = df.at[i,'fromrun']\n",
    "        l = df.at[i,'fromlumi']\n",
    "        if(isbad(r,l)): \n",
    "            runlist.append(r)\n",
    "            lslist.append(l)\n",
    "    return(runlist,lslist)\n",
    "\n",
    "def get_quality(df):\n",
    "    ### get total entries, number of 'good' ones, 'bad' ones and other\n",
    "    # warning: this function assumes that df contains only one entry per unique LS!\n",
    "    ngood = np.sum(isgolden(df['fromrun'].values,df['fromlumi'].values))\n",
    "    nbad = np.sum(isbad(df['fromrun'].values,df['fromlumi'].values))\n",
    "    nother = len(df)-ngood-nbad\n",
    "    return (ngood,nbad,nother)\n",
    "\n",
    "def select_bad(df):\n",
    "    ### keep only bad lumisections in df\n",
    "    dfres = df[isbad(df['fromrun'].values,df['fromlumi'].values)]\n",
    "    dfres.reset_index(drop=True,inplace=True)\n",
    "    return dfres\n",
    "\n",
    "def select_golden_and_bad(df):\n",
    "    ### keep only golden and bad lumisections in df\n",
    "    dfres = df[isgolden(df['fromrun'].values,df['fromlumi'].values) + isbad(df['fromrun'].values,df['fromlumi'].values)]\n",
    "    dfres.reset_index(drop=True,inplace=True)\n",
    "    return dfres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to obtain histograms in np array format\n",
    "\n",
    "def get_hist_values(df):\n",
    "    ### same as builtin \"df['histo'].values\" but convert strings to np arrays\n",
    "    # also an array of run and LS numbers is returned\n",
    "    # warning: no check is done to assure that all histograms are of the same type!\n",
    "    nn = len(json.loads(df.at[0,'histo']))\n",
    "    vals = np.zeros((len(df),nn))\n",
    "    ls = np.zeros(len(df))\n",
    "    runs = np.zeros(len(df))\n",
    "    for i in range(len(df)):\n",
    "        vals[i,:] = json.loads(df.at[i,'histo'])\n",
    "        ls[i] = int(df.at[i,'fromlumi'])\n",
    "        runs[i] = int(df.at[i,'fromrun'])\n",
    "    return (vals,runs,ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for plotting \n",
    "      \n",
    "def plot_hists(histlist,colorlist=[],labellist=[],transparency=1,xlims=(0,-1)):\n",
    "    ### plot some histograms (in histlist) in one figure using specified colors and/or labels\n",
    "    # - histlist is a list of 1D arrays containing the histograms (or a 2D array of shape (nhistograms,nbins))\n",
    "    # - colorlist is a list or array containing colors (in string format)\n",
    "    # - labellist is a list or array containing labels for in legend\n",
    "    dolabel = True; docolor = True\n",
    "    if len(labellist)==0:\n",
    "        labellist = ['']*len(histlist)\n",
    "        dolabel = False\n",
    "    if len(colorlist)==0:\n",
    "        docolor = False\n",
    "    if xlims[1]<xlims[0]: xlims = (0,len(histlist[0]))\n",
    "    xax = np.linspace(xlims[0],xlims[1],num=len(histlist[0]))\n",
    "    plt.figure()\n",
    "    for i,row in enumerate(histlist):\n",
    "        if docolor: plt.step(xax,row,color=colorlist[i],label=labellist[i],alpha=transparency)\n",
    "        else: plt.step(xax,row,label=labellist[i],alpha=transparency)\n",
    "    if dolabel: plt.legend()  \n",
    "    \n",
    "def plot_hists_multi(histlist,colorlist=[],labellist=[],transparency=1,xlims=(0,-1)):\n",
    "    ### plot many histograms (in histlist) in one figure using specified colors and/or labels\n",
    "    # - histlist is a list of 1D arrays containing the histograms (or a 2D array of shape (nhistograms,nbins))\n",
    "    # - colorlist is a list or array containing numbers to be mapped to colors\n",
    "    # - labellist is a list or array containing labels for in legend\n",
    "    dolabel = True; docolor = True\n",
    "    if len(labellist)==0:\n",
    "        labellist = ['']*len(histlist)\n",
    "        dolabel = False\n",
    "    if len(colorlist)==0:\n",
    "        docolor = False\n",
    "    if xlims[1]<xlims[0]: xlims = (0,len(histlist[0]))\n",
    "    xax = np.linspace(xlims[0],xlims[1],num=len(histlist[0]))\n",
    "    plt.figure()\n",
    "    if docolor:\n",
    "        norm = mpl.colors.Normalize(vmin=np.min(colorlist),vmax=np.max(colorlist))\n",
    "        cobject = mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.jet)\n",
    "        cobject.set_array([]) # ad-hoc bug fix\n",
    "    for i,row in enumerate(histlist):\n",
    "        if docolor: plt.step(xax,row,color=cobject.to_rgba(colorlist[i]),label=labellist[i],alpha=transparency)\n",
    "        else: plt.step(xax,row,label=labellist[i],alpha=transparency)\n",
    "    if docolor: plt.colorbar(cobject)\n",
    "    if dolabel: plt.legend()\n",
    "    \n",
    "def plot_hists_from_df(df,histtype,nhists):\n",
    "    ### plot a number of histograms in a dataframe\n",
    "    # - df is the dataframe from which to plot\n",
    "    # - histtype is the name of the histogram type (e.g. 'chargeInner_PXLayer_1')\n",
    "    # - nhists is the number of histograms to plot\n",
    "    dfs = select_histnames(df,[histtype])\n",
    "    nhists = min(len(dfs),nhists)\n",
    "    dfs = dfs[0:nhists+1]\n",
    "    val = get_hist_values(dfs)[0]\n",
    "    plot_hists(val)\n",
    "    \n",
    "def plot_sets(setlist,ax=None,title='',colorlist=[],labellist=[],transparencylist=[],xlims=(0,-1)):\n",
    "    ### plot multiple sets of histograms to compare the shapes\n",
    "    # - setlist is a list of 2D numpy arrays containing histograms\n",
    "    # - ax is a pyplot axis object (if none a new figure is created)\n",
    "    # - title is a string that will be used as the title for the ax object\n",
    "    # other parameters are lists of which each element applies to one list of histograms\n",
    "    dolabel = True\n",
    "    if len(labellist)==0:\n",
    "        labellist = ['']*len(setlist)\n",
    "        dolabel = False\n",
    "    if len(colorlist)==0:\n",
    "        colorlist = ['red','blue','green','orange']\n",
    "        if len(setlist)>4:\n",
    "            print('ERROR: please specify the colors if you plot more than four sets.')\n",
    "            return\n",
    "    if len(transparencylist)==0:\n",
    "        transparencylist = [1.]*len(setlist)\n",
    "    if xlims[1]<xlims[0]: xlims = (0,len(setlist[0][0]))\n",
    "    xax = np.linspace(xlims[0],xlims[1],num=len(setlist[0][0]))\n",
    "    if ax is None: fig,ax = plt.subplots()\n",
    "    for i,histlist in enumerate(setlist):\n",
    "        row = histlist[0]\n",
    "        ax.step(xax,row,color=colorlist[i],label=labellist[i],alpha=transparencylist[i])\n",
    "        if len(histlist)<2: continue\n",
    "        for j,row in enumerate(histlist[1:,:]):\n",
    "            ax.step(xax,row,color=colorlist[i],alpha=transparencylist[i])\n",
    "    if dolabel: ax.legend(loc='upper right')\n",
    "    if len(title)>0: ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### functions for calculating moments of a histogram\n",
    "\n",
    "def moment(bins,counts,order):\n",
    "    ### get n-th central moment of a histogram\n",
    "    # - bins is a 1D or 2D np array holding the bin centers\n",
    "    #   (shape (nbins) or (nhistograms,nbins))\n",
    "    # - array is a 2D np array containing the bin counts\n",
    "    #   (shape (nhistograms,nbins))\n",
    "    # - order is the order of the moment to calculate\n",
    "    #   (0 = maximum, 1 = mean value)\n",
    "    if len(bins.shape)==1:\n",
    "        bins = np.tile(bins,(len(counts),1))\n",
    "    if not bins.shape == counts.shape:\n",
    "        print('### ERROR ###: bins and counts do not have the same shape!')\n",
    "        return None\n",
    "    if len(bins.shape)==1:\n",
    "        bins = np.array([bins])\n",
    "        counts = np.array([counts])\n",
    "    if order==0: # return maximum\n",
    "        return np.nan_to_num(np.max(counts,axis=1))\n",
    "    return np.nan_to_num(np.divide(np.sum(np.multiply(counts,np.power(bins,order)),axis=1,dtype=np.float),np.sum(counts,axis=1)))\n",
    "\n",
    "def histmean(bins,counts):\n",
    "    ### special case of moment calculation\n",
    "    return moment(bins,counts,1)\n",
    "\n",
    "def histrms(bins,counts):\n",
    "    ### special case of moment calculation\n",
    "    return np.power(moment(bins,counts,2)-np.power(moment(bins,counts,1),2),0.5)\n",
    "\n",
    "def histmoments(bins,counts,orders):\n",
    "    ### apply moment calculation for a list of orders\n",
    "    # the return type is a numpy array of shape (nhistograms,nmoments)\n",
    "    moments = np.zeros((len(counts),len(orders)))\n",
    "    for i,order in enumerate(orders):\n",
    "        moments[:,i] = moment(bins,counts,order)\n",
    "    return moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### averaging a collection of histograms (e.g. for template definition)\n",
    "\n",
    "def averagehists(hists,nout):\n",
    "    ### partition hists (of shape (nhistograms,nbins)) into nout parts and take the average histogram of each part\n",
    "    avghists = np.zeros((nout,hists.shape[1]))\n",
    "    nsub = int(len(hists)/nout)\n",
    "    for i in range(nout):\n",
    "        startindex = i*nsub\n",
    "        stopindex = (i+1)*nsub\n",
    "        avghists[i,:] = np.mean(hists[startindex:stopindex,:],axis=0)\n",
    "    return avghists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### rebinning of histograms\n",
    "\n",
    "def rebinhists(hists,factor):\n",
    "    ### perform rebinning on a set of histograms\n",
    "    # hists is a numpy array of shape (nhistograms,nbins)\n",
    "    # factor is the rebinning factor, which must be a divisor of nbins.\n",
    "    if(not hists.shape[1]%factor==0): \n",
    "        print('### ERROR ###: no rebinning performed since no suitable reduction factor was given.')\n",
    "        return hists\n",
    "    (len1,len2) = hists.shape\n",
    "    newlen = int(len2/factor)\n",
    "    rebinned = np.zeros((len1,newlen))\n",
    "    for i in range(newlen):\n",
    "        rebinned[:,i] = np.sum(hists[:,factor*i:factor*(i+1)],axis=1)\n",
    "    return rebinned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### normalization\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def normalizehists(hists):\n",
    "    ### perform normalization (i.e. sum of bin contents equals one for each histogram)\n",
    "    return normalize(hists, norm='l1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparedatafromnpy(dataname, rebinningfactor=1, donormalize=True, doplot=False):\n",
    "    # read a .npy file and output the histograms\n",
    "    \n",
    "    hist = np.load(dataname,allow_pickle=False)\n",
    "    # preprocessing of the data: rebinning and normalizing\n",
    "    hist = hist[:,1:-1]\n",
    "    if rebinningfactor != 1: rhist = rebinhists(hist,rebinningfactor)\n",
    "    else: rhist = hist\n",
    "    if donormalize: rhist = normalizehists(rhist)\n",
    "        \n",
    "    if not doplot: return rhist\n",
    "    \n",
    "    # plot histograms\n",
    "    plt.figure()\n",
    "    xlims = (0,len(rhist[0]))\n",
    "    xax = np.linspace(xlims[0],xlims[1],num=len(rhist[0]))\n",
    "    for i in range(len(hist)): plt.step(xax,rhist[int(i),:],color='b')\n",
    "    plt.title('Histograms in file')\n",
    "        \n",
    "    return rhist\n",
    "\n",
    "def preparedatafromdf(df, returnrunls=False, onlygolden=False, rebinningfactor=1, donormalize=True, doplot=False):\n",
    "    # prepare the data contained in a dataframe in the form of a numpy array\n",
    "    # args:\n",
    "    # - returnrunls: wether to return only a histogram array or 1D arrays of run and lumisection numbers as well\n",
    "    # - onlygolden: if True, only lumisections in the golden json file are kept\n",
    "    # - rebinningfactor: an integer number to downsample the histograms in the dataframe\n",
    "    # - donormalize: if True, data are normalized\n",
    "    # - doplot: if True, some example plots are made showing the histograms\n",
    "    \n",
    "    if onlygolden:\n",
    "        df = select_golden(df)\n",
    "\n",
    "    # preprocessing of the data: rebinning and normalizing\n",
    "    (hist,runnbs,lsnbs) = get_hist_values(df)\n",
    "    hist = hist[:,1:-1]\n",
    "    if rebinningfactor != 1: rhist = rebinhists(hist,rebinningfactor)\n",
    "    else: rhist = hist\n",
    "    if donormalize: rhist = normalizehists(rhist)\n",
    "        \n",
    "    if not doplot:\n",
    "        if returnrunls: return (rhist,runnbs,lsnbs) \n",
    "        else: return rhist\n",
    "    \n",
    "    # plot some examples\n",
    "    nplot = min(10,len(hist))\n",
    "    flatindex = np.linspace(0,len(hist),num=len(hist),endpoint=False)\n",
    "    randint = np.random.choice(flatindex,size=nplot,replace=False)\n",
    "    xlims = (0,len(hist[0]))\n",
    "    xax = np.linspace(xlims[0],xlims[1],num=len(hist[0]))\n",
    "    plt.figure()\n",
    "    for i in randint: plt.step(xax,hist[int(i),:],color='r')\n",
    "    plt.title('Examples of histograms in data')\n",
    "    plt.figure()\n",
    "    for i in randint: plt.step(xax,rhist[int(i),:],color='b')\n",
    "    plt.title('Same histograms, but rebinned and normalized')\n",
    "        \n",
    "    if returnrunls: return (rhist,runnbs,lsnbs)\n",
    "    else: return rhist\n",
    "\n",
    "def preparedatafromcsv(dataname, returnrunls=False, onlygolden=False, rebinningfactor=1, donormalize=True, doplot=False):\n",
    "    # prepare the data contained in a dataframe csv file in the form of a numpy array\n",
    "    # args:\n",
    "    # - returnrunls: wether to return only a histogram array or 1D arrays of run and lumisection numbers as well\n",
    "    # - onlygolden: if True, only lumisections in the golden json file are kept\n",
    "    # - rebinningfactor: an integer number to downsample the histograms in the dataframe\n",
    "    # - doplot: if True, some example plots are made showing the histograms\n",
    "\n",
    "    # read data\n",
    "    df = read_csv(dataname)\n",
    "    # prepare data from df\n",
    "    return preparedatafromdf(df, returnrunls=returnrunls,onlygolden=onlygolden,rebinningfactor=rebinningfactor,donormalize=donormalize,doplot=doplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
