{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A collection of functions used for performing clustering tasks**  \n",
    "Part 1 of this notebook consists of a class definition for fitting a distribution to a multidimensional point cloud.  \n",
    "Part 2 is a little deprecated not but kept for reference; it contains functionality for pre-filtering the histograms in the training set based on their moments (e.g. mean, rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: fitting a distribution to a point cloud**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### functionality for fitting a function to point multidimensional point clouds\n",
    "\n",
    "# imports\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "\n",
    "class fitfunction:\n",
    "    ### abstract base class for all fit functions\n",
    "    # all other fit functions inherit from fitfunction and overload its functions\n",
    "    # no concrete fitting procedure is implemented,\n",
    "    # but some basic checks on dimensionality are performed\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self,points):\n",
    "        self.npoints = points.shape[0]\n",
    "        self.ndims = points.shape[1]\n",
    "        \n",
    "    # get pdf at points\n",
    "    def pdf(self,points):\n",
    "        ### get the pdf (probability density function) value at given points\n",
    "        # points is a 2D numpy array of shape (npoints,ndims)\n",
    "        # the output is a 1D array of shape (npoints)\n",
    "        pshape = points.shape\n",
    "        if not len(pshape)==2:\n",
    "            print('wrong input shape')\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def pdfgrid(self,grid):\n",
    "        ### get the pdf (probability density function) value at a given grid\n",
    "        # (only applicable to 2D case!)\n",
    "        # grid is a np array of shape (nx,ny,2)\n",
    "        # containing the x- and y-values in its first and second depth-wise dimension respectively.\n",
    "        # the grid is typically (but not necessarily) created via:\n",
    "        # x,y = np.mgrid[<xrange>,<yrange>]\n",
    "        # grid = np.dstack(x,y)\n",
    "        gshape = grid.shape\n",
    "        if not (self.ndims==2 and len(gshape)==3 and gshape[2]==2):\n",
    "            print('wrong input shape')\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "class lognormal(fitfunction):\n",
    "    \n",
    "    # parameters\n",
    "    # mean: multidim mean of underlying normal\n",
    "    # cov: multidim covariance matrix of underlying normal\n",
    "    # mvn: scipy.stats multivariate_normal object\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self,points):\n",
    "        # points is a np array of shape (npoints,ndims)\n",
    "        super().__init__(points)\n",
    "        # transform the data from assumed log-normal to normal\n",
    "        points_log = np.log(points)\n",
    "        # fit a total multivariate normal distribution\n",
    "        self.mean = np.mean(points_log,axis=0)\n",
    "        self.cov = np.cov(points_log,rowvar=False)\n",
    "        self.mvn = multivariate_normal(self.mean,self.cov)\n",
    "        \n",
    "    # get pdf at points\n",
    "    def pdf(self,points):\n",
    "        if not super().pdf(points): return None\n",
    "        return self.mvn.pdf(np.log(points))\n",
    "    \n",
    "    def pdfgrid(self,grid):\n",
    "        if not super().pdfgrid(points): return None\n",
    "        return self.mvn.pdf(np.log(grid))\n",
    "    \n",
    "class exponential(fitfunction):\n",
    "    \n",
    "    # parameters\n",
    "    # l: multidim lambda parameter of exponential\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self,points):\n",
    "        # points is a np array of shape (npoints,ndims)\n",
    "        super().__init__(points)\n",
    "        # for now use mean for beta, maybe change later!\n",
    "        self.l = np.reciprocal(np.mean(points,axis=0))\n",
    "        \n",
    "    # get pdf at points\n",
    "    def pdf(self,points):\n",
    "        if not super().pdf(points): return None\n",
    "        return np.prod(self.l)*np.exp(-np.multiply(np.repeat(self.l,len(points),axis=0),points))\n",
    "        \n",
    "    def pdfgrid(self,grid):\n",
    "        if not super().pdfgrid(grid): return None\n",
    "        return np.prod(self.l)*np.exp(-np.sum(np.multiply(self.l,grid),axis=2))\n",
    "\n",
    "class seminormal(fitfunction):\n",
    "    # this is not strictly speaking a probability distribution,\n",
    "    # only the first quadrant of the result of fitting a normal distribution\n",
    "    # to the data + its mirror image wrt the origin\n",
    "    \n",
    "    # parameters\n",
    "    # cov: multidim covariance matrix of normal distribution\n",
    "    # mvn: scipy.stats multivariate_normal object\n",
    "        \n",
    "    # constructor from point cloud\n",
    "    def __init__(self,points=[]):\n",
    "        if len(points)==0: return\n",
    "        super().__init__(points)\n",
    "        points = np.vstack((points,-points))\n",
    "        self.cov = np.cov(points,rowvar=False)\n",
    "        self.mvn = multivariate_normal(np.zeros(self.ndims),self.cov)\n",
    "        \n",
    "    # get pdf at points\n",
    "    def pdf(self,points):\n",
    "        if not super().pdf(points): return None\n",
    "        return self.mvn.pdf(points)\n",
    "    \n",
    "    def pdfgrid(self,grid):\n",
    "        if not super().pdfgrid(grid): return None\n",
    "        return self.mvn.pdf(grid)\n",
    "    \n",
    "    def save(self,path):\n",
    "        np.save(path,self.cov)\n",
    "        \n",
    "    def load(self,path):\n",
    "        self.cov = np.load(path)\n",
    "        self.ndims = len(self.cov)\n",
    "        self.mvn = multivariate_normal(np.zeros(self.ndims),self.cov)\n",
    "        \n",
    "class gaussiankde(fitfunction):\n",
    "    # wrapper for scipy.stats.gaussian_kde (gaussian kernel density estimation)\n",
    "    \n",
    "    # parameters\n",
    "    # kernel: scipy.stats.gaussian_kde object\n",
    "    # cov: covariance matrix \n",
    "    # (use same definition as for seminormal, maybe later replace by internal kernel.covariance)\n",
    "    \n",
    "    # constructor from point cloud\n",
    "    def __init__(self,points=[],bw='default'):\n",
    "        if len(points)==0: return\n",
    "        super().__init__(points)\n",
    "        self.cov = np.cov(points,rowvar=False)\n",
    "        if bw=='default': bw = 20*np.power(self.npoints,-1/(self.ndims+4))\n",
    "        elif bw=='scott': bw = np.power(self.npoints,-1/(self.ndims+4))\n",
    "        self.kernel = gaussian_kde(np.transpose(points),bw_method=bw)\n",
    "        \n",
    "    # get pdf at points\n",
    "    def pdf(self,points):\n",
    "        if not super().pdf(points): return None\n",
    "        return self.kernel.pdf(np.transpose(points))\n",
    "    \n",
    "    # get pdf at grid\n",
    "    def pdfgrid(self,grid):\n",
    "        if not super().pdfgrid(grid): return None\n",
    "        # implementation seems to be different from scipy.mvn, explicit conversion to point array and back is needed\n",
    "        X = grid[:,:,0]\n",
    "        Y = grid[:,:,1]\n",
    "        pos = np.vstack((np.ravel(X),np.ravel(Y)))\n",
    "        Z = self.kernel.pdf(pos)\n",
    "        return np.reshape(Z,X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: moment-based pre-filtering functionality**  \n",
    "(Not used in the results from the latest weeks/months but it might be re-introduced at some point.  \n",
    "The functions below have however not been used for a long time and are not guaranteed to work out of the box...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_moments(moments,ls,dims,fig=None,ax=None,markersize=10):\n",
    "    # moments is an (nhists,nmoments) array\n",
    "    # dims is a tuple of two or three values between 0 and nmoments-1\n",
    "    from mpl_toolkits.mplot3d import Axes3D # specific import\n",
    "    if fig==None: fig = plt.figure()\n",
    "    if len(dims)==2:\n",
    "        if ax==None: ax = fig.add_subplot(111)\n",
    "        scpl = ax.scatter(moments[:,dims[0]],moments[:,dims[1]],s=markersize,c=ls,cmap='jet')\n",
    "        plt.colorbar(scpl)\n",
    "        ax.set_xlabel('moment '+str(dims[0]+1))\n",
    "        ax.set_ylabel('moment '+str(dims[1]+1))\n",
    "    elif len(dims)==3:\n",
    "        if ax==None: ax = fig.add_subplot(111, projection='3d')\n",
    "        scpl = ax.scatter(moments[:,dims[0]],moments[:,dims[1]],moments[:,dims[2]],s=markersize,c=ls,cmap='jet')\n",
    "        plt.colorbar(scpl)\n",
    "        ax.set_xlabel('moment '+str(dims[0]+1))\n",
    "        ax.set_ylabel('moment '+str(dims[1]+1))\n",
    "        ax.set_zlabel('moment '+str(dims[2]+1))\n",
    "    return (fig,ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecdist(moments,index):\n",
    "    # does not work well if there are outliers which dominate the distance\n",
    "    relmoments = moments-np.tile([moments[index,:]],(len(moments),1))\n",
    "    sumsm = np.sum(relmoments[:index,:],axis=0)\n",
    "    sumgr = np.sum(relmoments[index+1:,:],axis=0)\n",
    "    distofsum = np.sqrt(np.sum(np.power(sumsm-sumgr,2)))\n",
    "    sumofdist = np.sum(np.sqrt(np.sum(np.power(relmoments,2),axis=1)))\n",
    "    return distofsum/sumofdist\n",
    "\n",
    "def costhetadist(moments,index):\n",
    "    # works more or less but not all bad points have small values, \n",
    "    # allows to identify problematic regions but not individual LS\n",
    "    if(index==0 or index==len(moments)-1): return 0\n",
    "    inprod = np.sum(np.multiply(moments[index-1,:],moments[index+1,:]))\n",
    "    norms = np.sqrt(np.sum(np.power(moments[index-1,:],2)))*np.sqrt(np.sum(np.power(moments[index+1,:],2)))\n",
    "    return inprod/norms\n",
    "\n",
    "def avgnndist(moments,index,nn):\n",
    "    # seems to work well for the runs tested!\n",
    "    rng = np.array(range(index-nn,index+nn+1))\n",
    "    rng = rng[(rng>=0) & (rng<len(moments))]\n",
    "    moments_sec = moments[rng,:]-np.tile(moments[index,:],(len(rng),1))\n",
    "    return np.sum(np.sqrt(np.sum(np.power(moments_sec,2),axis=1)))/len(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getavgnndist(hists,nmoments,xmin,xmax,nbins,nneighbours):\n",
    "    dists = np.zeros(len(hists))\n",
    "    moments = np.zeros((len(hists),nmoments))\n",
    "    binwidth = (xmax-xmin)/nbins\n",
    "    bins = np.tile(np.linspace(xmin+binwidth/2,xmax-binwidth/2,num=nbins,endpoint=True),(len(hists),1))\n",
    "    for i in range(1,nmoments+1):\n",
    "        moments[:,i-1] = moment(bins,hists,i)\n",
    "    for i in range(len(hists)):\n",
    "        dists[i] = avgnndist(moments,i,nneighbours)\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmeanstd(dists,ls,rmlargest=0.):\n",
    "    if rmlargest>0.:\n",
    "        threshold = np.quantile(dists,1-rmlargest)\n",
    "        ls = ls[dists<threshold]\n",
    "        dists = dists[dists<threshold]\n",
    "    gmean = dists.mean()\n",
    "    gstd = dists.std()\n",
    "    return (gmean,gstd)\n",
    "\n",
    "def plot_distance(dists,ls,rmlargest=0.):\n",
    "    (gmean,gstd) = getmeanstd(dists,ls,rmlargest)\n",
    "    if rmlargest>0.:\n",
    "        threshold = np.quantile(dists,1-rmlargest)\n",
    "        ls = ls[dists<threshold]\n",
    "        dists = dists[dists<threshold]\n",
    "    \n",
    "    fig=plt.figure()\n",
    "    fig.set_size_inches(8, 6)\n",
    "    \n",
    "    plt.hlines(gmean,ls[0],ls[-1], color=\"blue\", label=\"Run average: \" + str(gmean))\n",
    "    plt.hlines(gmean+(1.0*gstd), ls[0],ls[-1], color=\"red\", label='1 SD (' + str(gstd) + \")\")\n",
    "    plt.hlines(gmean+(3.0*gstd), ls[0],ls[-1], color=\"red\", label='3 SD', linestyle=':')\n",
    "    \n",
    "    plt.ylim(np.min(dists)*0.9,np.max(dists)*1.1)\n",
    "    plt.scatter(ls, dists, marker='+', label='Data points')\n",
    "    plt.xlabel(\"Lumisection\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomalous(histlist,ls,highlight=-1,hrange=-1):\n",
    "    # histlist and ls are a list of histograms and corresponding lumisection numbers\n",
    "    # lsnumber is the lumisection number of the histogram to highlight\n",
    "    # hrange is the number of histograms before and after lsnumber to plot (default: whole run)\n",
    "    lshist = None\n",
    "    if highlight >= 0:\n",
    "        if not highlight in ls:\n",
    "            print('requested lumisection number not in list of lumisections')\n",
    "            return 0\n",
    "        index = np.where(ls==highlight)[0][0]\n",
    "        lshist = histlist[index]\n",
    "    if hrange > 0:\n",
    "        indexmax = min(index+hrange,len(ls))\n",
    "        indexmin = max(index-hrange,0)\n",
    "        histlist = histlist[indexmin:indexmax]\n",
    "        ls = ls[indexmin:indexmax]\n",
    "    # first plot all histograms in the run\n",
    "    plot_hists_multi(histlist,colorlist=ls,transparency=0.1)\n",
    "    # now plot a single histogram on top\n",
    "    if lshist is not None: \n",
    "        xlims = (0,len(lshist))\n",
    "        xax = np.linspace(xlims[0],xlims[1],num=len(lshist))\n",
    "        plt.step(xax,lshist,color='black',linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filteranomalous(df,nmoments=3,rmouterflow=True,rmlargest=0.,doplot=True,):\n",
    "    \n",
    "    # do preliminary filtering (no DCS-bit OFF)\n",
    "    # (implicitly re-index)\n",
    "    print('total number of LS: '+str(len(df)))\n",
    "    df = select_golden_and_bad(df)\n",
    "    print('filtered number of LS (DCS-bit ON): '+str(len(df)))\n",
    "    runs = get_runs(df)\n",
    "    #print('found following runs: '+str(runs))\n",
    "    \n",
    "    # initializations\n",
    "    nlumi = 0\n",
    "    dists = []\n",
    "    xmin = 0.\n",
    "    xmax = 1.\n",
    "    \n",
    "    # loop over runs and calculate distances\n",
    "    for run in runs:\n",
    "        dfr = select_runs(df,[run])\n",
    "        (hists,_,_) = get_hist_values(dfr)\n",
    "        nlumi += len(hists)\n",
    "        if rmouterflow: hists = hists[:,1:-1]\n",
    "        rdists = getavgnndist(hists,nmoments,xmin,xmax,len(hists[0]),2)\n",
    "        for d in rdists: dists.append(d)\n",
    "            \n",
    "    # concatenate all runs\n",
    "    dists = np.array(dists)\n",
    "    ind = np.linspace(0,nlumi,num=nlumi,endpoint=False)\n",
    "    if doplot: plotdistance(dists,ind,rmlargest=rmlargest)\n",
    "    (gmean,gstd) = getmeanstd(dists,ind,rmlargest=rmlargest)\n",
    "        \n",
    "    # add a columns to the original df\n",
    "    df['dist'] = dists\n",
    "    df['passmomentmethod'] = np.where(dists<gmean+3*gstd,1,0)\n",
    "    \n",
    "    # select separate df's\n",
    "    dfpass = df[df['dist']<gmean+3*gstd]\n",
    "    dfpass.reset_index(drop=True,inplace=True)\n",
    "    dffail = df[df['dist']>gmean+3*gstd]\n",
    "    dffail.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    return (df,dfpass,dffail,gmean,gstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
